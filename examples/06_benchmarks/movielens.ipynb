{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark with Movielens dataset\n",
    "\n",
    "This illustrative comparison applies to collaborative filtering algorithms available in this repository such as Spark ALS, Surprise SVD, SAR and others using the Movielens dataset. These algorithms are usable in a variety of recommendation tasks, including product or news recommendations.\n",
    "\n",
    "The main purpose of this notebook is not to produce comprehensive benchmarking results on multiple datasets. Rather, it is intended to illustrate on how one could evaluate different recommender algorithms using tools in this repository.\n",
    "\n",
    "## Experimentation setup:\n",
    "\n",
    "* Objective\n",
    "  * To compare how each collaborative filtering algorithm perform in predicting ratings and recommending relevant items.\n",
    "\n",
    "* Environment\n",
    "  * The comparison is run on a [Azure Data Science Virtual Machine](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/). \n",
    "  * The virtual machine size is a [Standard_NC6s_v2](https://learn.microsoft.com/es-es/azure/virtual-machines/ncv2-series) with 6 CPUs, 112Gb of RAM, and 1 GPU NVIDIA Tesla P100 with 16Gb of memory.\n",
    "  * It should be noted that the single node DSVM is not supposed to run scalable benchmarking analysis. Either scaling up or out the computing instances is necessary to run the benchmarking in an run-time efficient way without any memory issue.\n",
    "  * **NOTE ABOUT THE DEPENDENCIES TO INSTALL**: This notebook uses CPU, GPU and PySpark algorithms, so make sure you install the `full environment` as detailed in the [SETUP.md](../../SETUP.md). \n",
    "  \n",
    "* Datasets\n",
    "  * [Movielens 100K](https://grouplens.org/datasets/movielens/100k/).\n",
    "  * [Movielens 1M](https://grouplens.org/datasets/movielens/1m/).\n",
    "\n",
    "* Data split\n",
    "  * The data is split into train and test sets.\n",
    "  * The split ratios are 75-25 for train and test datasets.\n",
    "  * The splitting is stratified based on items. \n",
    "\n",
    "* Model training\n",
    "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
    "  * Empirical parameter values reported [here](http://mymedialite.net/examples/datasets.html) are used in this notebook.  More exhaustive hyper parameter tuning would be required to further optimize results.\n",
    "\n",
    "* Evaluation metrics\n",
    "  * Ranking metrics:\n",
    "    * Precision@k.\n",
    "    * Recall@k.\n",
    "    * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "    * Mean-average-precision (MAP). \n",
    "    * In the evaluation metrics above, k = 10. \n",
    "  * Rating metrics:\n",
    "    * Root mean squared error (RMSE).\n",
    "    * Mean average error (MAE).\n",
    "    * R squared.\n",
    "    * Explained variance.\n",
    "  * Run time performance\n",
    "    * Elapsed for training a model and using a model for predicting/recommending k items. \n",
    "    * The time may vary across different machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.13 (default, Mar 29 2022, 02:18:16) \n",
      "[GCC 7.5.0]\n",
      "NumPy version: 1.21.6\n",
      "Pandas version: 1.3.5\n",
      "PySpark version: 3.2.2\n",
      "Surprise version: 1.1.1\n",
      "PyTorch version: 1.12.1+cu102\n",
      "Fast AI version: 1.0.61\n",
      "Cornac version: 1.14.2\n",
      "TensorFlow version: 2.7.4\n",
      "CUDA version: 10.2\n",
      "CuDNN version: 7605\n",
      "Number of cores: 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "import torch\n",
    "import fastai\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "import surprise\n",
    "import cornac\n",
    "\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "from recommenders.utils.general_utils import get_number_processors\n",
    "from recommenders.utils.gpu_utils import get_cuda_version, get_cudnn_version\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.models.fastai.fastai_utils import hide_fastai_progress_bar\n",
    "\n",
    "from benchmark_utils import * \n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"PySpark version: {pyspark.__version__}\")\n",
    "print(f\"Surprise version: {surprise.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Fast AI version: {fastai.__version__}\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"CUDA version: {get_cuda_version()}\")\n",
    "print(f\"CuDNN version: {get_cudnn_version()}\")\n",
    "print(f\"Number of cores: {get_number_processors()}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/reco/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/04 09:45:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = start_or_get_spark(\"PySpark\", memory=\"32g\")\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide fastai progress bar\n",
    "hide_fastai_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds to make sure out runs are reproducible\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = {\n",
    "    \"als\": \"pyspark\",\n",
    "    \"sar\": \"python_cpu\",\n",
    "    \"svd\": \"python_cpu\",\n",
    "    \"fastai\": \"python_gpu\",\n",
    "    \"ncf\": \"python_gpu\",\n",
    "    \"bpr\": \"python_cpu\",\n",
    "    \"bivae\": \"python_gpu\",\n",
    "    \"lightgcn\": \"python_gpu\",\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"als\": [\"rating\", \"ranking\"],\n",
    "    \"sar\": [\"ranking\"],\n",
    "    \"svd\": [\"rating\", \"ranking\"],\n",
    "    \"fastai\": [\"rating\", \"ranking\"],\n",
    "    \"ncf\": [\"ranking\"],\n",
    "    \"bpr\": [\"ranking\"],\n",
    "    \"bivae\": [\"ranking\"],\n",
    "    \"lightgcn\": [\"ranking\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_params = {\n",
    "    \"rank\": 10,\n",
    "    \"maxIter\": 20,\n",
    "    \"implicitPrefs\": False,\n",
    "    \"alpha\": 0.1,\n",
    "    \"regParam\": 0.05,\n",
    "    \"coldStartStrategy\": \"drop\",\n",
    "    \"nonnegative\": False,\n",
    "    \"userCol\": DEFAULT_USER_COL,\n",
    "    \"itemCol\": DEFAULT_ITEM_COL,\n",
    "    \"ratingCol\": DEFAULT_RATING_COL,\n",
    "}\n",
    "\n",
    "sar_params = {\n",
    "    \"similarity_type\": \"jaccard\",\n",
    "    \"time_decay_coefficient\": 30,\n",
    "    \"time_now\": None,\n",
    "    \"timedecay_formula\": True,\n",
    "    \"col_user\": DEFAULT_USER_COL,\n",
    "    \"col_item\": DEFAULT_ITEM_COL,\n",
    "    \"col_rating\": DEFAULT_RATING_COL,\n",
    "    \"col_timestamp\": DEFAULT_TIMESTAMP_COL,\n",
    "}\n",
    "\n",
    "svd_params = {\n",
    "    \"n_factors\": 150,\n",
    "    \"n_epochs\": 15,\n",
    "    \"lr_all\": 0.005,\n",
    "    \"reg_all\": 0.02,\n",
    "    \"random_state\": SEED,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "fastai_params = {\n",
    "    \"n_factors\": 40, \n",
    "    \"y_range\": [0,5.5], \n",
    "    \"wd\": 1e-1,\n",
    "    \"max_lr\": 5e-3,\n",
    "    \"epochs\": 15\n",
    "}\n",
    "\n",
    "ncf_params = {\n",
    "    \"model_type\": \"NeuMF\",\n",
    "    \"n_factors\": 4,\n",
    "    \"layer_sizes\": [16, 8, 4],\n",
    "    \"n_epochs\": 15,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"verbose\": 10\n",
    "}\n",
    "\n",
    "bpr_params = {\n",
    "    \"k\": 200,\n",
    "    \"max_iter\": 200,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"lambda_reg\": 1e-3,\n",
    "    \"seed\": SEED,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "bivae_params = {\n",
    "    \"k\": 100,\n",
    "    \"encoder_structure\": [200],\n",
    "    \"act_fn\": \"tanh\",\n",
    "    \"likelihood\": \"pois\",\n",
    "    \"n_epochs\": 500,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"seed\": SEED,\n",
    "    \"use_gpu\": True,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "lightgcn_param = {\n",
    "    \"yaml_file\": os.path.join(\"..\",\"..\",\"recommenders\", \"models\", \"deeprec\", \"config\", \"lightgcn.yaml\"),\n",
    "    \"n_layers\": 3,\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 15,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"eval_epoch\": 5,\n",
    "    \"top_k\": DEFAULT_K,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"als\": als_params,\n",
    "    \"sar\": sar_params,\n",
    "    \"svd\": svd_params,\n",
    "    \"fastai\": fastai_params,\n",
    "    \"ncf\": ncf_params,\n",
    "    \"bpr\": bpr_params,\n",
    "    \"bivae\": bivae_params,\n",
    "    \"lightgcn\": lightgcn_param,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_data = {\n",
    "    \"als\": prepare_training_als,\n",
    "    \"sar\": prepare_training_sar,\n",
    "    \"svd\": prepare_training_svd,\n",
    "    \"fastai\": prepare_training_fastai,\n",
    "    \"ncf\": prepare_training_ncf,\n",
    "    \"bpr\": prepare_training_cornac,\n",
    "    \"bivae\": prepare_training_cornac,\n",
    "    \"lightgcn\": prepare_training_lightgcn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_metrics_data = {\n",
    "    \"als\": lambda train, test: prepare_metrics_als(train, test),\n",
    "    \"fastai\": lambda train, test: prepare_metrics_fastai(train, test),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = {\n",
    "    \"als\": lambda params, data: train_als(params, data),\n",
    "    \"svd\": lambda params, data: train_svd(params, data),\n",
    "    \"sar\": lambda params, data: train_sar(params, data), \n",
    "    \"fastai\": lambda params, data: train_fastai(params, data),\n",
    "    \"ncf\": lambda params, data: train_ncf(params, data),\n",
    "    \"bpr\": lambda params, data: train_bpr(params, data),\n",
    "    \"bivae\": lambda params, data: train_bivae(params, data),\n",
    "    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_predictor = {\n",
    "    \"als\": lambda model, test: predict_als(model, test),\n",
    "    \"svd\": lambda model, test: predict_svd(model, test),\n",
    "    \"fastai\": lambda model, test: predict_fastai(model, test),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_predictor = {\n",
    "    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n",
    "    \"sar\": lambda model, test, train: recommend_k_sar(model, test, train),\n",
    "    \"svd\": lambda model, test, train: recommend_k_svd(model, test, train),\n",
    "    \"fastai\": lambda model, test, train: recommend_k_fastai(model, test, train),\n",
    "    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n",
    "    \"bpr\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
    "    \"bivae\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
    "    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_evaluator = {\n",
    "    \"als\": lambda test, predictions: rating_metrics_pyspark(test, predictions),\n",
    "    \"svd\": lambda test, predictions: rating_metrics_python(test, predictions),\n",
    "    \"fastai\": lambda test, predictions: rating_metrics_python(test, predictions)\n",
    "}\n",
    "    \n",
    "    \n",
    "ranking_evaluator = {\n",
    "    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n",
    "    \"sar\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"svd\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"fastai\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"bpr\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"bivae\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(data, algo, k, train_time, time_rating, rating_metrics, time_ranking, ranking_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": time_rating, \"Recommending time (s)\": time_ranking}\n",
    "    if rating_metrics is None:\n",
    "        rating_metrics = {\n",
    "            \"RMSE\": np.nan,\n",
    "            \"MAE\": np.nan,\n",
    "            \"R2\": np.nan,\n",
    "            \"Explained Variance\": np.nan,\n",
    "        }\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {\n",
    "            \"MAP\": np.nan,\n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,\n",
    "        }\n",
    "    summary.update(rating_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = [\"100k\"]#, \"1m\"] # Movielens data size: 100k, 1m, 10m, or 20m\n",
    "algorithms = [\"als\", \"svd\", \"sar\", \"ncf\", \"fastai\", \"bpr\", \"bivae\", \"lightgcn\"]\n",
    "#algorithms = [\"als\", \"svd\", \"sar\", \"fastai\", \"bpr\", \"bivae\"]\n",
    "algorithms = [\"lightgcn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:00<00:00, 10.3kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Movielens 100k: (100000, 4)\n",
      "\n",
      "Computing lightgcn algorithm on Movielens 100k\n",
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)1.0s: train loss = 0.47360 = (mf)0.47336 + (embed)0.00024\n",
      "Epoch 2 (train)0.8s: train loss = 0.29019 = (mf)0.28956 + (embed)0.00063\n",
      "Epoch 3 (train)0.8s: train loss = 0.25493 = (mf)0.25413 + (embed)0.00079\n",
      "Epoch 4 (train)0.9s: train loss = 0.23511 = (mf)0.23413 + (embed)0.00098\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) INTERNAL: Failed initializing math mode\n\t [[node MatMul\n (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:102)\n]]\n\t [[MatMul/_49]]\n  (1) INTERNAL: Failed initializing math mode\n\t [[node MatMul\n (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:102)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MatMul:\nIn[0] embedding_lookup/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:80)\t\nIn[1] embedding_lookup_1/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:83)\n\nOperation defined at: (most recent call last)\n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n>>>     cell_id=cell_id,\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n>>>     raw_cell, store_history, silent, shell_futures, cell_id\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_24736/1409672059.py\", line 1, in <module>\n>>>     get_ipython().run_cell_magic('time', '', '\\n# For each data size and each algorithm, a recommender is evaluated. \\ncols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\\ndf_results = pd.DataFrame(columns=cols)\\n\\nfor data_size in data_sizes:\\n    # Load the dataset\\n    df = movielens.load_pandas_df(\\n        size=data_size,\\n        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\\n    )\\n    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\\n    \\n    # Split the dataset\\n    df_train, df_test = python_stratified_split(df,\\n                                                ratio=0.75, \\n                                                min_rating=1, \\n                                                filter_by=\"item\", \\n                                                col_user=DEFAULT_USER_COL, \\n                                                col_item=DEFAULT_ITEM_COL\\n                                                )\\n   \\n    # Loop through the algos\\n    for algo in algorithms:\\n        print(f\"\\\\nComputing {algo} algorithm on Movielens {data_size}\")\\n          \\n        # Data prep for training set\\n        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        # Get model parameters\\n        model_params = params[algo]\\n          \\n        # Train the model\\n        model, time_train = trainer[algo](model_params, train)\\n        print(f\"Training time: {time_train}s\")\\n                \\n        # Predict and evaluate\\n        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        if \"rating\" in metrics[algo]:   \\n            # Predict for rating\\n            preds, time_rating = rating_predictor[algo](model, test)\\n            print(f\"Rating prediction time: {time_rating}s\")\\n            \\n            # Evaluate for rating\\n            ratings = rating_evaluator[algo](test, preds)\\n        else:\\n            ratings = None\\n            time_rating = np.nan\\n        \\n        if \"ranking\" in metrics[algo]:\\n            # Predict for ranking\\n            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\\n            print(f\"Ranking prediction time: {time_ranking}s\")\\n            \\n            # Evaluate for rating\\n            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\\n        else:\\n            rankings = None\\n            time_ranking = np.nan\\n            \\n        # Record results\\n        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\\n        df_results.loc[df_results.shape[0] + 1] = summary\\n        \\nprint(\"\\\\nComputation finished\")\\n')\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2473, in run_cell_magic\n>>>     result = fn(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/decorator.py\", line 232, in fun\n>>>     return caller(func, *(extras + args), **kw)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n>>>     call = lambda f, *a, **k: f(*a, **k)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n>>>     exec(code, glob, local_ns)\n>>> \n>>>   File \"<timed exec>\", line 33, in <module>\n>>> \n>>>   File \"/tmp/ipykernel_24736/1119464800.py\", line 9, in <lambda>\n>>>     \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/examples/06_benchmarks/benchmark_utils.py\", line 347, in train_lightgcn\n>>>     model = LightGCN(hparams, data)\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\", line 102, in __init__\n>>>     transpose_b=True,\n>>> \n\nInput Source operations connected to node MatMul:\nIn[0] embedding_lookup/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:80)\t\nIn[1] embedding_lookup_1/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:83)\n\nOperation defined at: (most recent call last)\n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n>>>     cell_id=cell_id,\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n>>>     raw_cell, store_history, silent, shell_futures, cell_id\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_24736/1409672059.py\", line 1, in <module>\n>>>     get_ipython().run_cell_magic('time', '', '\\n# For each data size and each algorithm, a recommender is evaluated. \\ncols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\\ndf_results = pd.DataFrame(columns=cols)\\n\\nfor data_size in data_sizes:\\n    # Load the dataset\\n    df = movielens.load_pandas_df(\\n        size=data_size,\\n        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\\n    )\\n    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\\n    \\n    # Split the dataset\\n    df_train, df_test = python_stratified_split(df,\\n                                                ratio=0.75, \\n                                                min_rating=1, \\n                                                filter_by=\"item\", \\n                                                col_user=DEFAULT_USER_COL, \\n                                                col_item=DEFAULT_ITEM_COL\\n                                                )\\n   \\n    # Loop through the algos\\n    for algo in algorithms:\\n        print(f\"\\\\nComputing {algo} algorithm on Movielens {data_size}\")\\n          \\n        # Data prep for training set\\n        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        # Get model parameters\\n        model_params = params[algo]\\n          \\n        # Train the model\\n        model, time_train = trainer[algo](model_params, train)\\n        print(f\"Training time: {time_train}s\")\\n                \\n        # Predict and evaluate\\n        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        if \"rating\" in metrics[algo]:   \\n            # Predict for rating\\n            preds, time_rating = rating_predictor[algo](model, test)\\n            print(f\"Rating prediction time: {time_rating}s\")\\n            \\n            # Evaluate for rating\\n            ratings = rating_evaluator[algo](test, preds)\\n        else:\\n            ratings = None\\n            time_rating = np.nan\\n        \\n        if \"ranking\" in metrics[algo]:\\n            # Predict for ranking\\n            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\\n            print(f\"Ranking prediction time: {time_ranking}s\")\\n            \\n            # Evaluate for rating\\n            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\\n        else:\\n            rankings = None\\n            time_ranking = np.nan\\n            \\n        # Record results\\n        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\\n        df_results.loc[df_results.shape[0] + 1] = summary\\n        \\nprint(\"\\\\nComputation finished\")\\n')\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2473, in run_cell_magic\n>>>     result = fn(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/decorator.py\", line 232, in fun\n>>>     return caller(func, *(extras + args), **kw)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n>>>     call = lambda f, *a, **k: f(*a, **k)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n>>>     exec(code, glob, local_ns)\n>>> \n>>>   File \"<timed exec>\", line 33, in <module>\n>>> \n>>>   File \"/tmp/ipykernel_24736/1119464800.py\", line 9, in <lambda>\n>>>     \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/examples/06_benchmarks/benchmark_utils.py\", line 347, in train_lightgcn\n>>>     model = LightGCN(hparams, data)\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\", line 102, in __init__\n>>>     transpose_b=True,\n>>> \n\nOriginal stack trace for 'MatMul':\n  File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n    app.start()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/anaconda/envs/reco/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_24736/1409672059.py\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', '\\n# For each data size and each algorithm, a recommender is evaluated. \\ncols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\\ndf_results = pd.DataFrame(columns=cols)\\n\\nfor data_size in data_sizes:\\n    # Load the dataset\\n    df = movielens.load_pandas_df(\\n        size=data_size,\\n        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\\n    )\\n    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\\n    \\n    # Split the dataset\\n    df_train, df_test = python_stratified_split(df,\\n                                                ratio=0.75, \\n                                                min_rating=1, \\n                                                filter_by=\"item\", \\n                                                col_user=DEFAULT_USER_COL, \\n                                                col_item=DEFAULT_ITEM_COL\\n                                                )\\n   \\n    # Loop through the algos\\n    for algo in algorithms:\\n        print(f\"\\\\nComputing {algo} algorithm on Movielens {data_size}\")\\n          \\n        # Data prep for training set\\n        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        # Get model parameters\\n        model_params = params[algo]\\n          \\n        # Train the model\\n        model, time_train = trainer[algo](model_params, train)\\n        print(f\"Training time: {time_train}s\")\\n                \\n        # Predict and evaluate\\n        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        if \"rating\" in metrics[algo]:   \\n            # Predict for rating\\n            preds, time_rating = rating_predictor[algo](model, test)\\n            print(f\"Rating prediction time: {time_rating}s\")\\n            \\n            # Evaluate for rating\\n            ratings = rating_evaluator[algo](test, preds)\\n        else:\\n            ratings = None\\n            time_rating = np.nan\\n        \\n        if \"ranking\" in metrics[algo]:\\n            # Predict for ranking\\n            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\\n            print(f\"Ranking prediction time: {time_ranking}s\")\\n            \\n            # Evaluate for rating\\n            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\\n        else:\\n            rankings = None\\n            time_ranking = np.nan\\n            \\n        # Record results\\n        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\\n        df_results.loc[df_results.shape[0] + 1] = summary\\n        \\nprint(\"\\\\nComputation finished\")\\n')\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2473, in run_cell_magic\n    result = fn(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 33, in <module>\n  File \"/tmp/ipykernel_24736/1119464800.py\", line 9, in <lambda>\n    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n  File \"/home/hoaphumanoid/notebooks/repos/recommenders/examples/06_benchmarks/benchmark_utils.py\", line 347, in train_lightgcn\n    model = LightGCN(hparams, data)\n  File \"/home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\", line 102, in __init__\n    transpose_b=True,\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 1096, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\", line 3701, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6036, in mat_mul\n    name=name)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 746, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3705, in _create_op_internal\n    op_def=op_def)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1363\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1364\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) INTERNAL: Failed initializing math mode\n\t [[{{node MatMul}}]]\n\t [[MatMul/_49]]\n  (1) INTERNAL: Failed initializing math mode\n\t [[{{node MatMul}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24736/1119464800.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(params, data)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"bpr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_bpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"bivae\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_bivae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m\"lightgcn\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_lightgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m }\n",
      "\u001b[0;32m~/notebooks/repos/recommenders/examples/06_benchmarks/benchmark_utils.py\u001b[0m in \u001b[0;36mtrain_lightgcn\u001b[0;34m(params, data)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0meval_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0meval_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0meval_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meval_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\u001b[0m in \u001b[0;36mrun_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \"\"\"\n\u001b[1;32m    296\u001b[0m         topk_scores = self.recommend_k_items(\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         )\n\u001b[1;32m    299\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\u001b[0m in \u001b[0;36mrecommend_k_items\u001b[0;34m(self, test, top_k, sort_top_k, remove_seen, use_id)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0muser_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_user\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_seen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         top_items, top_scores = get_top_k_scored_items(\n",
      "\u001b[0;32m~/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, user_ids, remove_seen)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mitem_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             rate_batch = self.sess.run(\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_items\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             )\n\u001b[1;32m    353\u001b[0m             \u001b[0mtest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 971\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1194\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1374\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1397\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1399\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) INTERNAL: Failed initializing math mode\n\t [[node MatMul\n (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:102)\n]]\n\t [[MatMul/_49]]\n  (1) INTERNAL: Failed initializing math mode\n\t [[node MatMul\n (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:102)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MatMul:\nIn[0] embedding_lookup/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:80)\t\nIn[1] embedding_lookup_1/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:83)\n\nOperation defined at: (most recent call last)\n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n>>>     cell_id=cell_id,\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n>>>     raw_cell, store_history, silent, shell_futures, cell_id\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_24736/1409672059.py\", line 1, in <module>\n>>>     get_ipython().run_cell_magic('time', '', '\\n# For each data size and each algorithm, a recommender is evaluated. \\ncols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\\ndf_results = pd.DataFrame(columns=cols)\\n\\nfor data_size in data_sizes:\\n    # Load the dataset\\n    df = movielens.load_pandas_df(\\n        size=data_size,\\n        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\\n    )\\n    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\\n    \\n    # Split the dataset\\n    df_train, df_test = python_stratified_split(df,\\n                                                ratio=0.75, \\n                                                min_rating=1, \\n                                                filter_by=\"item\", \\n                                                col_user=DEFAULT_USER_COL, \\n                                                col_item=DEFAULT_ITEM_COL\\n                                                )\\n   \\n    # Loop through the algos\\n    for algo in algorithms:\\n        print(f\"\\\\nComputing {algo} algorithm on Movielens {data_size}\")\\n          \\n        # Data prep for training set\\n        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        # Get model parameters\\n        model_params = params[algo]\\n          \\n        # Train the model\\n        model, time_train = trainer[algo](model_params, train)\\n        print(f\"Training time: {time_train}s\")\\n                \\n        # Predict and evaluate\\n        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        if \"rating\" in metrics[algo]:   \\n            # Predict for rating\\n            preds, time_rating = rating_predictor[algo](model, test)\\n            print(f\"Rating prediction time: {time_rating}s\")\\n            \\n            # Evaluate for rating\\n            ratings = rating_evaluator[algo](test, preds)\\n        else:\\n            ratings = None\\n            time_rating = np.nan\\n        \\n        if \"ranking\" in metrics[algo]:\\n            # Predict for ranking\\n            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\\n            print(f\"Ranking prediction time: {time_ranking}s\")\\n            \\n            # Evaluate for rating\\n            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\\n        else:\\n            rankings = None\\n            time_ranking = np.nan\\n            \\n        # Record results\\n        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\\n        df_results.loc[df_results.shape[0] + 1] = summary\\n        \\nprint(\"\\\\nComputation finished\")\\n')\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2473, in run_cell_magic\n>>>     result = fn(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/decorator.py\", line 232, in fun\n>>>     return caller(func, *(extras + args), **kw)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n>>>     call = lambda f, *a, **k: f(*a, **k)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n>>>     exec(code, glob, local_ns)\n>>> \n>>>   File \"<timed exec>\", line 33, in <module>\n>>> \n>>>   File \"/tmp/ipykernel_24736/1119464800.py\", line 9, in <lambda>\n>>>     \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/examples/06_benchmarks/benchmark_utils.py\", line 347, in train_lightgcn\n>>>     model = LightGCN(hparams, data)\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\", line 102, in __init__\n>>>     transpose_b=True,\n>>> \n\nInput Source operations connected to node MatMul:\nIn[0] embedding_lookup/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:80)\t\nIn[1] embedding_lookup_1/Identity (defined at /home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py:83)\n\nOperation defined at: (most recent call last)\n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n>>>     cell_id=cell_id,\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n>>>     raw_cell, store_history, silent, shell_futures, cell_id\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_24736/1409672059.py\", line 1, in <module>\n>>>     get_ipython().run_cell_magic('time', '', '\\n# For each data size and each algorithm, a recommender is evaluated. \\ncols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\\ndf_results = pd.DataFrame(columns=cols)\\n\\nfor data_size in data_sizes:\\n    # Load the dataset\\n    df = movielens.load_pandas_df(\\n        size=data_size,\\n        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\\n    )\\n    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\\n    \\n    # Split the dataset\\n    df_train, df_test = python_stratified_split(df,\\n                                                ratio=0.75, \\n                                                min_rating=1, \\n                                                filter_by=\"item\", \\n                                                col_user=DEFAULT_USER_COL, \\n                                                col_item=DEFAULT_ITEM_COL\\n                                                )\\n   \\n    # Loop through the algos\\n    for algo in algorithms:\\n        print(f\"\\\\nComputing {algo} algorithm on Movielens {data_size}\")\\n          \\n        # Data prep for training set\\n        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        # Get model parameters\\n        model_params = params[algo]\\n          \\n        # Train the model\\n        model, time_train = trainer[algo](model_params, train)\\n        print(f\"Training time: {time_train}s\")\\n                \\n        # Predict and evaluate\\n        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        if \"rating\" in metrics[algo]:   \\n            # Predict for rating\\n            preds, time_rating = rating_predictor[algo](model, test)\\n            print(f\"Rating prediction time: {time_rating}s\")\\n            \\n            # Evaluate for rating\\n            ratings = rating_evaluator[algo](test, preds)\\n        else:\\n            ratings = None\\n            time_rating = np.nan\\n        \\n        if \"ranking\" in metrics[algo]:\\n            # Predict for ranking\\n            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\\n            print(f\"Ranking prediction time: {time_ranking}s\")\\n            \\n            # Evaluate for rating\\n            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\\n        else:\\n            rankings = None\\n            time_ranking = np.nan\\n            \\n        # Record results\\n        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\\n        df_results.loc[df_results.shape[0] + 1] = summary\\n        \\nprint(\"\\\\nComputation finished\")\\n')\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2473, in run_cell_magic\n>>>     result = fn(*args, **kwargs)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/decorator.py\", line 232, in fun\n>>>     return caller(func, *(extras + args), **kw)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n>>>     call = lambda f, *a, **k: f(*a, **k)\n>>> \n>>>   File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n>>>     exec(code, glob, local_ns)\n>>> \n>>>   File \"<timed exec>\", line 33, in <module>\n>>> \n>>>   File \"/tmp/ipykernel_24736/1119464800.py\", line 9, in <lambda>\n>>>     \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/examples/06_benchmarks/benchmark_utils.py\", line 347, in train_lightgcn\n>>>     model = LightGCN(hparams, data)\n>>> \n>>>   File \"/home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\", line 102, in __init__\n>>>     transpose_b=True,\n>>> \n\nOriginal stack trace for 'MatMul':\n  File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/envs/reco/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n    app.start()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/anaconda/envs/reco/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/anaconda/envs/reco/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_24736/1409672059.py\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', '\\n# For each data size and each algorithm, a recommender is evaluated. \\ncols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\\ndf_results = pd.DataFrame(columns=cols)\\n\\nfor data_size in data_sizes:\\n    # Load the dataset\\n    df = movielens.load_pandas_df(\\n        size=data_size,\\n        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\\n    )\\n    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\\n    \\n    # Split the dataset\\n    df_train, df_test = python_stratified_split(df,\\n                                                ratio=0.75, \\n                                                min_rating=1, \\n                                                filter_by=\"item\", \\n                                                col_user=DEFAULT_USER_COL, \\n                                                col_item=DEFAULT_ITEM_COL\\n                                                )\\n   \\n    # Loop through the algos\\n    for algo in algorithms:\\n        print(f\"\\\\nComputing {algo} algorithm on Movielens {data_size}\")\\n          \\n        # Data prep for training set\\n        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        # Get model parameters\\n        model_params = params[algo]\\n          \\n        # Train the model\\n        model, time_train = trainer[algo](model_params, train)\\n        print(f\"Training time: {time_train}s\")\\n                \\n        # Predict and evaluate\\n        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\\n        \\n        if \"rating\" in metrics[algo]:   \\n            # Predict for rating\\n            preds, time_rating = rating_predictor[algo](model, test)\\n            print(f\"Rating prediction time: {time_rating}s\")\\n            \\n            # Evaluate for rating\\n            ratings = rating_evaluator[algo](test, preds)\\n        else:\\n            ratings = None\\n            time_rating = np.nan\\n        \\n        if \"ranking\" in metrics[algo]:\\n            # Predict for ranking\\n            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\\n            print(f\"Ranking prediction time: {time_ranking}s\")\\n            \\n            # Evaluate for rating\\n            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\\n        else:\\n            rankings = None\\n            time_ranking = np.nan\\n            \\n        # Record results\\n        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\\n        df_results.loc[df_results.shape[0] + 1] = summary\\n        \\nprint(\"\\\\nComputation finished\")\\n')\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2473, in run_cell_magic\n    result = fn(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 33, in <module>\n  File \"/tmp/ipykernel_24736/1119464800.py\", line 9, in <lambda>\n    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n  File \"/home/hoaphumanoid/notebooks/repos/recommenders/examples/06_benchmarks/benchmark_utils.py\", line 347, in train_lightgcn\n    model = LightGCN(hparams, data)\n  File \"/home/hoaphumanoid/notebooks/repos/recommenders/recommenders/models/deeprec/models/graphrec/lightgcn.py\", line 102, in __init__\n    transpose_b=True,\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 1096, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\", line 3701, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6036, in mat_mul\n    name=name)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 746, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3705, in _create_op_internal\n    op_def=op_def)\n  File \"/anaconda/envs/reco/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For each data size and each algorithm, a recommender is evaluated. \n",
    "cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    # Load the dataset\n",
    "    df = movielens.load_pandas_df(\n",
    "        size=data_size,\n",
    "        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n",
    "    )\n",
    "    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n",
    "    \n",
    "    # Split the dataset\n",
    "    df_train, df_test = python_stratified_split(df,\n",
    "                                                ratio=0.75, \n",
    "                                                min_rating=1, \n",
    "                                                filter_by=\"item\", \n",
    "                                                col_user=DEFAULT_USER_COL, \n",
    "                                                col_item=DEFAULT_ITEM_COL\n",
    "                                                )\n",
    "   \n",
    "    # Loop through the algos\n",
    "    for algo in algorithms:\n",
    "        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n",
    "          \n",
    "        # Data prep for training set\n",
    "        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
    "        \n",
    "        # Get model parameters\n",
    "        model_params = params[algo]\n",
    "          \n",
    "        # Train the model\n",
    "        model, time_train = trainer[algo](model_params, train)\n",
    "        print(f\"Training time: {time_train}s\")\n",
    "                \n",
    "        # Predict and evaluate\n",
    "        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
    "        \n",
    "        if \"rating\" in metrics[algo]:   \n",
    "            # Predict for rating\n",
    "            preds, time_rating = rating_predictor[algo](model, test)\n",
    "            print(f\"Rating prediction time: {time_rating}s\")\n",
    "            \n",
    "            # Evaluate for rating\n",
    "            ratings = rating_evaluator[algo](test, preds)\n",
    "        else:\n",
    "            ratings = None\n",
    "            time_rating = np.nan\n",
    "        \n",
    "        if \"ranking\" in metrics[algo]:\n",
    "            # Predict for ranking\n",
    "            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n",
    "            print(f\"Ranking prediction time: {time_ranking}s\")\n",
    "            \n",
    "            # Evaluate for rating\n",
    "            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n",
    "        else:\n",
    "            rankings = None\n",
    "            time_ranking = np.nan\n",
    "            \n",
    "        # Record results\n",
    "        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n",
    "        df_results.loc[df_results.shape[0] + 1] = summary\n",
    "        \n",
    "print(\"\\nComputation finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>Train time (s)</th>\n",
       "      <th>Predicting time (s)</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>Recommending time (s)</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Data, Algo, K, Train time (s), Predicting time (s), RMSE, MAE, R2, Explained Variance, Recommending time (s), MAP, nDCG@k, Precision@k, Recall@k]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco",
   "language": "python",
   "name": "conda-env-reco-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b9e8d8274bb2aefc43ff4060bf2aea1a22b531dbbc61ceb737842ea8b3b7c74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
