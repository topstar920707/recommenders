{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining word and entity embeddings\n",
    "This notebook trains word embeddings and entity embeddings for DKN initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "from utils.general import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.task_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentenceCollection:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.rd = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.rd = open(self.filename, 'r', encoding='utf-8', newline='\\r\\n')\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        line = self.rd.readline()\n",
    "        if line:\n",
    "            return list(line.strip('\\r\\n').split(' '))\n",
    "        else:\n",
    "            self.rd.close()\n",
    "            raise StopIteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "InFile_dir = 'data_folder/my'\n",
    "OutFile_dir = 'data_folder/my/pretrained-embeddings'\n",
    "OutFile_dir_KG = 'data_folder/my/KG'\n",
    "OutFile_dir_DKN = 'data_folder/my/DKN-training-folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use word2vec algorithm implemented in Gensim (https://radimrehurek.com/gensim/models/word2vec.html) to generate word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to train word embedding... \tdone . \n",
      "time elapses: 526.3s\n"
     ]
    }
   ],
   "source": [
    "def train_word2vec(Path_sentences, OutFile_dir):     \n",
    "    OutFile_word2vec = os.path.join(OutFile_dir, r'word2vec.model')\n",
    "    OutFile_word2vec_txt = os.path.join(OutFile_dir, r'word2vec.txt')\n",
    "    create_dir(OutFile_dir)\n",
    "\n",
    "    print('start to train word embedding...', end=' ')\n",
    "    my_sentences = MySentenceCollection(Path_sentences)\n",
    "    model = Word2Vec(my_sentences, size=32, window=5, min_count=1, workers=8, iter=30)\n",
    "\n",
    "    model.save(OutFile_word2vec)\n",
    "    model.wv.save_word2vec_format(OutFile_word2vec_txt, binary=False)\n",
    "    print('\\tdone . ')\n",
    "\n",
    "Path_sentences = os.path.join(InFile_dir, 'sentence.txt')\n",
    "\n",
    "t0 = time.time()\n",
    "train_word2vec(Path_sentences, OutFile_dir)\n",
    "t1 = time.time()\n",
    "print('time elapses: {0:.1f}s'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We leverage a graph embedding model to encode entities into embedding vectors.\n",
    "<img src=\"https://recodatasets.blob.core.windows.net/kdd2020/images%2Fkg-embedding-math.JPG\" width=\"600\">\n",
    "<img src=\"https://recodatasets.blob.core.windows.net/kdd2020/images%2Fkg-embedding.JPG\" width=\"600\">\n",
    "We use an open-source implementation of TransE (https://github.com/thunlp/Fast-TransX) for generating knowledge graph embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/jialia/jialia/kdd2020tutorial/formal_02/recommenders/scenarios/KDD2020-tutorial\n",
      "fatal: destination path 'Fast-TransX' already exists and is not an empty directory.\n",
      "epoch 0 464878.218750\n",
      "epoch 1 392123.312500\n",
      "epoch 2 361906.625000\n",
      "epoch 3 315392.156250\n",
      "epoch 4 310050.875000\n",
      "epoch 5 281908.250000\n",
      "epoch 6 271810.968750\n",
      "epoch 7 240873.968750\n",
      "epoch 8 237960.375000\n",
      "epoch 9 221742.484375\n"
     ]
    }
   ],
   "source": [
    "!bash ./run_transE.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DKN take considerations of both the entity embeddings and its context embeddings.\n",
    "<img src=\"https://recodatasets.blob.core.windows.net/kdd2020/images/context-embedding.JPG\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EMBEDDING_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-867053a0e641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcontext_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutFile_dir_KG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'context2vec.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkg_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutFile_dir_KG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train2id.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgen_context_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/home/jialia/jialia/kdd2020tutorial/formal_02/recommenders/scenarios/KDD2020-tutorial/utils/task_helper.py\u001b[0m in \u001b[0;36mgen_context_embedding\u001b[0;34m(entity_file, context_file, kg_file)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0mfp_entity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp_entity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mlinesplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mEMBEDDING_LENGTH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mlinesplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinesplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mentity_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinesplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EMBEDDING_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "##### build context embedding\n",
    "EMBEDDING_LENGTH = 32\n",
    "entity_file = os.path.join(OutFile_dir_KG, 'entity2vec.vec') \n",
    "context_file = os.path.join(OutFile_dir_KG, 'context2vec.vec')   \n",
    "kg_file = os.path.join(OutFile_dir_KG, 'train2id.txt')   \n",
    "gen_context_embedding(entity_file, context_file, kg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_np_from_txt(\n",
    "        os.path.join(OutFile_dir_KG, 'entity2vec.vec'),\n",
    "        os.path.join(OutFile_dir_DKN, 'entity_embedding.npy'),\n",
    "    )\n",
    "load_np_from_txt(\n",
    "        os.path.join(OutFile_dir_KG, 'context2vec.vec'),\n",
    "        os.path.join(OutFile_dir_DKN, 'context_embedding.npy'),\n",
    "    )\n",
    "format_word_embeddings(\n",
    "    os.path.join(OutFile_dir, 'word2vec.txt'),\n",
    "    os.path.join(InFile_dir, 'word2idx.pkl'),\n",
    "    os.path.join(OutFile_dir_DKN, 'word_embedding.npy')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_gpu_kdd",
   "language": "python",
   "name": "reco_gpu_kdd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
