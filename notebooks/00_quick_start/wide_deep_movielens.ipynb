{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Model for Movie Recommendation\n",
    "\n",
    "### Prerequisite\n",
    "* `tensorflow`\n",
    "\n",
    "In this example, we utilize TensorFlow's higher level Estimator API to build wide-and-deep model for movie recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:CPU:0', '/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "devices = device_lib.list_local_devices()\n",
    "[x.name for x in devices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId  Rating  Timestamp\n",
       "0     196      242     3.0  881250949\n",
       "1     186      302     3.0  891717742\n",
       "2      22      377     1.0  878887116\n",
       "3     244       51     2.0  880606923\n",
       "4     166      346     1.0  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['UserId','MovieId','Rating','Timestamp'],\n",
    "    # TODO For now, not using genres YET\n",
    "    load_genres=False\n",
    ")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 943 users to 5-dim vector\n",
      "Embedding 1682 items to 6-dim vector\n"
     ]
    }
   ],
   "source": [
    "# Distinct users and items\n",
    "user_list = data['UserId'].unique()\n",
    "item_list = data['MovieId'].unique()\n",
    "\n",
    "# Rule of thumb for embedding_dimensions =  number_of_categories ** 0.25\n",
    "USER_EMBEDDING_DIM = int(len(user_list) ** 0.25) # = 16\n",
    "ITEM_EMBEDDING_DIM = int(len(item_list) ** 0.25) # = 64\n",
    "print(\"Embedding {} users to {}-dim vector\".format(len(user_list), USER_EMBEDDING_DIM))\n",
    "print(\"Embedding {} items to {}-dim vector\".format(len(item_list), ITEM_EMBEDDING_DIM))\n",
    "\n",
    "# Convert a categorical feature, e.g. UserId or MovieId, into a lower-dimensional vector (embedding)\n",
    "user_id = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'UserId', user_list)\n",
    "user_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=user_id,\n",
    "    dimension=USER_EMBEDDING_DIM,\n",
    "    max_norm=USER_EMBEDDING_DIM**.5)\n",
    "\n",
    "item_id = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'MovieId', item_list)\n",
    "item_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=item_id,\n",
    "    dimension=ITEM_EMBEDDING_DIM,\n",
    "    max_norm=ITEM_EMBEDDING_DIM**.5)\n",
    "\n",
    "timestamp = tf.feature_column.numeric_column('Timestamp')\n",
    "\n",
    "# TODO numeric_column (w/ shape)\n",
    "# genres = tf.feature_column.numeric_column(\n",
    "#     'Genre', shape=(NUM_GENRES,), dtype=tf.uint8)\n",
    "\n",
    "deep_columns = [user_embedding, item_embedding, timestamp]  # TODO , genres]\n",
    "wide_columns = []  # TODO cross product transformation of user and item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tran and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       UserId  MovieId  Timestamp\n",
      "31450     496      136  876066424\n",
      "42809      64      101  889740225\n",
      "52419     158      471  880132513\n",
      "45663     198      652  884209569\n",
      "50696     749      121  878847645\n",
      "\n",
      "Labels:\n",
      "31450    1.0\n",
      "42809    2.0\n",
      "52419    4.0\n",
      "45663    3.0\n",
      "50696    3.0\n",
      "Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train, test = python_random_split(data, ratio=0.75, seed=123)\n",
    "\n",
    "train_x = train.copy()\n",
    "train_y = train_x.pop('Rating')\n",
    "test_x = test.copy()\n",
    "test_y = test_x.pop('Rating')\n",
    "\n",
    "print(train_x.head())\n",
    "print(\"\\nLabels:\")\n",
    "print(train_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection\n",
    "* `wide` - Linear model\n",
    "* `deep` - DNN model\n",
    "* `wide_deep` - Linear combination of the linear and DNN models\n",
    "\n",
    "(TODO)Model type: `regressor` or `classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wide', 'deep', or 'wide_deep' \n",
    "MODEL_TYPE = 'deep'\n",
    "HIDDEN_UNITS = [256, 256, 256, 128]\n",
    "# Model checkpoints folder\n",
    "MODEL_DIR = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000026212FD8630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# TODO set run config if needed\n",
    "if MODEL_TYPE == 'wide':\n",
    "    if len(wide_columns) == 0:\n",
    "        raise ValueError(\"No features have defined for the 'wide' model\")\n",
    "    model = tf.estimator.LinearRegressor(  # LinearClassifier(\n",
    "        model_dir=MODEL_DIR,\n",
    "        feature_columns=wide_columns,\n",
    "    )\n",
    "elif MODEL_TYPE == 'deep':\n",
    "    if len(deep_columns) == 0:\n",
    "        raise ValueError(\"No features have defined for the 'deep' model\")\n",
    "    model = tf.estimator.DNNRegressor(  # DNNClassifier(\n",
    "        model_dir=MODEL_DIR,\n",
    "        feature_columns=deep_columns,\n",
    "        hidden_units=HIDDEN_UNITS,\n",
    "        optimizer=tf.train.AdamOptimizer(),\n",
    "#         activation_fn=tf.nn.sigmoid,\n",
    "#         dropout=0.3,\n",
    "#         loss_reduction=tf.losses.Reduction.MEAN,\n",
    "#         batch_norm=False\n",
    "    )\n",
    "elif MODEL_TYPE == 'wide_deep':\n",
    "    if len(wide_columns) == 0 and len(deep_columns) == 0:\n",
    "        raise ValueError(\"No features have defined for the 'wide_deep' model\")\n",
    "    model = tf.estimator.DNNLinearCombinedRegressor(  # DNNLinearCombinedClassifier(\n",
    "        model_dir=MODEL_DIR,\n",
    "        # wide settings\n",
    "        linear_feature_columns=wide_columns,\n",
    "        # deep settings\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=HIDDEN_UNITS,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Model type should be either 'wide', 'deep', or 'wide_deep'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./models\\model.ckpt.\n",
      "INFO:tensorflow:loss = 3.5551321e+16, step = 0\n",
      "INFO:tensorflow:global_step/sec: 87.4924\n",
      "INFO:tensorflow:loss = 1876942700000.0, step = 100 (1.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.508\n",
      "INFO:tensorflow:loss = 67808710.0, step = 200 (0.823 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 293 into ./models\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7182.6343.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x26212fd8400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maybe should set tf.estimator.RunConfig to run on GPU?\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "train_steps = len(train_x) / BATCH_SIZE\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    shuffle=True,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "model.train(input_fn=train_input_fn, steps=train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-22:14:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./models\\model.ckpt-293\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-22:14:04\n",
      "INFO:tensorflow:Saving dict for global step 293: average_loss = 17.11205, global_step = 293, loss = 2182.6594\n",
      "{'average_loss': 17.11205, 'loss': 2182.6594, 'global_step': 293}\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=test_x,\n",
    "    y=test_y,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "result = model.evaluate(input_fn=test_input_fn, steps=None)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./models\\model.ckpt-293\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42083</th>\n",
       "      <td>600</td>\n",
       "      <td>651</td>\n",
       "      <td>888451492</td>\n",
       "      <td>10.501305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71825</th>\n",
       "      <td>607</td>\n",
       "      <td>494</td>\n",
       "      <td>883879556</td>\n",
       "      <td>7.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99535</th>\n",
       "      <td>875</td>\n",
       "      <td>1103</td>\n",
       "      <td>876465144</td>\n",
       "      <td>3.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47879</th>\n",
       "      <td>648</td>\n",
       "      <td>238</td>\n",
       "      <td>882213535</td>\n",
       "      <td>6.251305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734</th>\n",
       "      <td>113</td>\n",
       "      <td>273</td>\n",
       "      <td>875935609</td>\n",
       "      <td>2.251305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserId  MovieId  Timestamp  prediction\n",
       "42083     600      651  888451492   10.501305\n",
       "71825     607      494  883879556    7.001305\n",
       "99535     875     1103  876465144    3.001305\n",
       "47879     648      238  882213535    6.251305\n",
       "36734     113      273  875935609    2.251305"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=test_input_fn))\n",
    "pred_list = [p['predictions'][0] for p in predictions]\n",
    "test_x['prediction']  = pd.Series(pred_list).values\n",
    "test_x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t4.136671\n",
      "MAE:\t\t3.301557\n",
      "rsquared:\t-12.295617\n",
      "exp var:\t-9.991789\n"
     ]
    }
   ],
   "source": [
    "cols = {\n",
    "    'col_user': \"UserId\",\n",
    "    'col_item': \"MovieId\",\n",
    "    'col_rating': \"Rating\",\n",
    "    'col_prediction': \"prediction\",\n",
    "}\n",
    "\n",
    "\n",
    "eval_rmse = rmse(test, test_x, **cols)\n",
    "eval_mae = mae(test, test_x, **cols)\n",
    "eval_rsquared = rsquared(test, test_x, **cols)\n",
    "eval_exp_var = exp_var(test, test_x, **cols)\n",
    "\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-tf-gpu",
   "language": "python",
   "name": "python3-tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
