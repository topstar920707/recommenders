{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart to integrate Recommenders in AzureML Designer\n",
    "\n",
    "This notebook shows how to integrate any algorithm in Recommenders library into AzureML Designer. \n",
    "\n",
    "[AzureML Designer](https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer) lets you visually connect datasets and modules on an interactive canvas to create machine learning models. \n",
    "\n",
    "![img](https://recodatasets.blob.core.windows.net/images/designer-drag-and-drop.gif)\n",
    "\n",
    "One of the features of AzureML Designer is that it is possible for developers to integrate any python library to make it available as a module. In this notebook are are going to show how to integrate [SAR](sar_movielens.ipynb) and several other modules in Designer\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "The first step is to install AzureML Designer SDK. Assuming that you have installed the Recommenders environment `reco_base` as explained in the [SETUP.md](../../SETUP.md), you need to install:\n",
    "```bash\n",
    "conda activate reco_base\n",
    "pip install keyring artifacts-keyring\n",
    "pip install azureml-designer-tools==0.1.10.post8799295 --extra-index-url=https://msdata.pkgs.visualstudio.com/_packaging/azureml-modules%40Local/pypi/simple/ \n",
    "```\n",
    "\n",
    "## Module implementation\n",
    "\n",
    "The scenario that we are going to reproduce in Designer, as a reference example, is the content of the [SAR quickstart notebook](sar_movielens.ipynb). In it, we load a dataset, split it into train and test sets, train SAR algorithm, predict using the test set and compute several ranking metrics (precision at k, recall at k, MAP and nDCG).\n",
    "\n",
    "For the pipeline that we want to create in Designer, we need to build the following modules:\n",
    "\n",
    "- Stratified splitter\n",
    "- SAR training\n",
    "- SAR prediction\n",
    "- Precision at k\n",
    "- Recall at k\n",
    "- MAP\n",
    "- nDCG\n",
    "\n",
    "The python code is defined with a python entry and a yaml file. All the python entries and yaml files for this pipeline can be found in [reco_utils/azureml/azureml_designer_modules](../../reco_utils/azureml/azureml_designer_modules).\n",
    "\n",
    "\n",
    "### Define python entry\n",
    "\n",
    "To illustrate how a python entry is defined we are going to explain the [precision at k entry](../../reco_utils/azureml/azureml_designer_modules/precision_at_k_entry.py). A simplified version of the code is shown next:\n",
    "\n",
    "```python\n",
    "# Dependencies\n",
    "from azureml.studio.core.data_frame_schema import DataFrameSchema\n",
    "from azureml.studio.core.io.data_frame_directory import (\n",
    "    load_data_frame_from_directory,\n",
    "    save_data_frame_to_directory,\n",
    ")\n",
    "from reco_utils.evaluation.python_evaluation import precision_at_k\n",
    "\n",
    "# First, the input variables of precision_at_k are defined as argparse arguments\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--rating-true\", help=\"True DataFrame.\")\n",
    "    parser.add_argument(\"--rating-pred\", help=\"Predicted DataFrame.\")\n",
    "    parser.add_argument(\n",
    "        \"--col-user\", type=str, help=\"A string parameter with column name for user.\"\n",
    "    )\n",
    "    # ... more arguments\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # This module has two main inputs from the canvas, the true and predicted labels\n",
    "    # they are loaded into the runtime as a pandas DataFrame\n",
    "    rating_true = load_data_frame_from_directory(args.rating_true).data\n",
    "    rating_pred = load_data_frame_from_directory(args.rating_pred).data\n",
    "\n",
    "    # The python function is instantiated and the computation is performed\n",
    "    eval_precision = precision_at_k(rating_true, rating_pred)\n",
    "    \n",
    "    # To output the result to Designer, we write it as a DataFrame\n",
    "    score_result = pd.DataFrame({\"precision_at_k\": [eval_precision]})\n",
    "    save_data_frame_to_directory(\n",
    "        args.score_result,\n",
    "        score_result,\n",
    "        schema=DataFrameSchema.data_frame_to_dict(score_result),\n",
    "    )\n",
    "```\n",
    "\n",
    "\n",
    "### Define yaml entry\n",
    "\n",
    "Once we have the python entry, we need to create the yaml file that will interact with Designer, [precision_at_k.yaml](../../reco_utils/azureml/azureml_designer_modules/precision_at_k.yaml).\n",
    "\n",
    "```yaml\n",
    "name: Precision at K\n",
    "id: efd1af54-0d31-42e1-b3d5-ce3b7c538705\n",
    "version: 0.0.1\n",
    "category: Recommenders/Metrics\n",
    "description: \"Precision at K metric from Recommenders repo: https://github.com/Microsoft/Recommenders.\"\n",
    "inputs:\n",
    "- name: Rating true\n",
    "  type: DataFrameDirectory\n",
    "  description: True DataFrame.\n",
    "  port: true\n",
    "- name: Rating pred\n",
    "  type: DataFrameDirectory\n",
    "  description: Predicted DataFrame.\n",
    "  port: true\n",
    "- name: User column\n",
    "  type: String\n",
    "  default: UserId\n",
    "  description: Column name of user IDs.\n",
    "outputs:\n",
    "- name: Score\n",
    "  type: DataFrameDirectory\n",
    "  description: Precision at k (min=0, max=1).\n",
    "  port: true\n",
    "implementation:\n",
    "  container:\n",
    "    conda: sar_conda.yaml\n",
    "    entry: azureml-designer-modules/entries/precision_at_k_entry.py\n",
    "    args:\n",
    "    - --rating-true\n",
    "    - inputPath: Rating true\n",
    "    - --rating-pred\n",
    "    - inputPath: Rating pred\n",
    "    - --col-user\n",
    "    - --score-result\n",
    "    - outputPath: Score\n",
    "```\n",
    "\n",
    "In the yaml file we can see a number of sections. The heading defines attributes like name, version or description. In the section inputs, all inputs are defined. The two main dataframes have ports, which can be connected to other modules. The inputs without port appear in a canvas menu. The output is defined as a DataFrame as well. The last section, implementation, defines the conda environment, the associated python entry and the arguments to the python file.\n",
    "\n",
    "Once the full pipeline is designer, it should look like this:\n",
    "![img](https://recodatasets.blob.core.windows.net/images/azureml_designer_sar_precisionatk.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_base)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
