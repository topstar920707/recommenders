{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Model for Movie Recommendation\n",
    "<br>\n",
    "\n",
    "This notebook shows how to build and test [**wide-and-deep model**](https://arxiv.org/abs/1606.07792)--linear combination of linear and deep NN models--using [TensorFlow high-level Estimator API](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedRegressor).\n",
    "\n",
    "On the [movie recommendation dataset](https://grouplens.org/datasets/movielens/), we quickly demonstrate how to prepare features, build the model, use log-hook to estimate performance while training, export model, and load the saved model.\n",
    "\n",
    "We use a preset of hyper-parameters optimized for *MovieLens 1M* dataset we found by utilizing **Azure Machine Learning service**([AzureML or AML](https://azure.microsoft.com/en-us/services/machine-learning-service/)). You can find more details about hyperparameter tuning of wide-and-deep model via AML from [our notebook](../04_model_select_and_optimize/aml_hyperparameter_tuning.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "* TensorFlow (version 1.8 or higher) - GPU version is preferable. To easily setup a conda environment with `tensorflow-gpu` package, please follow [SETUP].(https://github.com/Microsoft/Recommenders/blob/master/SETUP.md) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from reco_utils.common import tf_utils\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.pandas_df_utils import user_item_pairs\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    rmse, mae, rsquared, exp_var,\n",
    "    map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/device:CPU:0', '/device:XLA_CPU:0', '/device:XLA_GPU:0', '/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "\n",
    "devices = device_lib.list_local_devices()\n",
    "[x.name for x in devices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "Download [MovieLens](https://grouplens.org/datasets/movielens/) data and split train / test set.\n",
    "\n",
    "MovieLens data have movie genres information where each movie has one or more genres. We do multi-hot-encode to use genres as an item feature. For example:\n",
    "\n",
    "*Movie id=2355* has three genres, *Animation | Children's | Comedy*, which are being converted into an integer array of the indicator value for each genre like `[0, 0, 1, 1, 1, 0, 0, 0, ...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "\n",
    "USER_COL = 'UserId'\n",
    "ITEM_COL = 'MovieId'\n",
    "RATING_COL = 'Rating'\n",
    "ITEM_FEAT_COL = 'Genres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Genres_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId  Rating Genres_string\n",
       "0       1     1193     5.0         Drama\n",
       "1       2     1193     5.0         Drama\n",
       "2      12     1193     4.0         Drama\n",
       "3      15     1193     4.0         Drama\n",
       "4      17     1193     5.0         Drama"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[USER_COL, ITEM_COL, RATING_COL],\n",
    "    genres_col='Genres_string'\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: ['Action' 'Adventure' 'Animation' \"Children's\" 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Fantasy' 'Film-Noir' 'Horror' 'Musical' 'Mystery'\n",
      " 'Romance' 'Sci-Fi' 'Thriller' 'War' 'Western'] \n",
      "\n",
      "   MovieId                 Genres_string  \\\n",
      "0     1193                         Drama   \n",
      "1      661  Animation|Children's|Musical   \n",
      "2      914               Musical|Romance   \n",
      "3     3408                         Drama   \n",
      "4     2355   Animation|Children's|Comedy   \n",
      "\n",
      "                                              Genres  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "# Encode 'genres' into int array (multi-hot representation) to use as item features\n",
    "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n",
    "data[ITEM_FEAT_COL] = genres_encoder.fit_transform(\n",
    "    data['Genres_string'].apply(lambda s: s.split(\"|\"))\n",
    ").tolist()\n",
    "print(\"Genres:\", genres_encoder.classes_, \"\\n\")\n",
    "\n",
    "_items = data.drop_duplicates(ITEM_COL)[[ITEM_COL, 'Genres_string', ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "print(_items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num items = 3706, num users = 6040\n"
     ]
    }
   ],
   "source": [
    "# Unique items and users in the data. Will be used to generate recommendation pool\n",
    "items = _items.drop('Genres_string', axis=1)\n",
    "users = data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "\n",
    "print(\"num items = {}, num users = {}\".format(len(items), len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(\n",
    "    data.drop('Genres_string', axis=1),\n",
    "    ratio=0.75,\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Wide and deep model utilizes two different types of feature sets:\n",
    "1. Wide / cross-producted features to capture how the co-occurrence of a user-item feature pair correlates with the target label or rating, and\n",
    "2. Deep / lower-dimensional embedding vectors for every user and item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num epochs:  26\n",
      "Embedding 6040 users to 32-dim vector\n",
      "Embedding 3706 items to 16-dim vector\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Hyper parameters\n",
    "\"\"\"\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = int(20000000 / len(train))\n",
    "print(\"Num epochs: \", NUM_EPOCHS)\n",
    "\n",
    "LINEAR_OPTIMIZER = tf.train.FtrlOptimizer(\n",
    "    learning_rate=0.07,\n",
    "    l1_regularization_strength=0.015\n",
    ")\n",
    "DNN_OPTIMIZER = tf.train.AdagradOptimizer(\n",
    "    learning_rate=0.018\n",
    ")\n",
    "DNN_HIDDEN_UNITS = [64, 128, 32]\n",
    "DNN_DROPOUT = 0.2\n",
    "DNN_BATCH_NORM = True\n",
    "\n",
    "DNN_USER_DIM = 32\n",
    "DNN_ITEM_DIM = 16\n",
    "\n",
    "print(\"Embedding {} users to {}-dim vector\".format(len(users), DNN_USER_DIM))\n",
    "print(\"Embedding {} items to {}-dim vector\".format(len(items), DNN_ITEM_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CrossedColumn(keys=(_VocabularyListCategoricalColumn(key='UserId', vocabulary_list=(1, 2, 12, 15, 1 ...\n",
      "_EmbeddingColumn(categorical_column=_VocabularyListCategoricalColumn(key='UserId', vocabulary_list=( ...\n",
      "_EmbeddingColumn(categorical_column=_VocabularyListCategoricalColumn(key='MovieId', vocabulary_list= ...\n",
      "_NumericColumn(key='Genres', shape=(18,), default_value=None, dtype=tf.float32, normalizer_fn=None) ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Feature columns\n",
    "\"\"\"\n",
    "\n",
    "user_id = tf.feature_column.categorical_column_with_vocabulary_list(USER_COL, users[USER_COL].values)\n",
    "item_id = tf.feature_column.categorical_column_with_vocabulary_list(ITEM_COL, items[ITEM_COL].values)\n",
    "\n",
    "wide_columns = [\n",
    "    tf.feature_column.crossed_column([user_id, item_id], hash_bucket_size=1000)\n",
    "]\n",
    "\n",
    "deep_columns = [\n",
    "    # User embedding\n",
    "    tf.feature_column.embedding_column(\n",
    "        categorical_column=user_id,\n",
    "        dimension=DNN_USER_DIM,\n",
    "        max_norm=DNN_USER_DIM ** .5\n",
    "    ),\n",
    "    # Item embedding\n",
    "    tf.feature_column.embedding_column(\n",
    "        categorical_column=item_id,\n",
    "        dimension=DNN_ITEM_DIM,\n",
    "        max_norm=DNN_ITEM_DIM ** .5\n",
    "    ),\n",
    "    # Item feature\n",
    "    tf.feature_column.numeric_column(\n",
    "        ITEM_FEAT_COL,\n",
    "        shape=len(genres_encoder.classes_),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "]\n",
    "\n",
    "for c in wide_columns + deep_columns:\n",
    "    print(str(c)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'model_checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f17f1a266d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = 'model_checkpoints'\n",
    "\n",
    "try:\n",
    "    # Clean-up previous model dir if exists\n",
    "    shutil.rmtree(MODEL_DIR)\n",
    "except (PermissionError, FileNotFoundError):\n",
    "    pass\n",
    "\n",
    "# Set logging frequency\n",
    "LOG_STEP = 1000\n",
    "run_config = tf.estimator.RunConfig()\n",
    "run_config = run_config.replace(log_step_count_steps=LOG_STEP)\n",
    "\n",
    "# We use regressor for rating prediction\n",
    "model = tf.estimator.DNNLinearCombinedRegressor(\n",
    "    model_dir=MODEL_DIR,\n",
    "    config=run_config,\n",
    "    # wide model args\n",
    "    linear_feature_columns=wide_columns,\n",
    "    linear_optimizer=LINEAR_OPTIMIZER,\n",
    "    # deep model args\n",
    "    dnn_feature_columns=deep_columns,\n",
    "    dnn_hidden_units=DNN_HIDDEN_UNITS,\n",
    "    dnn_optimizer=DNN_OPTIMIZER,\n",
    "    dnn_dropout=DNN_DROPOUT,\n",
    "    batch_norm=DNN_BATCH_NORM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'model_checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f17bcddd518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Add additional metrics 'mae' in addition to the default 'loss'\n",
    "metrics_fn = (lambda labels, predictions: {\n",
    "    'mae': tf.metrics.mean_absolute_error(\n",
    "        tf.cast(labels, tf.float32),\n",
    "        predictions['predictions']\n",
    "    )\n",
    "})\n",
    "\n",
    "model = tf.contrib.estimator.add_metrics(model, metrics_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3479</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4215</td>\n",
       "      <td>218</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3528</td>\n",
       "      <td>1652</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>646</td>\n",
       "      <td>1078</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5105</td>\n",
       "      <td>2834</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId                                             Genres\n",
       "0    3479       22  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1    4215      218  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2    3528     1652  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3     646     1078  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4    5105     2834  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare a recommendation pool for recommending k-item (ranking) scenario\n",
    "# We also remove seen items (filter out user-item pairs in the training set)\n",
    "ranking_pool = user_item_pairs(\n",
    "    user_df=users,\n",
    "    item_df=items,\n",
    "    user_col=USER_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    user_item_filter_df=train,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "ranking_pool.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Training hooks\n",
    "\"\"\"\n",
    "eval_kwargs = {\n",
    "    'col_user': USER_COL,\n",
    "    'col_item': ITEM_COL,\n",
    "    'col_rating': RATING_COL,\n",
    "    'col_prediction': 'prediction',\n",
    "    'k': TOP_K\n",
    "}\n",
    "\n",
    "precision_eval_hook = tf_utils.evaluation_log_hook(\n",
    "    model,\n",
    "    true_df=test,\n",
    "    y_col=RATING_COL,\n",
    "    eval_df=ranking_pool,\n",
    "    every_n_iter=LOG_STEP*20,\n",
    "    model_dir=MODEL_DIR,\n",
    "    eval_fn=precision_at_k,\n",
    "    **eval_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_checkpoints/model.ckpt.\n",
      "INFO:tensorflow:loss = 4215.095, step = 0\n",
      "INFO:tensorflow:global_step/sec: 109.255\n",
      "INFO:tensorflow:loss = 315.16928, step = 1000 (9.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.431\n",
      "INFO:tensorflow:loss = 255.80698, step = 2000 (9.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.352\n",
      "INFO:tensorflow:loss = 268.7221, step = 3000 (8.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.505\n",
      "INFO:tensorflow:loss = 251.08221, step = 4000 (8.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.278\n",
      "INFO:tensorflow:loss = 242.23853, step = 5000 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.646\n",
      "INFO:tensorflow:loss = 227.27785, step = 6000 (8.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.145\n",
      "INFO:tensorflow:loss = 227.18408, step = 7000 (9.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.12\n",
      "INFO:tensorflow:loss = 251.33633, step = 8000 (8.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.912\n",
      "INFO:tensorflow:loss = 216.36395, step = 9000 (8.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.177\n",
      "INFO:tensorflow:loss = 193.74312, step = 10000 (8.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.047\n",
      "INFO:tensorflow:loss = 207.47343, step = 11000 (8.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.254\n",
      "INFO:tensorflow:loss = 233.68915, step = 12000 (8.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.734\n",
      "INFO:tensorflow:loss = 227.6485, step = 13000 (9.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.863\n",
      "INFO:tensorflow:loss = 199.01324, step = 14000 (8.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.095\n",
      "INFO:tensorflow:loss = 193.94823, step = 15000 (8.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.336\n",
      "INFO:tensorflow:loss = 206.08614, step = 16000 (9.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.338\n",
      "INFO:tensorflow:loss = 213.30081, step = 17000 (8.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.343\n",
      "INFO:tensorflow:loss = 216.63687, step = 18000 (8.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.208\n",
      "INFO:tensorflow:loss = 193.69214, step = 19000 (8.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.933\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-25-05:05:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-25-05:05:21\n",
      "INFO:tensorflow:Saving dict for global step 0: average_loss = 13.688485, global_step = 0, label/mean = 3.580709, loss = 1751.7128, mae = 3.5271547, prediction/mean = 0.053553972\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: model_checkpoints/model.ckpt-0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation: average_loss = 13.688485145568848, precision_at_k = 0.02116, step = 20000\n",
      "INFO:tensorflow:loss = 244.22903, step = 20000 (185.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.35889\n",
      "INFO:tensorflow:loss = 212.88522, step = 21000 (9.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.884\n",
      "INFO:tensorflow:loss = 237.43958, step = 22000 (8.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.452\n",
      "INFO:tensorflow:loss = 178.77486, step = 23000 (8.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.995\n",
      "INFO:tensorflow:loss = 203.98067, step = 24000 (8.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.446\n",
      "INFO:tensorflow:loss = 195.33241, step = 25000 (8.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.223\n",
      "INFO:tensorflow:loss = 234.39857, step = 26000 (8.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.021\n",
      "INFO:tensorflow:loss = 213.77669, step = 27000 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.122\n",
      "INFO:tensorflow:loss = 197.28653, step = 28000 (8.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.031\n",
      "INFO:tensorflow:loss = 208.35149, step = 29000 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.083\n",
      "INFO:tensorflow:loss = 202.71048, step = 30000 (8.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.098\n",
      "INFO:tensorflow:loss = 199.31923, step = 31000 (8.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.398\n",
      "INFO:tensorflow:loss = 228.98715, step = 32000 (8.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.217\n",
      "INFO:tensorflow:loss = 207.39502, step = 33000 (8.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.645\n",
      "INFO:tensorflow:loss = 196.88232, step = 34000 (8.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.742\n",
      "INFO:tensorflow:loss = 197.6573, step = 35000 (8.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.805\n",
      "INFO:tensorflow:loss = 181.70306, step = 36000 (8.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.139\n",
      "INFO:tensorflow:loss = 200.24025, step = 37000 (8.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.906\n",
      "INFO:tensorflow:loss = 186.69977, step = 38000 (8.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.188\n",
      "INFO:tensorflow:loss = 227.80116, step = 39000 (8.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.427\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-25-05:11:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-25-05:11:13\n",
      "INFO:tensorflow:Saving dict for global step 0: average_loss = 13.688485, global_step = 0, label/mean = 3.580709, loss = 1751.7128, mae = 3.5271547, prediction/mean = 0.053553972\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: model_checkpoints/model.ckpt-0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation: average_loss = 13.688485145568848, precision_at_k = 0.02116, step = 40000\n",
      "INFO:tensorflow:loss = 238.34875, step = 40000 (186.039 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40002 into model_checkpoints/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.35472\n",
      "INFO:tensorflow:loss = 268.93634, step = 41000 (9.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.917\n",
      "INFO:tensorflow:loss = 217.82895, step = 42000 (8.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.487\n",
      "INFO:tensorflow:loss = 210.91626, step = 43000 (8.970 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.88\n",
      "INFO:tensorflow:loss = 220.82213, step = 44000 (8.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.156\n",
      "INFO:tensorflow:loss = 168.3501, step = 45000 (8.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.036\n",
      "INFO:tensorflow:loss = 214.42038, step = 46000 (8.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.794\n",
      "INFO:tensorflow:loss = 218.62462, step = 47000 (8.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.867\n",
      "INFO:tensorflow:loss = 207.54907, step = 48000 (8.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.824\n",
      "INFO:tensorflow:loss = 154.18506, step = 49000 (8.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.404\n",
      "INFO:tensorflow:loss = 200.54301, step = 50000 (8.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.022\n",
      "INFO:tensorflow:loss = 165.60431, step = 51000 (8.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.745\n",
      "INFO:tensorflow:loss = 209.86362, step = 52000 (9.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.687\n",
      "INFO:tensorflow:loss = 198.30777, step = 53000 (8.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.191\n",
      "INFO:tensorflow:loss = 227.31422, step = 54000 (8.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.779\n",
      "INFO:tensorflow:loss = 202.83058, step = 55000 (8.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.764\n",
      "INFO:tensorflow:loss = 197.31085, step = 56000 (8.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.175\n",
      "INFO:tensorflow:loss = 173.7772, step = 57000 (8.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.637\n",
      "INFO:tensorflow:loss = 185.04987, step = 58000 (9.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.92\n",
      "INFO:tensorflow:loss = 174.70155, step = 59000 (8.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.951\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-25-05:16:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-40002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-25-05:17:04\n",
      "INFO:tensorflow:Saving dict for global step 40002: average_loss = 0.8035008, global_step = 40002, label/mean = 3.580709, loss = 102.82384, mae = 0.7048649, prediction/mean = 3.5821948\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40002: model_checkpoints/model.ckpt-40002\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-40002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation: average_loss = 0.803500771522522, precision_at_k = 0.06313, step = 60000\n",
      "INFO:tensorflow:loss = 184.7662, step = 60000 (185.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.37951\n",
      "INFO:tensorflow:loss = 176.88919, step = 61000 (9.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.283\n",
      "INFO:tensorflow:loss = 195.77837, step = 62000 (8.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.329\n",
      "INFO:tensorflow:loss = 220.4201, step = 63000 (8.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.033\n",
      "INFO:tensorflow:loss = 204.35814, step = 64000 (8.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.591\n",
      "INFO:tensorflow:loss = 183.70642, step = 65000 (8.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.186\n",
      "INFO:tensorflow:loss = 180.07558, step = 66000 (8.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.392\n",
      "INFO:tensorflow:loss = 200.00487, step = 67000 (8.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.328\n",
      "INFO:tensorflow:loss = 187.35892, step = 68000 (8.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.522\n",
      "INFO:tensorflow:loss = 196.31903, step = 69000 (8.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.303\n",
      "INFO:tensorflow:loss = 191.26575, step = 70000 (8.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.547\n",
      "INFO:tensorflow:loss = 201.93205, step = 71000 (8.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.505\n",
      "INFO:tensorflow:loss = 228.29108, step = 72000 (8.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.823\n",
      "INFO:tensorflow:loss = 216.5856, step = 73000 (8.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.862\n",
      "INFO:tensorflow:loss = 216.57153, step = 74000 (8.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.398\n",
      "INFO:tensorflow:loss = 198.69629, step = 75000 (8.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.004\n",
      "INFO:tensorflow:loss = 214.50279, step = 76000 (8.547 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 76188 into model_checkpoints/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 152.22783.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f17f24e8d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "    input_fn=tf_utils.pandas_input_fn(\n",
    "        df=train,\n",
    "        y_col=RATING_COL,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        shuffle=True\n",
    "    ),\n",
    "    hooks=[precision_eval_hook]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We predict the ratings by using the wide-deep model we trained. Finally, we also generate top-k movie recommentation for each user and test the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Item rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-76188\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    250053.000000\n",
       "mean          3.583720\n",
       "std           0.652448\n",
       "min          -0.539153\n",
       "25%           3.167789\n",
       "50%           3.703695\n",
       "75%           4.079504\n",
       "max           5.550684\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = {\n",
    "    'col_user': USER_COL,\n",
    "    'col_item': ITEM_COL,\n",
    "    'col_rating': RATING_COL,\n",
    "    'col_prediction': 'prediction'\n",
    "}\n",
    "\n",
    "predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=test)))\n",
    "prediction_df = test.drop(RATING_COL, axis=1)\n",
    "prediction_df['prediction'] = [p['predictions'][0] for p in predictions]\n",
    "prediction_df['prediction'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t0.892138\n",
      "MAE:\t\t0.702158\n",
      "rsquared:\t0.360975\n",
      "exp var:\t0.360982\n"
     ]
    }
   ],
   "source": [
    "eval_rmse = rmse(test, prediction_df, **cols)\n",
    "eval_mae = mae(test, prediction_df, **cols)\n",
    "eval_rsquared = rsquared(test, prediction_df, **cols)\n",
    "eval_exp_var = exp_var(test, prediction_df, **cols)\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-25-05:58:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-76188\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-25-05:58:16\n",
      "INFO:tensorflow:Saving dict for global step 76188: average_loss = 0.7959096, global_step = 76188, label/mean = 3.580709, loss = 101.852394, mae = 0.7021575, prediction/mean = 3.5837185\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 76188: model_checkpoints/model.ckpt-76188\n",
      "{'average_loss': 0.7959096, 'label/mean': 3.580709, 'loss': 101.852394, 'mae': 0.7021575, 'prediction/mean': 3.5837185, 'global_step': 76188}\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate(\n",
    "    input_fn=tf_utils.pandas_input_fn(\n",
    "        df=test,\n",
    "        y_col=RATING_COL\n",
    "    ),\n",
    "    steps=None\n",
    ")\n",
    "\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recommend k items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-76188\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "MAP:\t0.005812\n",
      "NDCG:\t0.059414\n",
      "Precision@K:\t0.060116\n",
      "Recall@K:\t0.018249\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=ranking_pool)))\n",
    "prediction_df = ranking_pool.copy()\n",
    "prediction_df['prediction'] = [p['predictions'][0] for p in predictions]\n",
    "\n",
    "eval_map = map_at_k(test, prediction_df, k=TOP_K, **cols)\n",
    "eval_ndcg = ndcg_at_k(test, prediction_df, k=TOP_K, **cols)\n",
    "eval_precision = precision_at_k(test, prediction_df, k=TOP_K, **cols)\n",
    "eval_recall = recall_at_k(test, prediction_df, k=TOP_K, **cols)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "To see Tensorboard, open a terminal from this notebook folder, run `tensorboard --logdir=model_checkpoints`, and open http://localhost:6006 from a browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR_BASE = 'saved_model'\n",
    "os.makedirs(EXPORT_DIR_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-76188\n",
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-76188\n",
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1046: calling SavedModelBuilder.add_meta_graph (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from model_checkpoints/model.ckpt-76188\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1548397777'/saved_model.pb\n",
      "Model exported to b'saved_model/1548397777'\n"
     ]
    }
   ],
   "source": [
    "train_rcvr_fn = tf.contrib.estimator.build_supervised_input_receiver_fn_from_input_fn(\n",
    "    tf_utils.pandas_input_fn(\n",
    "        df=train,\n",
    "        y_col=RATING_COL,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        shuffle=True\n",
    "    )\n",
    ")\n",
    "eval_rcvr_fn = tf.contrib.estimator.build_supervised_input_receiver_fn_from_input_fn(\n",
    "    tf_utils.pandas_input_fn(\n",
    "        df=test,\n",
    "        y_col=RATING_COL\n",
    "    )\n",
    ")\n",
    "serve_rcvr_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "    tf.feature_column.make_parse_example_spec(wide_columns+deep_columns)\n",
    ")\n",
    "rcvr_fn_map = {\n",
    "    tf.estimator.ModeKeys.TRAIN: train_rcvr_fn,\n",
    "    tf.estimator.ModeKeys.EVAL: eval_rcvr_fn,\n",
    "    tf.estimator.ModeKeys.PREDICT: serve_rcvr_fn\n",
    "}\n",
    "\n",
    "export_dir = tf.contrib.estimator.export_all_saved_models(\n",
    "    model,\n",
    "    export_dir_base=EXPORT_DIR_BASE,\n",
    "    input_receiver_fn_map=rcvr_fn_map\n",
    ")\n",
    "\n",
    "print(\"Model exported to\", export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpdsko823z\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpdsko823z', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f178b4a0198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Checking available modes for SavedModelEstimator.\n",
      "INFO:tensorflow:Available modes for Estimator: ['train', 'eval', 'infer']\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmpdsko823z, running initialization to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='saved_model/1548397777/variables/variables', vars_to_warm_start=['dnn/hiddenlayer_0/batchnorm_0/beta', 'dnn/hiddenlayer_0/batchnorm_0/beta/Adagrad', 'dnn/hiddenlayer_0/batchnorm_0/gamma', 'dnn/hiddenlayer_0/batchnorm_0/gamma/Adagrad', 'dnn/hiddenlayer_0/batchnorm_0/moving_mean', 'dnn/hiddenlayer_0/batchnorm_0/moving_variance', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/Adagrad', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/Adagrad', 'dnn/hiddenlayer_1/batchnorm_1/beta', 'dnn/hiddenlayer_1/batchnorm_1/beta/Adagrad', 'dnn/hiddenlayer_1/batchnorm_1/gamma', 'dnn/hiddenlayer_1/batchnorm_1/gamma/Adagrad', 'dnn/hiddenlayer_1/batchnorm_1/moving_mean', 'dnn/hiddenlayer_1/batchnorm_1/moving_variance', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/Adagrad', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/Adagrad', 'dnn/hiddenlayer_2/batchnorm_2/beta', 'dnn/hiddenlayer_2/batchnorm_2/beta/Adagrad', 'dnn/hiddenlayer_2/batchnorm_2/gamma', 'dnn/hiddenlayer_2/batchnorm_2/gamma/Adagrad', 'dnn/hiddenlayer_2/batchnorm_2/moving_mean', 'dnn/hiddenlayer_2/batchnorm_2/moving_variance', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/Adagrad', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/Adagrad', 'dnn/input_from_feature_columns/input_layer/MovieId_embedding/embedding_weights', 'dnn/input_from_feature_columns/input_layer/MovieId_embedding/embedding_weights/Adagrad', 'dnn/input_from_feature_columns/input_layer/UserId_embedding/embedding_weights', 'dnn/input_from_feature_columns/input_layer/UserId_embedding/embedding_weights/Adagrad', 'dnn/logits/bias', 'dnn/logits/bias/Adagrad', 'dnn/logits/kernel', 'dnn/logits/kernel/Adagrad', 'global_step', 'linear/linear_model/MovieId_X_UserId/weights', 'linear/linear_model/MovieId_X_UserId/weights/Ftrl', 'linear/linear_model/MovieId_X_UserId/weights/Ftrl_1', 'linear/linear_model/bias_weights', 'linear/linear_model/bias_weights/Ftrl', 'linear/linear_model/bias_weights/Ftrl_1'], var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('saved_model/1548397777/variables/variables',)\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/moving_mean; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/moving_variance; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/moving_mean; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/moving_variance; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/moving_mean; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/moving_variance; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/MovieId_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/UserId_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: global_step; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/MovieId_X_UserId/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/bias_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-25-06:29:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-25-06:29:55\n",
      "INFO:tensorflow:Saving dict for global step 76188: global_step = 76188, loss = 101.852394, metrics/average_loss = 0.7959096, metrics/label/mean = 3.580709, metrics/mae = 0.7021575, metrics/prediction/mean = 3.5837185\n",
      "{'loss': 101.852394, 'metrics/average_loss': 0.7959096, 'metrics/label/mean': 3.580709, 'metrics/mae': 0.7021575, 'metrics/prediction/mean': 3.5837185, 'global_step': 76188}\n"
     ]
    }
   ],
   "source": [
    "saved_model = tf.contrib.estimator.SavedModelEstimator(export_dir)\n",
    "\n",
    "result = saved_model.evaluate(\n",
    "    tf_utils.pandas_input_fn(\n",
    "        df=test,\n",
    "        y_col=RATING_COL\n",
    "    ),\n",
    "    steps=None\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId                                                  4790\n",
       "MovieId                                                 3481\n",
       "Rating                                                     4\n",
       "Genres     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: 382276, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = test.iloc[0]\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmpdsko823z, running initialization to predict.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='saved_model/1548397777/variables/variables', vars_to_warm_start=['dnn/hiddenlayer_0/batchnorm_0/beta', 'dnn/hiddenlayer_0/batchnorm_0/beta/Adagrad', 'dnn/hiddenlayer_0/batchnorm_0/gamma', 'dnn/hiddenlayer_0/batchnorm_0/gamma/Adagrad', 'dnn/hiddenlayer_0/batchnorm_0/moving_mean', 'dnn/hiddenlayer_0/batchnorm_0/moving_variance', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/Adagrad', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/Adagrad', 'dnn/hiddenlayer_1/batchnorm_1/beta', 'dnn/hiddenlayer_1/batchnorm_1/beta/Adagrad', 'dnn/hiddenlayer_1/batchnorm_1/gamma', 'dnn/hiddenlayer_1/batchnorm_1/gamma/Adagrad', 'dnn/hiddenlayer_1/batchnorm_1/moving_mean', 'dnn/hiddenlayer_1/batchnorm_1/moving_variance', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/Adagrad', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/Adagrad', 'dnn/hiddenlayer_2/batchnorm_2/beta', 'dnn/hiddenlayer_2/batchnorm_2/beta/Adagrad', 'dnn/hiddenlayer_2/batchnorm_2/gamma', 'dnn/hiddenlayer_2/batchnorm_2/gamma/Adagrad', 'dnn/hiddenlayer_2/batchnorm_2/moving_mean', 'dnn/hiddenlayer_2/batchnorm_2/moving_variance', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/Adagrad', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/Adagrad', 'dnn/input_from_feature_columns/input_layer/MovieId_embedding/embedding_weights', 'dnn/input_from_feature_columns/input_layer/MovieId_embedding/embedding_weights/Adagrad', 'dnn/input_from_feature_columns/input_layer/UserId_embedding/embedding_weights', 'dnn/input_from_feature_columns/input_layer/UserId_embedding/embedding_weights/Adagrad', 'dnn/logits/bias', 'dnn/logits/bias/Adagrad', 'dnn/logits/kernel', 'dnn/logits/kernel/Adagrad', 'global_step', 'linear/linear_model/MovieId_X_UserId/weights', 'linear/linear_model/MovieId_X_UserId/weights/Ftrl', 'linear/linear_model/MovieId_X_UserId/weights/Ftrl_1', 'linear/linear_model/bias_weights', 'linear/linear_model/bias_weights/Ftrl', 'linear/linear_model/bias_weights/Ftrl_1'], var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('saved_model/1548397777/variables/variables',)\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/moving_mean; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/moving_variance; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/moving_mean; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/moving_variance; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/moving_mean; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/moving_variance; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/MovieId_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/UserId_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: global_step; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/MovieId_X_UserId/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/bias_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'outputs': array([3.8338346], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "def predict_input_fn():\n",
    "    example = tf.train.Example()\n",
    "    \n",
    "    example.features.feature[USER_COL].int64_list.value.extend([test_sample[USER_COL]])\n",
    "    example.features.feature[ITEM_COL].int64_list.value.extend([test_sample[ITEM_COL]])\n",
    "    example.features.feature[ITEM_FEAT_COL].float_list.value.extend(test_sample[ITEM_FEAT_COL])\n",
    "    return {'inputs':tf.constant([example.SerializeToString()])}\n",
    "\n",
    "print(next(saved_model.predict(predict_input_fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "shutil.rmtree(EXPORT_DIR_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-tf-gpu",
   "language": "python",
   "name": "python3-tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
