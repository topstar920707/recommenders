{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM : A Highly Efficient Gradient Boosting Decision Tree\n",
    "This notebook will give you a quick example of how to train LightGBM model in recommendation scenario. \n",
    "LightGBM \\[1\\] is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n",
    "* Faster training speed and higher efficiency.\n",
    "* Lower memory usage.\n",
    "* Better accuracy.\n",
    "* Support of parallel and GPU learning.\n",
    "* Capable of handling large-scale data.\n",
    "\n",
    "In recommendation scenario, LightGBM has a great capability in handling dense numerical features effectively. Therefore, to maximize the performance of LightGBM, we'd better encode the categorical features in data to numerical ones first and then put them into LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "LightGBM version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../../\")\n",
    "import papermill as pm\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "import reco_utils.recommender.lightgbm.lightgbm_utils as lgb_utils\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"LightGBM version: {}\".format(lgb.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Here we use CSV format as the example data input. Our example data is a sample (about 1 million samples) from Criteo dataset [2]. Criteo dataset is a well known industry benchmarking dataset for developing CTR prediction models and it's frequently adopted as evaluation dataset by research papers. The original dataset is too large for a lightweight demo, so we sample a small portion from it as a demo dataset. <br>\n",
    "Specifically, there are 39 columns of features in Criteo, where 13 columns are numerical features (I1-I13) and the other 26 columns are categorical features (C1-C26)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we prepared three files (train_file (first 80\\%), valid_file (middle 10\\%) and test_file (last 10\\%)) in the data root directory , cut from the original data. <br>\n",
    "Notably, considering the Criteo is a kind of time-series streaming data, which is also very common in recommendation scenarion, we split the data by its order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10900000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27c07bd6</td>\n",
       "      <td>4bcc9449</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>87508095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>4f0948e6</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>61f8e249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10900001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>474</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2381.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>99d2d39e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7212cd0a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>a98f5ada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10900002</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155268.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>157482f0</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>e2e82c3c</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>32ebc486</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>e539c901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10900003</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5175.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>395856b0</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>8e4884c0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b936bfbe</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>3464ae5c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10900004</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>775e80fe</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>3ee29a07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>c83e0347</td>\n",
       "      <td>ea9a246c</td>\n",
       "      <td>2fede552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Label   I1   I2     I3    I4        I5    I6    I7    I8  ...  \\\n",
       "0  10900000      1  4.0    0   11.0  11.0      64.0  24.0   9.0  46.0  ...   \n",
       "1  10900001      0  0.0  474   18.0  18.0    2381.0  25.0  49.0  25.0  ...   \n",
       "2  10900002      0  NaN   -1    4.0   2.0  155268.0   NaN   0.0   3.0  ...   \n",
       "3  10900003      0  NaN    2   20.0  14.0    5175.0  57.0   4.0  27.0  ...   \n",
       "4  10900004      0  1.0   87  105.0   5.0       8.0   5.0   7.0   6.0  ...   \n",
       "\n",
       "        C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0  27c07bd6  4bcc9449  21ddcdc9  b1252a9d  87508095       NaN  c7dc6720   \n",
       "1  3486227d  99d2d39e       NaN       NaN  7212cd0a       NaN  423fab69   \n",
       "2  1e88c74f  157482f0  21ddcdc9  b1252a9d  e2e82c3c  ad3062eb  3a171ecb   \n",
       "3  07c540c4  395856b0  21ddcdc9  a458ea53  8e4884c0       NaN  32c7478e   \n",
       "4  8efede7f  775e80fe  21ddcdc9  a458ea53  3ee29a07       NaN  423fab69   \n",
       "\n",
       "        C24       C25       C26  \n",
       "0  4f0948e6  e8b83407  61f8e249  \n",
       "1  a98f5ada       NaN       NaN  \n",
       "2  32ebc486  001f3601  e539c901  \n",
       "3  b936bfbe  001f3601  3464ae5c  \n",
       "4  c83e0347  ea9a246c  2fede552  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = '../../tests/resources/lightgbm'\n",
    "train_file = os.path.join(data_path, r'tiny_criteo0.csv')\n",
    "valid_file = os.path.join(data_path, r'tiny_criteo1.csv')\n",
    "test_file = os.path.join(data_path, r'tiny_criteo2.csv')\n",
    "output_file = os.path.join(data_path, r'output.txt')\n",
    "\n",
    "if not os.path.exists(train_file):\n",
    "    # to do: upload our test resources.\n",
    "    download_lgb_resources(r'https://recodatasets.blob.core.windows.net/lightgbm/', data_path, 'resources.zip')\n",
    "\n",
    "test_data = pd.read_csv(test_file)\n",
    "display(test_data.head())\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sencod, we convert categorical features in original data into numerical ones, by label-encoding [3] and binary-encoding [4]. Also due to the time series property of Criteo, the label-encoding we adopted is executed one-by-one, which means we encode the samples in order, by the information of the former samples before each sample (you can consult the dynamical target encoding codes in `lgb_utils.NumEncoder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Fitting and Transforming ../../tests/resources/lightgbm/tiny_criteo0.csv .\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-01 08:32:33,751 [INFO] Filtering and fillna features\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:10<00:00,  2.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.78it/s]\n",
      "2019-03-01 08:32:45,217 [INFO] Ordinal encoding cate features\n",
      "2019-03-01 08:33:00,647 [INFO] Target encoding cate features\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:43<00:00,  1.66s/it]\n",
      "2019-03-01 08:33:44,348 [INFO] Start manual binary encoding\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:12<00:00,  3.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:18<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Transforming ../../tests/resources/lightgbm/tiny_criteo1.csv .\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-01 08:34:15,609 [INFO] Filtering and fillna features\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00, 24.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1009.52it/s]\n",
      "2019-03-01 08:34:16,690 [INFO] Ordinal encoding cate features\n",
      "2019-03-01 08:34:18,345 [INFO] Target encoding cate features\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:05<00:00,  5.23it/s]\n",
      "2019-03-01 08:34:23,356 [INFO] Start manual binary encoding\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:04<00:00, 15.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Transforming ../../tests/resources/lightgbm/tiny_criteo2.csv .\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-01 08:34:31,263 [INFO] Filtering and fillna features\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00, 24.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1107.42it/s]\n",
      "2019-03-01 08:34:32,341 [INFO] Ordinal encoding cate features\n",
      "2019-03-01 08:34:34,021 [INFO] Target encoding cate features\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:04<00:00,  5.33it/s]\n",
      "2019-03-01 08:34:38,989 [INFO] Start manual binary encoding\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:04<00:00, 15.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: X: (800000, 303); Y: (800000, 1).\n",
      "Valid Data Shape: X: (100000, 303); Y: (100000, 1).\n",
      "Test Data Shape: X: (100000, 303); Y: (100000, 1).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cate_cols = ['C'+str(i) for i in range(1, 27)]\n",
    "nume_cols = ['I'+str(i) for i in range(1, 14)]\n",
    "label_col = 'Label'\n",
    "num_encoder = lgb_utils.NumEncoder(cate_cols, nume_cols, label_col)\n",
    "train_x, train_y = num_encoder.fit_transform(train_file)\n",
    "valid_x, valid_y = num_encoder.transform(valid_file)\n",
    "test_x, test_y = num_encoder.transform(test_file)\n",
    "del num_encoder\n",
    "print('Train Data Shape: X: {trn_x_shape}; Y: {trn_y_shape}.\\nValid Data Shape: X: {vld_x_shape}; Y: {vld_y_shape}.\\nTest Data Shape: X: {tst_x_shape}; Y: {tst_y_shape}.\\n'\n",
    "      .format(trn_x_shape=train_x.shape,\n",
    "              trn_y_shape=train_y.shape,\n",
    "              vld_x_shape=valid_x.shape,\n",
    "              vld_y_shape=valid_y.shape,\n",
    "              tst_x_shape=test_x.shape,\n",
    "              tst_y_shape=test_y.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setting\n",
    "After data preparation, let's set the primary related parameters for LightGBM now. Basically, the task is a binary classification, so the objective function is set to binary loss.\n",
    "\n",
    "Generally, we can adjust the number of leaves (MAX_LEAF), minimum number of datas in each leaf (MIN_DATA), number o trees (NUM_OF_TREES), the learning rate of trees (TREE_LEARINING_RATE) and EARLY_STOPPING_ROUNDS (to avoid overfitting) in the model to get better performance.\n",
    "\n",
    "Besides, we can also try some other listed paramters in the following to optimize the results, which are listed in [5] concretely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MAX_LEAF = 128\n",
    "MIN_DATA = 40\n",
    "NUM_OF_TREES = 200\n",
    "TREE_LEARNING_RATE = 0.15\n",
    "EARLY_STOPPING_ROUNDS = 20\n",
    "METRIC = \"auc\"\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_class': 1,\n",
    "    'objective': \"binary\",\n",
    "    'metric': METRIC,\n",
    "    'num_leaves': MAX_LEAF,\n",
    "    'min_data': MIN_DATA,\n",
    "    'boost_from_average': True,\n",
    "    'num_threads': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_freq': 3,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'learning_rate': TREE_LEARNING_RATE,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "When both hyper-parameters and data are ready, we can create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.747287\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's auc: 0.754357\n",
      "[3]\tvalid_0's auc: 0.758606\n",
      "[4]\tvalid_0's auc: 0.760637\n",
      "[5]\tvalid_0's auc: 0.762482\n",
      "[6]\tvalid_0's auc: 0.763813\n",
      "[7]\tvalid_0's auc: 0.76506\n",
      "[8]\tvalid_0's auc: 0.765835\n",
      "[9]\tvalid_0's auc: 0.766965\n",
      "[10]\tvalid_0's auc: 0.767588\n",
      "[11]\tvalid_0's auc: 0.768471\n",
      "[12]\tvalid_0's auc: 0.769421\n",
      "[13]\tvalid_0's auc: 0.770194\n",
      "[14]\tvalid_0's auc: 0.7709\n",
      "[15]\tvalid_0's auc: 0.771585\n",
      "[16]\tvalid_0's auc: 0.772365\n",
      "[17]\tvalid_0's auc: 0.773133\n",
      "[18]\tvalid_0's auc: 0.773704\n",
      "[19]\tvalid_0's auc: 0.774298\n",
      "[20]\tvalid_0's auc: 0.774892\n",
      "[21]\tvalid_0's auc: 0.775447\n",
      "[22]\tvalid_0's auc: 0.775945\n",
      "[23]\tvalid_0's auc: 0.776312\n",
      "[24]\tvalid_0's auc: 0.776671\n",
      "[25]\tvalid_0's auc: 0.776938\n",
      "[26]\tvalid_0's auc: 0.777283\n",
      "[27]\tvalid_0's auc: 0.777533\n",
      "[28]\tvalid_0's auc: 0.777917\n",
      "[29]\tvalid_0's auc: 0.778465\n",
      "[30]\tvalid_0's auc: 0.778753\n",
      "[31]\tvalid_0's auc: 0.779115\n",
      "[32]\tvalid_0's auc: 0.779296\n",
      "[33]\tvalid_0's auc: 0.779497\n",
      "[34]\tvalid_0's auc: 0.77971\n",
      "[35]\tvalid_0's auc: 0.780057\n",
      "[36]\tvalid_0's auc: 0.780521\n",
      "[37]\tvalid_0's auc: 0.780795\n",
      "[38]\tvalid_0's auc: 0.780846\n",
      "[39]\tvalid_0's auc: 0.781034\n",
      "[40]\tvalid_0's auc: 0.781189\n",
      "[41]\tvalid_0's auc: 0.781388\n",
      "[42]\tvalid_0's auc: 0.781612\n",
      "[43]\tvalid_0's auc: 0.781818\n",
      "[44]\tvalid_0's auc: 0.781952\n",
      "[45]\tvalid_0's auc: 0.782092\n",
      "[46]\tvalid_0's auc: 0.782183\n",
      "[47]\tvalid_0's auc: 0.78232\n",
      "[48]\tvalid_0's auc: 0.782466\n",
      "[49]\tvalid_0's auc: 0.782594\n",
      "[50]\tvalid_0's auc: 0.782698\n",
      "[51]\tvalid_0's auc: 0.782747\n",
      "[52]\tvalid_0's auc: 0.782899\n",
      "[53]\tvalid_0's auc: 0.783041\n",
      "[54]\tvalid_0's auc: 0.783091\n",
      "[55]\tvalid_0's auc: 0.783154\n",
      "[56]\tvalid_0's auc: 0.783312\n",
      "[57]\tvalid_0's auc: 0.783476\n",
      "[58]\tvalid_0's auc: 0.783513\n",
      "[59]\tvalid_0's auc: 0.783578\n",
      "[60]\tvalid_0's auc: 0.783476\n",
      "[61]\tvalid_0's auc: 0.78348\n",
      "[62]\tvalid_0's auc: 0.783594\n",
      "[63]\tvalid_0's auc: 0.78367\n",
      "[64]\tvalid_0's auc: 0.783702\n",
      "[65]\tvalid_0's auc: 0.783746\n",
      "[66]\tvalid_0's auc: 0.783782\n",
      "[67]\tvalid_0's auc: 0.783816\n",
      "[68]\tvalid_0's auc: 0.783857\n",
      "[69]\tvalid_0's auc: 0.783887\n",
      "[70]\tvalid_0's auc: 0.783929\n",
      "[71]\tvalid_0's auc: 0.783963\n",
      "[72]\tvalid_0's auc: 0.783974\n",
      "[73]\tvalid_0's auc: 0.784126\n",
      "[74]\tvalid_0's auc: 0.784122\n",
      "[75]\tvalid_0's auc: 0.784166\n",
      "[76]\tvalid_0's auc: 0.784194\n",
      "[77]\tvalid_0's auc: 0.784181\n",
      "[78]\tvalid_0's auc: 0.784159\n",
      "[79]\tvalid_0's auc: 0.78418\n",
      "[80]\tvalid_0's auc: 0.784182\n",
      "[81]\tvalid_0's auc: 0.784128\n",
      "[82]\tvalid_0's auc: 0.784137\n",
      "[83]\tvalid_0's auc: 0.784153\n",
      "[84]\tvalid_0's auc: 0.784112\n",
      "[85]\tvalid_0's auc: 0.784114\n",
      "[86]\tvalid_0's auc: 0.7841\n",
      "[87]\tvalid_0's auc: 0.784122\n",
      "[88]\tvalid_0's auc: 0.784129\n",
      "[89]\tvalid_0's auc: 0.78417\n",
      "[90]\tvalid_0's auc: 0.784135\n",
      "[91]\tvalid_0's auc: 0.784152\n",
      "[92]\tvalid_0's auc: 0.784202\n",
      "[93]\tvalid_0's auc: 0.784218\n",
      "[94]\tvalid_0's auc: 0.78422\n",
      "[95]\tvalid_0's auc: 0.784246\n",
      "[96]\tvalid_0's auc: 0.784221\n",
      "[97]\tvalid_0's auc: 0.784213\n",
      "[98]\tvalid_0's auc: 0.784225\n",
      "[99]\tvalid_0's auc: 0.784256\n",
      "[100]\tvalid_0's auc: 0.784257\n",
      "[101]\tvalid_0's auc: 0.784225\n",
      "[102]\tvalid_0's auc: 0.784213\n",
      "[103]\tvalid_0's auc: 0.784185\n",
      "[104]\tvalid_0's auc: 0.784198\n",
      "[105]\tvalid_0's auc: 0.784164\n",
      "[106]\tvalid_0's auc: 0.784146\n",
      "[107]\tvalid_0's auc: 0.784164\n",
      "[108]\tvalid_0's auc: 0.784193\n",
      "[109]\tvalid_0's auc: 0.784203\n",
      "[110]\tvalid_0's auc: 0.784203\n",
      "[111]\tvalid_0's auc: 0.784254\n",
      "[112]\tvalid_0's auc: 0.784298\n",
      "[113]\tvalid_0's auc: 0.784255\n",
      "[114]\tvalid_0's auc: 0.784254\n",
      "[115]\tvalid_0's auc: 0.784291\n",
      "[116]\tvalid_0's auc: 0.784272\n",
      "[117]\tvalid_0's auc: 0.784282\n",
      "[118]\tvalid_0's auc: 0.784341\n",
      "[119]\tvalid_0's auc: 0.784397\n",
      "[120]\tvalid_0's auc: 0.784431\n",
      "[121]\tvalid_0's auc: 0.784381\n",
      "[122]\tvalid_0's auc: 0.784407\n",
      "[123]\tvalid_0's auc: 0.784424\n",
      "[124]\tvalid_0's auc: 0.784427\n",
      "[125]\tvalid_0's auc: 0.784425\n",
      "[126]\tvalid_0's auc: 0.784425\n",
      "[127]\tvalid_0's auc: 0.784453\n",
      "[128]\tvalid_0's auc: 0.78443\n",
      "[129]\tvalid_0's auc: 0.784433\n",
      "[130]\tvalid_0's auc: 0.78443\n",
      "[131]\tvalid_0's auc: 0.784442\n",
      "[132]\tvalid_0's auc: 0.784414\n",
      "[133]\tvalid_0's auc: 0.784477\n",
      "[134]\tvalid_0's auc: 0.784494\n",
      "[135]\tvalid_0's auc: 0.784503\n",
      "[136]\tvalid_0's auc: 0.784469\n",
      "[137]\tvalid_0's auc: 0.784463\n",
      "[138]\tvalid_0's auc: 0.784467\n",
      "[139]\tvalid_0's auc: 0.78442\n",
      "[140]\tvalid_0's auc: 0.784416\n",
      "[141]\tvalid_0's auc: 0.784416\n",
      "[142]\tvalid_0's auc: 0.784373\n",
      "[143]\tvalid_0's auc: 0.784341\n",
      "[144]\tvalid_0's auc: 0.78433\n",
      "[145]\tvalid_0's auc: 0.78434\n",
      "[146]\tvalid_0's auc: 0.784373\n",
      "[147]\tvalid_0's auc: 0.784352\n",
      "[148]\tvalid_0's auc: 0.78434\n",
      "[149]\tvalid_0's auc: 0.784301\n",
      "[150]\tvalid_0's auc: 0.784234\n",
      "[151]\tvalid_0's auc: 0.784225\n",
      "[152]\tvalid_0's auc: 0.784237\n",
      "[153]\tvalid_0's auc: 0.784191\n",
      "[154]\tvalid_0's auc: 0.784148\n",
      "[155]\tvalid_0's auc: 0.784088\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.784503\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(train_x, train_y.reshape(-1), params=params)\n",
    "lgb_eval = lgb.Dataset(valid_x, valid_y.reshape(-1), reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=NUM_OF_TREES,\n",
    "                early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                valid_sets=lgb_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what is the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.7831, 'logloss': 0.4598}\n"
     ]
    }
   ],
   "source": [
    "test_preds = gbm.predict(test_x)\n",
    "print(lgb_utils.cal_metric(test_y.reshape(-1), test_preds, ['auc','logloss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model saving and loading\n",
    "Now we finish the basic training and testing for LightGBM, next let's try to save and reload the model, and then evaluate it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.7831, 'logloss': 0.4598}\n"
     ]
    }
   ],
   "source": [
    "save_file = os.path.join(data_path, r'finished.model')\n",
    "gbm.save_model(save_file)\n",
    "gbm = lgb.Booster(model_file=save_file)\n",
    "\n",
    "# eval the performance again\n",
    "test_preds = gbm.predict(test_x)\n",
    "print(lgb_utils.cal_metric(test_y.reshape(-1), test_preds, ['auc','logloss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\\[1\\] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. LightGBM: A highly efficient gradient boosting decision tree. In Advances in Neural Information Processing Systems. 3146â€“3154.<br>\n",
    "\\[2\\] The Criteo datasets: http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/ .<br>\n",
    "\\[3\\] Anna Veronika Dorogush, Vasily Ershov, and Andrey Gulin. 2018. CatBoost: gradient boosting with categorical features support. arXiv preprint arXiv:1810.11363 (2018).<br>\n",
    "\\[4\\] Scikit-learn. 2018. categorical_encoding. https://github.com/scikit-learn-contrib/categorical-encoding .<br>\n",
    "\\[5\\] The parameters of LightGBM: https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst ."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (reco)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
