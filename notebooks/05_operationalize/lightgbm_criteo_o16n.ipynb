{"cells":[{"cell_type":"markdown","source":["Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."],"metadata":{}},{"cell_type":"markdown","source":["## Goal\n\nThis notebook creates a scalable real-time scoring service for the Spark based models such as the Content Based Personaliation moel trained in the [MMLSpark-LightGBM-Criteo notebook](../02_model/mmlspark_lightgbm_criteo.ipynb)."],"metadata":{}},{"cell_type":"markdown","source":["## Assumptions\nIn order to execute this notebook the following items are assumed:\n\n1. A model has previously been trained as shown in the [mmlspark_lightgbm_criteo](../02_model/mmlspark_lightgbm_criteo.ipynb) notebook\n2. This notebook is running in the same Azure Databricks workspace used to train and save the model\n3. The Databricks cluster used has been prepared for operationalization (MML Spark and reco_utils are both installed)\n  - See [Setup](https://github.com/Microsoft/Recommenders/blob/master/SETUP.md) instructions for details\n4. An Azure Machine Learning Service workspace has been setup in the same region as the Azure Databricks workspace used for model training\n  - See [Create A Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/setup-create-workspace) for more details\n5. The Azure ML Workspace config.json has been uploaded to databrics at dbfs:/aml_config/config.json\n  - See [Configure Environment](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment) and [Databricks CLI](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html#access-dbfs-with-the-databricks-cli)\n6. An Azure Container Instance (ACI) has been registered for use your Azure subscription\n  - See [Supported Services](https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-supported-services#portal) for more details"],"metadata":{}},{"cell_type":"markdown","source":["### Setup libraries and variables\n\nThe next few cells initialize the environment and varibles: we import relevant libraries and set variables."],"metadata":{}},{"cell_type":"code","source":["import os\nimport json\nimport shutil\n\nfrom reco_utils.dataset.criteo import get_spark_schema, load_spark_df\n\nfrom azureml.core import Workspace\nfrom azureml.core import VERSION as azureml_version\n\nfrom azureml.core.model import Model\nfrom azureml.core.conda_dependencies import CondaDependencies \nfrom azureml.core.webservice import Webservice, AksWebservice\nfrom azureml.core.image import ContainerImage\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n\n# Check core SDK version number\nprint(\"Azure ML SDK version: {}\".format(azureml_version))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Azure ML SDK version: 1.0.21\n</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["## Prepare Assets for the Scoring Service\n\nBefore walking through the steps taken to create setup the service, it is useful to set some context. In our example, a \"scoring service\" is a function that is executed by a docker container. It takes in post request with JSON formatted payload and produces a score based on a previously estimated model. In our case, we will take the model we estimated earlier that predicts the probability of an user-item interaction based on a set of numeric and categorical features. <br><br>\n\nIn order to create a scoring service, we will do the following steps:\n\n1. Setup and authorize the Azure Machine Learning Workspace\n2. Serialize the previously trained model and add it to the Azure Model Registry\n3. Define the 'scoring service' script to execute the model\n4. Define all the pre-requisites that that script requires\n5. Use the model, the driver script, and the pre-requisites to create a Azure Container Image\n6. Deploy the container image on a scalable platform Azure Kubernetes Service\n7. Test the service"],"metadata":{}},{"cell_type":"code","source":["MODEL_NAME = 'lightgbm_criteo.mml'  # this name must exactly match the name used to save the pipeline model in the estimation notebook\nMODEL_DESCRIPTION = 'LightGBM Criteo Model'\n\n# Setup AzureML assets (names must be lower case alphanumeric without spaces and between 3 and 32 characters)\n# Azure ML Webservice\nSERVICE_NAME = 'lightgbm-criteo'\n# Azure ML Container Image\nCONTAINER_NAME = 'lightgbm-criteo'\nCONTAINER_RUN_TIME = 'spark-PY'\n# Azure AKS Service\nAKS_NAME = 'predict-aks'\n\n# Names of other files that are used below\nCONDA_FILE = \"deploy_conda.yaml\"\nDRIVER_FILE = \"mmlspark_serving.py\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## Setup AzureML Workspace\nWorkspace configuration can be retrieved from the portal and uploaded to Databricks<br>\nSee [AzureML on Databricks](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment#azure-databricks)"],"metadata":{}},{"cell_type":"code","source":["ws = Workspace.from_config('/dbfs/aml_config/config.json')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Found the config file in: /dbfs/aml_config/config.json\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AYP4LT73Y to authenticate.\nInteractive authentication successfully completed.\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["## Prepare the Serialized Model\nSpark Serving needs the schema of the raw input data so an additional file is added to the model directory.<br>"],"metadata":{}},{"cell_type":"code","source":["### MAKE THIS METHOD PUBLIC WITH DEFAULT HEADER ###\nraw_schema = get_spark_schema()\nwith open(os.path.join('/dbfs', MODEL_NAME, 'schema.json'), 'w') as f:\n  f.write(raw_schema.json())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### Copy from dbfs to local\n\nWhile you can access files on DBFS with local file APIs, it is safer to explicitly copy saved models to and from dbfs, because the local file APIs can only access files smaller than 2 GB (see details [here](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html#access-dbfs-using-local-file-apis))."],"metadata":{}},{"cell_type":"code","source":["model_local = os.path.join(os.getcwd(), MODEL_NAME)\ndbutils.fs.cp('dbfs:/' + MODEL_NAME, 'file:' + model_local, recurse=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["### Register the Model\n\nNext, we need to register the model in the Azure Machine Learning Workspace."],"metadata":{}},{"cell_type":"code","source":["# First the model directory is compressed to minimize data transfer\nzip_file = shutil.make_archive(base_name=MODEL_NAME, format='zip', root_dir=model_local)\n\n# Register the model\nmodel = Model.register(model_path=zip_file,  # this points to a local file\n                       model_name=MODEL_NAME,  # this is the name the model is registered as\n                       description=MODEL_DESCRIPTION,\n                       workspace=ws)\n\nprint(model.name, model.description, model.version)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model lightgbm_criteo.mml\nlightgbm_criteo.mml LightGBM Criteo Model 4\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["## Define the Scoring Script\n\nNext we, need to create the driver script that will be executed when the service is called. The functions that need to be defined for scoring are `init()` and `run()`. The `init()` function is run when the service is created, and the `run()` function is run each time the service is called.\n\nIn our example, we use the `init()` function to load all the libraries, initialize the spark session, start the spark streaming service and load the model pipeline. We use the `run()` method to route the input to the spark streaming service to generate predictions (in this case the probability of an interaction) then return the output."],"metadata":{}},{"cell_type":"code","source":["driver_file = '''\nimport os\nimport json\nfrom time import sleep\nfrom uuid import uuid4\nfrom zipfile import ZipFile\n\nfrom azureml.core.model import Model\nfrom pyspark.ml import PipelineModel\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType\nimport requests\n\n\ndef init():\n    \"\"\"One time initialization of pyspark and model server\"\"\"\n\n    spark = SparkSession.builder.appName(\"Model Server\").getOrCreate()\n    import mmlspark\n\n    # extract and load model\n    model_path = Model.get_model_path('{model_name}')\n    with ZipFile(model_path, 'r') as f:\n        f.extractall('model')\n    model = PipelineModel.load('model')\n\n    # load data schema saved with model\n    with open(os.path.join('model', 'schema.json'), 'r') as f:\n        schema = StructType.fromJson(json.load(f))\n\n    input_df = (\n        spark.readStream.continuousServer()\n        .address(\"localhost\", 8089, \"predict\")\n        .load()\n        .parseRequest(schema)\n    )\n\n    output_df = (\n        model.transform(input_df)\n        .makeReply(\"probability\")\n    )\n\n    checkpoint = os.path.join('/tmp', 'checkpoints', uuid4().hex)\n    server = (\n        output_df.writeStream.continuousServer()\n        .trigger(continuous=\"1 second\")\n        .replyTo(\"predict\")\n        .queryName(\"prediction\")\n        .option(\"checkpointLocation\", checkpoint)\n        .start()\n    )\n\n    # let the server finish starting\n    sleep(1)\n\n\ndef run(input_json):\n    try:\n        response = requests.post(data=input_json, url='http://localhost:8089/predict')\n        result = response.json()['probability']['values'][1]\n    except Exception as e:\n        result = str(e)\n    \n    return json.dumps({{\"result\": result}})\n    \n'''.format(model_name=MODEL_NAME)\n\n# check syntax\nexec(driver_file)\n\nwith open(DRIVER_FILE, \"w\") as f:\n    f.write(driver_file)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["## 4. Define Dependencies\n\nNext, we define the dependencies that are required by driver script."],"metadata":{}},{"cell_type":"code","source":["# azureml-sdk is required to load the registered model\nconda_file = CondaDependencies.create(pip_packages=['azureml-sdk', 'requests']).serialize_to_string()\n\nwith open(CONDA_FILE, \"w\") as f:\n    f.write(conda_file)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["## 5. Create the Image\n\nWe use the `ContainerImage` class to first configure the image with the defined driver and dependencies, then to create the image for use later.<br>\nBuilding the image allows it to be downloaded and debugged locally using docker, see [troubleshooting instructions](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-troubleshoot-deployment)"],"metadata":{}},{"cell_type":"code","source":["image_config = ContainerImage.image_configuration(execution_script=DRIVER_FILE, \n                                                  runtime=CONTAINER_RUN_TIME,\n                                                  conda_file=CONDA_FILE,\n                                                  tags={\"runtime\":CONTAINER_RUN_TIME, \"model\": MODEL_NAME})\n\nimage = ContainerImage.create(name=SERVICE_NAME,\n                              models=[model],\n                              image_config=image_config,\n                              workspace=ws)\n\nimage.wait_for_creation(show_output=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating image\nRunning......................\nSucceededImage creation operation finished for image lightgbm-criteo:3, operation &quot;Succeeded&quot;\n</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["## 6. Create the Service\n\nOnce we have created an image, we configure an AKS cluster and deploy the image as a AKS Webservice.\n\n**NOTE** You *can* create a service directly from the registered model and image_configuration with the `Webservice.deploy_from_model()` function. We create the image here explicitly and use `deploy_from_image()` for two reasons:\n\n1. It provides more transparency in terms of the actual steps that are taking place\n2. It has potential for faster iteration and for more portability. Once we have an image, we can create a new deployment with the exact same code."],"metadata":{}},{"cell_type":"code","source":["# Create AKS compute first\n\n# Use the default configuration (can also provide parameters to customize)\nprov_config = AksCompute.provisioning_configuration()\n\n# Create the cluster\naks_target = ComputeTarget.create(\n  workspace=ws, \n  name=AKS_NAME, \n  provisioning_configuration=prov_config\n)\n\naks_target.wait_for_completion(show_output=True)\n\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Set the web service configuration (using default here)\naks_config = AksWebservice.deploy_configuration()\n\n# Deploy service using created image\naks_service = Webservice.deploy_from_image(\n  workspace=ws, \n  name=SERVICE_NAME,\n  deployment_config=aks_config,\n  image=image,\n  deployment_target=aks_target\n)\n\naks_service.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["## 7. Test the Service\n\nNext, we can use data from the `test` data to test the service.\n\nThe service expects JSON as its payload, so we take the test data, fill missing values, convert to JSON, then submit to the service endpoint.\n\nWe have to fill in missing values here to create the data, because the webservice expects that the data coming into the webservice is well-formed."],"metadata":{}},{"cell_type":"code","source":["# View the URI\nurl = aks_service.scoring_uri\nprint('AKS URI: {}'.format(url))\n\n# Setup authentication using one of the keys from aks_service\nheaders = dict(Authorization='Bearer {}'.format(aks_service.get_keys()[0]))"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Grab some sample data\ndf = load_spark_df(size='sample', spark=spark, dbutils=dbutils)\ndata = df.head().asDict()\nprint(data)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Send a request to the AKS cluster\nresponse = requests.post(url=url, json=data, headers=headers)\nprint(response.json())"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["### Delete the Service\n\nWhen you are done, you can delete the service to minimize costs. You can always redeploy from the image using the same command above."],"metadata":{}},{"cell_type":"code","source":["# Uncomment the following line to delete the web service\n# aks_service.delete()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":["aks_service.state"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>&apos;Deleting&apos;\n</div>"]}}],"execution_count":31}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.8","nbconvert_exporter":"python","file_extension":".py"},"name":"deploy-to-aci-04","notebookId":904892461294324,"kernelspec":{"display_name":"Python (reco_base)","language":"python","name":"reco_base"},"authors":[{"name":"pasha"}]},"nbformat":4,"nbformat_minor":0}
