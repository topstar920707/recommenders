{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operationalization of ALS on Azure AKS and ACI with Databricks\n",
    "\n",
    "In this notebook we showcase how to train the recommendation algorithm ALS on Azure Databricks and operationalize it using Azure ML Service and Azure Kubernetes (AKS). \n",
    "\n",
    "This notebook is based on [this repository](https://github.com/dciborow/DB-Recs) by Daniel Ciborowski, dciborow@microsoft.com.\n",
    "\n",
    "##### Setup\n",
    "* Create a new Databricks cluster, using this configuration: `DB 4.1, Spark 2.3.0, Python3`.\n",
    "* Attach the following PyPi libraries to the custer. [See here for help adding a library.](https://docs.databricks.com/user-guide/libraries.html).\n",
    "    * Add Azure-cli via pypi: `azure-cli`.\n",
    "    * Add AzureML via Pypi: `azureml-sdk[databricks]`.\n",
    "    * Add pydocumentdb via Pypi: `pydocumentdb`.\n",
    "* Attach CosmosDB uber jar to the library. The jar can downloaded at https://search.maven.org/artifact/com.microsoft.azure/azure-cosmosdb-spark_2.3.0_2.11/1.2.2/jar. Make sure you download the uber version.\n",
    "* Add this repository utilies to the cluster as detailed in the [SETUP.md](../../SETUP.md##setup-guide-for-azure-databricks).\n",
    "\n",
    "\n",
    "##### This notebook is broken down into four sections.\n",
    "1. Service Creation\n",
    "1. Training\n",
    "1. Scoring\n",
    "1. Operationalization\n",
    "\n",
    "##### The following Azure services will be deployed into a new or existing resource group.\n",
    "1. [Azure ML Service](https://docs.databricks.com/user-guide/libraries.html)\n",
    "1. [Cosmos DB](https://azure.microsoft.com/en-us/services/cosmos-db/)\n",
    "1. [Container Registery](https://docs.microsoft.com/en-us/azure/container-registry/)\n",
    "1. [Container Instances](https://docs.microsoft.com/en-us/azure/container-instances/)\n",
    "1. [Application Insights](https://azure.microsoft.com/en-us/services/monitor/)\n",
    "1. [Storage Account](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview)\n",
    "1. [Key Vault](https://azure.microsoft.com/en-us/services/key-vault/)\n",
    "1. [Azure Container Instances (ACI)](https://azure.microsoft.com/en-us/services/container-instances/)\n",
    "1. [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import shutil\n",
    "import time, timeit\n",
    "import urllib\n",
    "import yaml\n",
    "import json\n",
    "import uuid\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from azure.common.client_factory import get_client_from_cli_profile\n",
    "from azure.mgmt.compute import ComputeManagementClient\n",
    "import azure.mgmt.cosmosdb\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "import pydocumentdb\n",
    "import pydocumentdb.document_client as document_client\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from reco_utils.dataset.cosmos_cli import find_collection, read_collection, read_database, find_database\n",
    "from reco_utils.dataset.spark_splitters import spark_random_split\n",
    "\n",
    "print(\"PySpark version:\", pyspark.__version__)\n",
    "print(\"Azure SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Service Creation\n",
    "Modify the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the services names\n",
    "short_uuid = str(uuid.uuid4())[:4]\n",
    "prefix = \"reco\" + short_uuid\n",
    "data = \"mvl\"\n",
    "algo = \"als\"\n",
    "\n",
    "# Add your subscription ID\n",
    "subscription_id = \"XXXXXXXXXXXXXXXXXX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource group and workspace\n",
    "resource_group = prefix + \"_\" + data\n",
    "workspace_name = prefix + \"_\"+data+\"_aml\"\n",
    "workspace_region = \"westus2\"\n",
    "print(\"Resource group:\", resource_group)\n",
    "\n",
    "# Columns\n",
    "userCol = \"UserId\"\n",
    "itemCol = \"MovieId\"\n",
    "ratingCol = \"Rating\"\n",
    "userColIndex = userCol.replace(\"Id\",\"Index\")\n",
    "itemColIndex = itemCol.replace(\"Id\",\"Index\")\n",
    "\n",
    "# CosmosDB\n",
    "location = workspace_region\n",
    "account_name = prefix + \"-\" + data + \"-ds-sql\"\n",
    "DOCUMENTDB_DATABASE = \"recommendations\"\n",
    "DOCUMENTDB_COLLECTION = \"user_recommendations_\" + algo\n",
    "\n",
    "# AzureML\n",
    "history_name = 'spark-ml-notebook'\n",
    "model_name = data+\"-\"+algo+\"-reco.mml\" #NOTE: The name of a asset must be only letters or numerals, not contain spaces, and under 30 characters\n",
    "service_name = data + \"-\" + algo\n",
    "experiment_name = data + \"_\"+ algo +\"_Experiment\"\n",
    "\n",
    "train_data_path = data + \"Train\"\n",
    "test_data_path = data + \"Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Workspace class and check the azureml SDK version. The variable `exist_ok` checks if the workspace exists or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      exist_ok=True)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_client_from_cli_profile(azure.mgmt.cosmosdb.CosmosDB)\n",
    "\n",
    "async_cosmosdb_create = client.database_accounts.create_or_update(\n",
    "    resource_group,\n",
    "    account_name,\n",
    "    {\n",
    "        'location': location,\n",
    "        'locations': [{\n",
    "            'location_name': location\n",
    "        }]\n",
    "    }\n",
    ")\n",
    "account = async_cosmosdb_create.result()\n",
    "\n",
    "my_keys = client.database_accounts.list_keys(\n",
    "    resource_group,\n",
    "    account_name\n",
    ")\n",
    "\n",
    "master_key = my_keys.primary_master_key\n",
    "endpoint = \"https://\" + account_name + \".documents.azure.com:443/\"\n",
    "\n",
    "#db client\n",
    "client = document_client.DocumentClient(endpoint, {'masterKey': master_key})\n",
    "\n",
    "if find_database(client, DOCUMENTDB_DATABASE) == False:\n",
    "    db = client.CreateDatabase({ 'id': DOCUMENTDB_DATABASE })\n",
    "else:\n",
    "    db = read_database(client, DOCUMENTDB_DATABASE)\n",
    "# Create collection options\n",
    "options = {\n",
    "    'offerThroughput': 11000\n",
    "}\n",
    "\n",
    "# Create a collection\n",
    "collection_definition = { 'id': DOCUMENTDB_COLLECTION, 'partitionKey': {'paths': ['/id'],'kind': 'Hash'} }\n",
    "if find_collection(client,DOCUMENTDB_DATABASE,  DOCUMENTDB_COLLECTION) ==False:\n",
    "    collection = client.CreateCollection(db['_self'], collection_definition, options)\n",
    "else:\n",
    "    collection = read_collection(client, DOCUMENTDB_DATABASE, DOCUMENTDB_COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = {\n",
    "  \"Endpoint\": endpoint,\n",
    "  \"Masterkey\": master_key,\n",
    "  \"Database\": DOCUMENTDB_DATABASE,\n",
    "  \"Collection\": DOCUMENTDB_COLLECTION,\n",
    "  \"Upsert\": \"true\"\n",
    "}\n",
    "with open(\"secrets.json\", \"w\") as file:\n",
    "    json.dump(secrets, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Training\n",
    "\n",
    "For demo purposes, we are going to use the synthetic dataset [MovieRatings.csv](http://aka.ms/MovieRatings.csv). MovieRatings has around 227k ratings in the range of 0-10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Movie Lens\n",
    "basedataurl = \"http://aka.ms\" \n",
    "datafile = \"MovieRatings.csv\"\n",
    "\n",
    "datafile_dbfs = os.path.join(\"/dbfs\", datafile)\n",
    "\n",
    "if os.path.isfile(datafile_dbfs):\n",
    "    print(\"found {} at {}\".format(datafile, datafile_dbfs))\n",
    "else:\n",
    "    print(\"downloading {} to {}\".format(datafile, datafile_dbfs))\n",
    "    urllib.request.urlretrieve(os.path.join(basedataurl, datafile), datafile_dbfs)\n",
    "    \n",
    "data_all = sqlContext.read.format('csv')\\\n",
    "                     .options(header='true', delimiter=',', inferSchema='true', ignoreLeadingWhiteSpace='true', ignoreTrailingWhiteSpace='true')\\\n",
    "                     .load(datafile)    \n",
    "data_all.printSchema()\n",
    "display(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = spark_random_split(data_all, ratio=0.75, seed=123)\n",
    "\n",
    "print(\"Train ({}, {})\".format(train.cache().count(), len(train.columns)))\n",
    "print(\"Test ({}, {})\".format(test.cache().count(), len(test.columns)))\n",
    "\n",
    "train_data_path_dbfs = os.path.join(\"/dbfs\", train_data_path)\n",
    "test_data_path_dbfs = os.path.join(\"/dbfs\", test_data_path)\n",
    "\n",
    "train.write.mode('overwrite').parquet(train_data_path)\n",
    "test.write.mode('overwrite').parquet(test_data_path)\n",
    "print(\"Train and test datasets saved to {} and {}\".format(train_data_path_dbfs, test_data_path_dbfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the features of Azure ML is its [experimentation service](https://azure.microsoft.com/en-us/blog/experimentation-using-azure-machine-learning/). We can use it to log the metrics of the model using different hyperparamters. All this information can be viewed on the Azure dashboard. \n",
    "\n",
    "Let's start a training run by defining an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myexperiment = Experiment(ws, experiment_name)\n",
    "root_run = myexperiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ALS algorithm as the recommender model. For detailed explanation of ASL, please see our [Deep dive notebook on ALS](../02_modeling/als_deep_dive.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexerContacts = StringIndexer(inputCol=userCol, outputCol=userColIndex, handleInvalid='keep').fit(data_all)\n",
    "indexerRules = StringIndexer(inputCol=itemCol, outputCol=itemColIndex, handleInvalid='keep').fit(data_all)\n",
    "\n",
    "als = ALS(maxIter=5, userCol=userColIndex, itemCol=itemColIndex, ratingCol=ratingCol, coldStartStrategy=\"drop\")\n",
    "\n",
    "# put together the pipeline\n",
    "pipe = Pipeline(stages=[indexerContacts, indexerRules, als])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization Rates\n",
    "regs = [1, 0.1, 0.01, 0.001]\n",
    "paramGrid = ParamGridBuilder().addGrid(als.regParam, regs).build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=ratingCol, predictionCol=\"prediction\")\n",
    "cv = CrossValidator(estimator=pipe, evaluator=evaluator, estimatorParamMaps=paramGrid)\n",
    "train.cache()\n",
    "cvModel = cv.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record a bunch of reg values in a ALS model\n",
    "i = 0\n",
    "for reg in regs:\n",
    "    print(reg)\n",
    "    # create a bunch of child runs\n",
    "    with root_run.child_run(\"reg-\" + str(reg)) as run:\n",
    "        rmse = cvModel.avgMetrics[i]\n",
    "        print(\"Root-mean-square error = \" + str(rmse))\n",
    "        \n",
    "        # log reg, rmse and feature names in run history\n",
    "        run.log(\"reg\", reg)\n",
    "        run.log(\"rmse\", rmse)\n",
    "        run.log_list(\"columns\", train.columns)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all run metrics from run history into a dictionary object.\n",
    "child_runs = {}\n",
    "child_run_metrics = {}\n",
    "\n",
    "for r in root_run.get_children():\n",
    "    child_runs[r.id] = r\n",
    "    child_run_metrics[r.id] = r.get_metrics()\n",
    "\n",
    "#Now find the run with the lowest rmse\n",
    "best_run_id = min(child_run_metrics, key = lambda k: child_run_metrics[k]['rmse'])\n",
    "best_run = child_runs[best_run_id]\n",
    "print('Best run is:', best_run_id)\n",
    "print('Metrics:', child_run_metrics[best_run_id])    \n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "best_reg = child_run_metrics[best_run_id]['reg']\n",
    "max_auc = child_run_metrics[best_run_id]['rmse']\n",
    "\n",
    "reg_auc = np.array([(child_run_metrics[k]['reg'], child_run_metrics[k]['rmse']) for k in child_run_metrics.keys()])\n",
    "reg_auc_sorted = reg_auc[reg_auc[:,0].argsort()]\n",
    "\n",
    "ax.plot(reg_auc_sorted[:,0], reg_auc_sorted[:,1], 'r--')\n",
    "ax.plot(reg_auc_sorted[:,0], reg_auc_sorted[:,1], 'bo')\n",
    "\n",
    "ax.set_xlabel('reg', fontsize = 14)\n",
    "ax.set_ylabel('rmse', fontsize = 14)\n",
    "ax.set_title('rmse over reg', fontsize = 16)\n",
    "\n",
    "# plot arrow\n",
    "ax.arrow(x = best_reg + 0.45, y = max_auc, dx = -0.4, dy = 0, ls = '-', lw = 0.00001,\n",
    "          width = 0.00001, head_width = 0.00002, head_length = 0.02)\n",
    "\n",
    "# plot \"best run\" text\n",
    "ax.text(x = best_reg, y = max_auc, s = 'Best Run', fontsize = 14)\n",
    "#plt.show()\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "cvModel.bestModel.write().overwrite().save(model_name)\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the serialized model into run history record\n",
    "model_dbfs = os.path.join(\"/dbfs\", model_name)\n",
    "mdl, ext = model_name.split(\".\")\n",
    "model_zip = mdl + \".zip\"\n",
    "shutil.make_archive(mdl, 'zip', model_dbfs)\n",
    "root_run.upload_file(\"outputs/\" + model_name, model_zip)        \n",
    "\n",
    "# now delete the serialized model from local folder since it is already uploaded to run history \n",
    "# shutil.rmtree(model_dbfs)\n",
    "os.remove(model_zip)\n",
    "        \n",
    "# Declare run completed\n",
    "root_run.complete()\n",
    "\n",
    "##NOTE: service deployment always gets the model from the current working dir.\n",
    "print(\"copy model from dbfs to local\")\n",
    "model_local = \"file:\" + os.getcwd() + \"/\" + model_name\n",
    "dbutils.fs.cp(model_name, model_local, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cvModel.transform(test)\n",
    "display(pred)\n",
    "\n",
    "re = RegressionEvaluator(metricName=\"rmse\", labelCol=ratingCol,\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = re.evaluate(pred)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secrets.json') as json_data:\n",
    "    writeConfig = json.load(json_data)\n",
    "    recs = cvModel.bestModel.stages[2].recommendForAllUsers(10)\n",
    "    recs.withColumn(\"id\",recs[userColIndex].cast(\"string\")).select(\"id\", \"recommendations.\"+ itemColIndex)\\\n",
    "    .write.format(\"com.microsoft.azure.cosmosdb.spark\").mode('overwrite').options(**writeConfig).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Operationalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile score_sparkml.py\n",
    "\n",
    "score_sparkml = \"\"\"\n",
    "\n",
    "import json\n",
    "def init(local=False):\n",
    "    global client, collection\n",
    "    try:\n",
    "      # Query them in SQL\n",
    "      import pydocumentdb.document_client as document_client\n",
    "\n",
    "      MASTER_KEY = '{key}'\n",
    "      HOST = '{endpoint}'\n",
    "      DATABASE_ID = \"{database}\"\n",
    "      COLLECTION_ID = \"{collection}\"\n",
    "      database_link = 'dbs/' + DATABASE_ID\n",
    "      collection_link = database_link + '/colls/' + COLLECTION_ID\n",
    "      \n",
    "      client = document_client.DocumentClient(HOST, {'masterKey': MASTER_KEY})\n",
    "      collection = client.ReadCollection(collection_link=collection_link)\n",
    "    except Exception as e:\n",
    "      collection = e\n",
    "def run(input_json):      \n",
    "\n",
    "    try:\n",
    "      import json\n",
    "\n",
    "      id = json.loads(json.loads(input_json)[0])['id']\n",
    "      query = {'query': 'SELECT * FROM c WHERE c.id = \"' + str(id) +'\"' } #+ str(id)\n",
    "\n",
    "      options = {}\n",
    "\n",
    "      result_iterable = client.QueryDocuments(collection['_self'], query, options)\n",
    "      result = list(result_iterable);\n",
    "  \n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "    return json.dumps(str(result)) #json.dumps({{\"result\":result}})\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('secrets.json') as json_data:\n",
    "    writeConfig = json.load(json_data)\n",
    "    score_sparkml = score_sparkml.replace(\"{key}\",writeConfig['Masterkey']).replace(\"{endpoint}\",writeConfig['Endpoint']).replace(\"{database}\",writeConfig['Database']).replace(\"{collection}\",writeConfig['Collection'])\n",
    "\n",
    "    exec(score_sparkml)\n",
    "\n",
    "    with open(\"score_sparkml.py\", \"w\") as file:\n",
    "        file.write(score_sparkml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile myenv_sparkml.yml\n",
    "\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - numpy==1.14.2\n",
    "    - scikit-learn==0.19.1\n",
    "    - pandas\n",
    "    # Required packages for AzureML execution, history, and data preparation.\n",
    "    - --extra-index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E7501C02541B433786111FE8E140CAA1\n",
    "    - azureml-core\n",
    "    - pydocumentdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aci = azure container instance\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, \n",
    "    memory_gb = 1, \n",
    "    tags = {'name':'Spark ML Databricks sample'}, \n",
    "    description = 'This is a great example.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Model.register(model_path = model_name, # this points to a local file\n",
    "                       model_name = model_name, # this is the name the model is registered as, am using same name for both path and name.                 \n",
    "                       description = \"ADB trained model\",\n",
    "                       workspace = ws)\n",
    "\n",
    "print(mymodel.name, mymodel.description, mymodel.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mymodel]\n",
    "runtime = \"spark-py\"\n",
    "conda_file = 'myenv_sparkml.yml'\n",
    "driver_file = \"score_sparkml.py\"\n",
    "\n",
    "# image creation\n",
    "myimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n",
    "                                    runtime = runtime, \n",
    "                                    conda_file = conda_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List images by ws\n",
    "for i in ContainerImage.list(workspace = ws):\n",
    "    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.a. Azure Container Instances (ACI) deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    myservice = AciWebservice(ws, name=service_name)\n",
    "except:\n",
    "    myservice = Webservice.deploy_from_model(\n",
    "        workspace=ws, \n",
    "        name=service_name,\n",
    "        deployment_config = aci_config,\n",
    "        models = models,\n",
    "        image_config = myimage_config\n",
    "    )\n",
    "\n",
    "    myservice.wait_for_deployment(show_output=True)\n",
    "\n",
    "print(yaml.dump(myservice.__dict__, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = '[\"{\\\\\"id\\\\\":\\\\\"5616\\\\\"}\"]'.encode()\n",
    "res1_service = myservice.run(input_data = json2)\n",
    "print(res1_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.b. Azure Kubernetes Service (AKS) deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = ContainerImage.list(workspace = ws)[0].name\n",
    "print(image_id)\n",
    "image_version = ContainerImage.list(workspace = ws)[0].version\n",
    "print(image_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimage = Image(workspace=ws, id=\"{}:{}\".format(image_id, image_version)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create AKS compute\n",
    "\n",
    "It may take 20-25 minutes to create a new cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)\n",
    "\n",
    "aks_target.wait_for_completion(show_output = True)\n",
    "\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = aks_service.scoring_uri\n",
    "service_key = aks_service.get_keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = '[\"{\\\\\"id\\\\\":\\\\\"5616\\\\\"}\"]'.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(scoring_url,data=json2)\n",
    "req.add_header(\"Authorization\",\"Bearer {}\".format(service_key))\n",
    "req.add_header(\"Content-Type\",\"application/json\")\n",
    "\n",
    "tic = time.time()\n",
    "with urllib.request.urlopen(req) as result:\n",
    "    res = result.readlines()\n",
    "    print(res)\n",
    "    \n",
    "toc = time.time()\n",
    "t2 = toc - tic\n",
    "print(\"Full run took %.2f seconds\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "ALS_Movie_Example",
  "notebookId": 759976252821758
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
