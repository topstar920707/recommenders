{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for Spark based recommender algorithm with the utility functions provided by the Microsoft/Recommenders repository is tricky. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.0 | packaged by conda-forge | (default, Feb  9 2017, 14:36:55) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Pandas version: 0.23.4\n",
      "PySpark version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "from reco_utils.common.spark_utils import start_or_get_spark\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRankingEvaluation, SparkRatingEvaluation\n",
    "from reco_utils.dataset.movielens import load_spark_df\n",
    "from reco_utils.dataset.spark_splitters import spark_random_split\n",
    "\n",
    "from numba import autojit\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"PySpark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_PYTHON=/anaconda/envs/recommender/bin/python\n",
      "env: PYSPARK_DRIVER_PYTHON=/anaconda/envs/recommender/bin/python\n"
     ]
    }
   ],
   "source": [
    "%env PYSPARK_PYTHON=/anaconda/envs/recommender/bin/python\n",
    "%env PYSPARK_DRIVER_PYTHON=/anaconda/envs/recommender/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_USER = \"UserId\"\n",
    "COL_ITEM = \"MovieId\"\n",
    "COL_TIMESTAMP = \"Timestamp\"\n",
    "COL_RATING = \"Rating\"\n",
    "COL_PREDICTION = \"prediction\"\n",
    "\n",
    "HEADER = {\n",
    "    \"col_user\": COL_USER,\n",
    "    \"col_item\": COL_ITEM,\n",
    "    \"col_rating\": COL_RATING,\n",
    "    \"col_prediction\": COL_PREDICTION,\n",
    "}\n",
    "\n",
    "HEADER_ALS = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_ITEM,\n",
    "    \"ratingCol\": COL_RATING\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do hyper parameter optimization on training and validating data, and then evaluate the optimal recommender on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_or_get_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movielens 100k dataset is used for running the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_spark_df(spark, size='100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into 3 subsets randomly with a given split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = spark_random_split(data, ratio=[4, 4, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Hyper parameter tuning with Azure Machine Learning Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hyperdrive` module in the Azure Machine Learning Services is supposed to run hyper parameter tuning and optimizing for machine learning model selection. At the moment, the service supports running model tuning on heterogenous computing targets such as cluster of commodity compute nodes with or without GPU devices. It is feasible to run parameter tuning on a cluster of VM nodes, but it creates individual and independent Spark session on each node of the cluster, which is not perfectly efficient. \n",
    "\n",
    "Therefore, at the moment, it is not recommended to use Azure Machine Learning Services for tuning Spark models. This will be a feature in the future version. For non-Spark model tuning, detailed instructions can be found in [this](https://github.com/Microsoft/Recommenders.git) notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Hyper parameter tuning with Spark ML constructs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark ML lib implements modules such as `CrossValidator` and `TrainValidationSplit` for tuning hyperparameters. However, by default, it does not support custom machine learning algorithms, data splitting methods, and evaluation metrics, which are commonly used in recommendation scenario. \n",
    "\n",
    "For example, the Spark native constuct can be used for tuning a recommender against the `rmse` metric which is one of the available regression metrics in Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, a Spark ALS object needs to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE the parameters of interest, rank and regParam, are left unset, \n",
    "# because their values will be assigned in the parameter grid builder.\n",
    "als = ALS(\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    alpha=0.1,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    **HEADER_ALS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, a parameter grid can be defined as follows. For illustration purpose, only `rank` and `regParam` are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20]) \\\n",
    "    .addGrid(als.regParam, [1, 0.1, 0.01, 0.001, 0.0001]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the settings above, a `TrainValidationSplit` constructor can be created for fitting the best model in the given parameter range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvs = TrainValidationSplit(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    # A regression evaluation method is used. \n",
    "    evaluator=RegressionEvaluator(labelCol='Rating'),\n",
    "    # 80% of the data will be used for training, 20% for validation.\n",
    "    # NOTE here the splitting is random. The Spark splitting utilities (e.g. chrono splitter)\n",
    "    # are therefore not available here. \n",
    "    trainRatio=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = tvs.fit(train)\n",
    "\n",
    "time_spark = time.time() - time_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model parameters in the grid and the best metrics can be then returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"estimator: estimator to be cross-validated (current: ALS_470cb3934f2d05018def)\\nestimatorParamMaps: estimator param maps (current: [{Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 10, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 1}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 10, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 10, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.01}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 10, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.001}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 10, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.0001}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 20, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 1}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 20, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 20, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.01}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 20, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.001}, {Param(parent='ALS_470cb3934f2d05018def', name='rank', doc='rank of the factorization'): 20, Param(parent='ALS_470cb3934f2d05018def', name='regParam', doc='regularization parameter (>= 0).'): 0.0001}])\\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_46428d0627baa75721c0)\\nseed: random seed. (default: -9100912684695417215)\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3984392359427056,\n",
       " 1.0379928298726153,\n",
       " 1.4197604420411656,\n",
       " 1.8399159520498511,\n",
       " 2.3814634002809205,\n",
       " 1.3984392369583563,\n",
       " 1.0300816295931077,\n",
       " 1.4566886296674724,\n",
       " 1.8531892135542498,\n",
       " 2.487910014840161]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.validationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best_spark = model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Hyper parameter tuning with `hyperopt` in sequential mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hyperopt` is an open source Python package that is designed for tuning parameters for generic function with pre-defined loss. More information about `hyperopt` can be found [here](https://github.com/hyperopt/hyperopt).\n",
    "\n",
    "An *objective* function is defined for optimizing the hyper parameters. In this case, the objective is to **maximize** the metric of **precision@k** for a recommender. To illustrate, the recommender is built with Spark ALS implementation (**NOTE** though the Spark ALS algorithm is demonstrated, the walk-through in the notebook is not meant for distributed / parallel execution of the hyper parameter searching). The arguments of the objective function are parameters used for building and evaluating the ALS-based recommender. Parameters of **rank** and **reg**, which controls number of latent factors and regularization, respectively, are considered as hyper parameters. Note the loss can be defined as demand, depending on the actual recommendation use case scenario. For example, in the case of predicting ratings, a regression loss by using metrics like RMSE, MAE, etc., can be useful, while in the case of recommending a list of items, a ranking loss like precision, recall, etc., are preferred. \n",
    "\n",
    "The objective function shown below demonstrates a precision@k loss for ALS recommender. It is worth noting that `hyperopt` only supports minimization so in our case, `-precision` is used in the loss because the larger precision@k the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize an objective function\n",
    "def objective(params):\n",
    "    rank = params['rank']\n",
    "    reg = params['reg']\n",
    "    train = params['train'] \n",
    "    valid = params['valid'] \n",
    "    col_user = params['col_user'] \n",
    "    col_item = params['col_item']\n",
    "    col_rating = params['col_rating'] \n",
    "    col_prediction = params['col_prediction'] \n",
    "    k = params['k']\n",
    "    relevancy_method = params['relevancy_method']\n",
    "    \n",
    "    als = ALS(\n",
    "        rank=rank,\n",
    "        maxIter=15,\n",
    "        implicitPrefs=False,\n",
    "        alpha=0.1,\n",
    "        regParam=reg,\n",
    "        coldStartStrategy='drop',\n",
    "        nonnegative=False,\n",
    "        seed=0,\n",
    "        **HEADER_ALS\n",
    "    )\n",
    "    \n",
    "    model = als.fit(train)\n",
    "    \n",
    "    prediction = model.transform(valid)\n",
    "\n",
    "    rating_eval = SparkRatingEvaluation(\n",
    "        valid, \n",
    "        prediction, \n",
    "        **HEADER\n",
    "    )\n",
    "    \n",
    "    rmse = rating_eval.rmse()\n",
    "    \n",
    "    # Return the objective function result.\n",
    "    return {\n",
    "       'loss': rmse,\n",
    "       'status': STATUS_OK,\n",
    "       'eval_time': time.time()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hyperopt` allows users to define a search space for hyper parameter exploration. Selection of search space is empirical, and it depends on the understanding of how distribution of parameter of interest affects the model performance measured by the loss function. \n",
    "\n",
    "In the ALS algorithm, the two hyper parameters, rank and reg, affect model performance in a way that\n",
    "* The higher the rank, the better the model performance but also the higher risk of overfitting.\n",
    "* The reg parameter is subject to rank and it prevents overfitting in certain way. \n",
    "\n",
    "Therefore, in this case, a uniform distribution and a lognormal distribution sampling spaces are used for rank and reg, respectively. A narrow search space is used for illustration purpose, that is, the range of rank is from 10 to 20, while that of reg is from $e^{-5}$ to $e^{-1}$. Together with the randomly sampled hyper parameters, other parameters use for building / evaluating the recommender, like `k`, column names, data, etc., are kept as constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a search space\n",
    "space = {\n",
    "    'rank': hp.quniform('rank', 10, 20, 5),\n",
    "    'reg': hp.loguniform('reg', -5, -1),\n",
    "    'train': train, \n",
    "    'valid': valid, \n",
    "    'col_user': \"UserId\", \n",
    "    'col_item': \"MovieId\", \n",
    "    'col_rating': \"Rating\", \n",
    "    'col_prediction': \"prediction\", \n",
    "    'k': 10,\n",
    "    'relevancy_method': \"top_k\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fmin` of `hyperopt` is used for running the trials for searching optimal hyper parameters. In `hyperopt`, there are different strategies for intelligently optimize hyper parameters. For example, `hyperopt` avails Tree of Parzen Estimators (TPE) method for searching optimal parameters, which is more efficient than random search or grid search (details can be found [here](http://hyperopt.github.io/hyperopt/)). It is claimed in the project website that Bayesian based optimization method is planned but so far it has not yet been implemented. \n",
    "\n",
    "The following runs the trials with the pre-defined objective function and search space. TPE is used as the optimization method. Totally there will be 100 evaluations run for searching the best parameters.\n",
    "\n",
    "**NOTE** having a sufficiently large number of evaluation iterations will give statistically sound measure of model performance across the parameter space, but it also deteriorates the efficiency of running the optimization. To improve this, one can distribute the parameter optimization process across a distributed nodes (see next Section 5 for more details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# Trials for recording each iteration of the hyperparameter searching.\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    trials=trials,\n",
    "    max_evals=10\n",
    ")\n",
    "                  \n",
    "time_hyperopt = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = ['rank', 'reg']\n",
    "cols = len(parameters)\n",
    "f, axes = plt.subplots(nrows=1, ncols=cols, figsize=(15,5))\n",
    "cmap = plt.cm.jet\n",
    "for i, val in enumerate(parameters):\n",
    "    xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
    "    ys = [t['result']['loss'] for t in trials.trials]\n",
    "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
    "    ys = np.array(ys)\n",
    "    axes[i].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.75, c=cmap(float(i)/len(parameters)))\n",
    "    axes[i].set_title(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above plot that\n",
    "* The actual impact of rank is in line with the intuition - the larger the value the better the result.\n",
    "* It is interesting to see that the optimal value of reg is ~0.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    rank=best[\"rank\"],\n",
    "    regParam=best[\"reg\"],\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    alpha=0.1,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=0,\n",
    "    **HEADER_ALS\n",
    ")\n",
    "    \n",
    "model_best_hyperopt = als.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note one can also use `hyperopt` for tuning prameters against other metrics. This can be simply done by modifying the `objective` function. The following shows an objective function of how to tune \"precision@k\". Since `fmin` in `hyperopt` only supports minimization while the actual objective of the loss is to maximize \"precision@k\", `-precision` instead of `precision` is used in the returned value of the `objective` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize an objective function\n",
    "def objective(params):\n",
    "    rank = params['rank']\n",
    "    reg = params['reg']\n",
    "    train = params['train'] \n",
    "    valid = params['valid'] \n",
    "    col_user = params['col_user'] \n",
    "    col_item = params['col_item']\n",
    "    col_rating = params['col_rating'] \n",
    "    col_prediction = params['col_prediction'] \n",
    "    k = params['k']\n",
    "    relevancy_method = params['relevancy_method']\n",
    "    \n",
    "    header = {\n",
    "        \"userCol\": col_user,\n",
    "        \"itemCol\": col_item,\n",
    "        \"ratingCol\": col_rating,\n",
    "    }\n",
    "    \n",
    "    als = ALS(\n",
    "        rank=rank,\n",
    "        maxIter=15,\n",
    "        implicitPrefs=False,\n",
    "        alpha=0.1,\n",
    "        regParam=reg,\n",
    "        coldStartStrategy='drop',\n",
    "        nonnegative=False,\n",
    "        seed=0,\n",
    "        **header\n",
    "    )\n",
    "    \n",
    "    model = als.fit(train)\n",
    "    \n",
    "    users = train.select(col_user).distinct()\n",
    "    items = train.select(col_item).distinct()\n",
    "    user_item = users.crossJoin(items)\n",
    "    dfs_pred = model.transform(user_item)\n",
    "\n",
    "    # Remove seen items.\n",
    "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "        train.alias(\"train\"),\n",
    "        (dfs_pred[col_user] == train[col_user]) & (dfs_pred[col_item] == train[col_item]),\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "        .select('pred.' + col_user, 'pred.' + col_item, 'pred.' + \"prediction\")\n",
    "    \n",
    "    top_all.cache().count()\n",
    "\n",
    "    rank_eval = SparkRankingEvaluation(\n",
    "        valid, \n",
    "        top_all, \n",
    "        k=k, \n",
    "        col_user=col_user, \n",
    "        col_item=col_item, \n",
    "        col_rating=\"Rating\", \n",
    "        col_prediction=\"prediction\", \n",
    "        relevancy_method=relevancy_method\n",
    "    )\n",
    "    \n",
    "    precision = rank_eval.precision_at_k()\n",
    "    \n",
    "    # Return the objective function result.\n",
    "    return {\n",
    "        'loss': -precision,\n",
    "        'status': STATUS_OK,\n",
    "        'eval_time': time.time()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with `hyperopt` in parallel mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though `hyperopt` works well in a single node machine, its features (e.g., `Trials` module) do not support Spark environment. A good practice is to use `hyperopt` for sampling parameter values from the defined sampling space, and then parallelize the model training onto Spark cluster with the sampled parameter combinations.\n",
    "\n",
    "The downside of this method is that the intelligent searching algorithm (i.e., TPE) of `hyperopt` cannot be used. The approach introduced here is therefore equivalent to random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the parameters used for model building from the pre-defined space. Here, for illustration purpose, only 10 samples are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt.pyll.stochastic\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "sample_params = [hyperopt.pyll.stochastic.sample(space) for x in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the master node of the Spark cluster has multiple cores, a local parallelization with Python `map` function can be used for running model building in parallel. Note here the Spark `flatMap` function cannot be used, but a nested parallelization is not allowed. \n",
    "\n",
    "The following runs model building on the sampled parameter values with the pre-defined objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_map = list(map(lambda x: objective(x), sample_params))\n",
    "\n",
    "time_sample = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.07635206786850475,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830309.033338},\n",
       " {'loss': -0.0018027571580063627,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830329.3028948},\n",
       " {'loss': -0.02926829268292683,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830349.6416283},\n",
       " {'loss': -0.08791092258748673,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830372.0263839},\n",
       " {'loss': -0.10222693531283147,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830393.2818742},\n",
       " {'loss': -0.08154825026511142,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830414.033852},\n",
       " {'loss': -0.09013785790031817,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830435.530046},\n",
       " {'loss': -0.054082714740190885,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830458.1214182},\n",
       " {'loss': -0.09904559915164372,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830479.225547},\n",
       " {'loss': -0.035312831389183466,\n",
       "  'status': 'ok',\n",
       "  'eval_time': 1546830499.7374842}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_metrics = np.array([x['loss'] for x in results_map])\n",
    "best_loss = np.where(loss_metrics == min(loss_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = sample_params[best_loss[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    rank=best_param[\"rank\"],\n",
    "    regParam=best_param[\"reg\"],\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    alpha=0.1,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=0,\n",
    "    **HEADER_ALS\n",
    ")\n",
    "    \n",
    "model_best_sample = als.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hyperopt` reduces the searching time dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Evaluation on testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal parameters can then be used for building a recommender, which is then evaluated on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction results with the optimal modesl from different approaches.\n",
    "prediction_spark = model_best_spark.transform(test)\n",
    "prediction_hyperopt = model_best_hyperopt.transform(test)\n",
    "prediction_sample = model_best_sample.transform(test)\n",
    "\n",
    "predictions = [prediction_spark, prediction_hyperopt, prediction_sample]\n",
    "elapsed = [time_spark, time_hyperopt, time_sample]\n",
    "\n",
    "approaches = ['spark', 'hyperopt', 'sample']\n",
    "comparison = pd.DataFrame()\n",
    "for ind, approach in enumerate(approaches):    \n",
    "    rating_eval = SparkRatingEvaluation(\n",
    "        test, \n",
    "        predictions[ind],\n",
    "        **HEADER\n",
    "    )\n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        'Approach': approach,\n",
    "        'RMSE': rating_eval.rmse(),\n",
    "        'MAE': rating_eval.mae(),\n",
    "        'Explained variance': rating_eval.exp_var(),\n",
    "        'R squared': rating_eval.rsquared(),\n",
    "        'Elapsed': elapsed[ind]\n",
    "    }, index=[0])\n",
    "    \n",
    "    comparison = comparison.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Explained variance</th>\n",
       "      <th>R squared</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spark</td>\n",
       "      <td>0.993568</td>\n",
       "      <td>0.787028</td>\n",
       "      <td>0.244673</td>\n",
       "      <td>0.208661</td>\n",
       "      <td>44.237093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperopt</td>\n",
       "      <td>0.968426</td>\n",
       "      <td>0.774891</td>\n",
       "      <td>0.295251</td>\n",
       "      <td>0.248203</td>\n",
       "      <td>116.420096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample</td>\n",
       "      <td>0.985228</td>\n",
       "      <td>0.780406</td>\n",
       "      <td>0.258821</td>\n",
       "      <td>0.221890</td>\n",
       "      <td>211.739382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Approach      RMSE       MAE  Explained variance  R squared     Elapsed\n",
       "0     spark  0.993568  0.787028            0.244673   0.208661   44.237093\n",
       "0  hyperopt  0.968426  0.774891            0.295251   0.248203  116.420096\n",
       "0    sample  0.985228  0.780406            0.258821   0.221890  211.739382"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, it can be seen that, *with the same number of iterations*, Spark native construct based approach takes the least amount of time, and not suprisingly, sample based approach takes the most amount of time. The three approaches use the same objective which is RMSE. In this measure, the `hyperopt` based approach performs the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Approach|How-to|Pros|Cons|\n",
    "|-----------------|--------------|----------------|---------------|\n",
    "|Spark native construct|Use Spark `TrainValidationSplit` or `CrossValidation` module|The Spark native construct inherits the benefits of Spark framework, thus the tuning operations can be run in a distributed manner|Only the existing metrics and algorithms from Spark ML lib are supported. One may need to add custom implementations such as model Transformers, Estimators, and / or Evaluators that work specifically for recommendation algorithms.|\n",
    "|Commercial package|Use Microsoft Azure Machine Learning Services|Scalable parallel computation on cluster created on demand. Various hyper parameter optimization algorithms and iteration terminal policies are supported|Currently only embarassingly parallel of multiple Spark sessions are supported.|\n",
    "|Open-source package|Use `hyperopt`|A few optimization algorithms are supported.|Not available for Spark distributed environment.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    " * `hyperopt`, url: http://hyperopt.github.io/hyperopt/.\n",
    " * Bergstra, J., Yamins, D., Cox, D. D. (2013) Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures. To appear in Proc. of the 30th International Conference on Machine Learning (ICML 2013).\n",
    " * Kris Wright, \"Hyper parameter tuning with hyperopt\", url:https://districtdatalabs.silvrback.com/parameter-tuning-with-hyperopt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (recommender)",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
