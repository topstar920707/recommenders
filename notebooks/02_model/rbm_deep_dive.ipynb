{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# RBM Deep Dive with Tensorflow \n",
    "\n",
    "In this notebook we provide a complete walkthrough of the Restricted Boltzmann Machine (RBM) algorithm with applications to recommender systems. In particular, we use as a case study the [movielens dataset](https://movielens.org), comprising user's ranking of movies on a scale of 1 to 5. A quickstart version of this notebook can be found [here](../00_quick_start/rbm_movielens.ipynb).  \n",
    "\n",
    "### Overview \n",
    "\n",
    "A Restricted Boltzmann Machine (RBM) is a generative neural network model typically used to perform unsupervised learning. The main task of an RBM is to learn the joint probability distribution $P(v,h)$, where $v$ are the visible units and $h$ the hidden ones. The hidden units represent latent variables while the visible units are clamped on the input data. Once the joint distribution is learnt, new examples are generated by sampling from it.    \n",
    "\n",
    "The implementation presented here is based on the article by Ruslan Salakhutdinov, Andriy Mnih and Geoffrey Hinton [Restricted Boltzmann Machines for Collaborative Filtering](https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf) with the exception that here we use multinomial units instead of the one-hot encoded used in the paper.  \n",
    "\n",
    "### Advantages of RBM: \n",
    "\n",
    "The model generates ratings for a user/movie pair using a collaborative filtering based approach. While matrix factorization methods learn how to reproduce an instance of the user/item affinity matrix, the RBM learns its underlying probability distribution. This has several advantages: \n",
    "\n",
    "- Generalizability : the model generalize well to new examples as long as they do not differ much in probability\n",
    "- Stability in time: if the recommendation task is time-stationary, the model does not need to be trained often to accomodate new ratings/users. \n",
    "- Scales well with the size of the dataset and the sparsity of the user/affinity matrix. \n",
    "- The tensorflow implementation presented here allows fast, scalable  training on GPU \n",
    "\n",
    "### Outline \n",
    "\n",
    "This notebook is organized as follows:\n",
    "\n",
    "1. RBM Theory \n",
    "2. Tensorflow implementation and model parameters  \n",
    "3. Data preparation and inspection\n",
    "4. Model application, performance and analysis  \n",
    "\n",
    "Sections 1 and 2 require basic knowledge of linear algebra, probability theory and tensorflow while  \n",
    "sections 3 and 4 only require some basic data science understanding. **Feel free to jumpo to the section you are most interested in!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global Settings and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 19:16:44) \n",
      "[GCC 7.3.0]\n",
      "Pandas version: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import papermill \n",
    "\n",
    "#RBM \n",
    "from reco_utils.recommender.rbm.rbm import RBM\n",
    "from reco_utils.dataset.numpy_splitters import numpy_stratified_split\n",
    "from reco_utils.dataset.sparse import AffinityMatrix\n",
    "\n",
    "#Evaluation libraries\n",
    "from reco_utils.dataset import movielens \n",
    "\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    ")\n",
    "\n",
    "from reco_utils.evaluation.parameter_sweep import generate_param_grid\n",
    "#For interactive mode only\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RBM Theory \n",
    "\n",
    "## 1.1 Overview and main differences with other recommender algorithms\n",
    "\n",
    "A Restricted Boltzmann Machine (RBM) is an undirected graphical model with origin in the statistical mechanics (or physics) of magnetic systems. Statistical mechanics (SM) provides a probabilistic description of complex systems made of a huge number of constituents (typically $\\sim 10^{23}$); instead of looking at a particular instance of the system, the aim of SM is to describe their **typical** behaviour. This approach has been succesfull for the description of gases, liquids, complex materials (e.g. semiconductors) and even the famous [Higgs boson](https://en.wikipedia.org/wiki/Higgs_boson)!\n",
    "\n",
    "Being designed to handle and organize a large amount of data, SM finds ideal applications in modern learning algorithms. In the context of **recommender systems**, the idea is to learn typical user behaviour instead of particular instances. To better understand this consider the most general setup of a recmmendation problem: there are $m$ users rating $n$ items according to some scale (e.g. 1 to 5). In a typical scenario of online shopping, streaming services or decision processes, the user only rates a subset $l \\ll m$ of the products. If we now create a matrix representation of this problem, we obtain the user/item affinity matrix $X$. In a more readable table form, $X$ will look like this:\n",
    "\n",
    "\n",
    "|  $X$   |$i_1$  |$i_2$  |$i_3$  |  ... |$i_m$  | \n",
    "|-----|-------|-------|-------|------|-------|\n",
    "|$u_1$|5      |0      |2      |0 ... |1      |\n",
    "|$u_2$|0      |0      |3      |4 ... |0      |\n",
    "|...  |...    |...    |...    |...   |...    |\n",
    "|$u_m$|3      |3      |0      |5...  |2      |\n",
    "\n",
    "\n",
    "where the zeroes denote unrated items. In a nutshell, the recommender task is to \"fill in\" the missing ratings (later we will see that in practice this is not the only criteria used to recommend a product). The classical approach to this problem is called matrix factorization: the basic idea is to decompose $X$ into a user ($P$) and item ($Q$) matrix, such that $X = Q^T P$. The dimensions of the two matrices are $dim(Q) = (f, n)$ and $dim(P)= (f,m)$ where $f \\le m,n$ is the number of latent factors, e.g. the genre of a movie, the type of food etc... and it is an hyperparameter of the model, for more details see the [ALS notebook](../02_model/als_deep_dive.ipynb). By learning $Q$ and $P$ we try to reproduce a particular instance of $X$ (provided by the available data) and use this information to fill up the missing matrix elements. \n",
    "\n",
    "The RBM approach is to look at $X$ as a particular realization (sample) of a more general process; instead of learning a specific $X$, we try to learn the matrix distribution from which $X$ has been sampled from. Effectively, we learn the typical distribution of *tastes* (i.e. latent factors) and use this information to *generate* new ratings. For this reason, this class of neural network models is also called **generative**. Consider the following example: imagine you are given the  income distribution per age window of a particular country (this is easy to find from goverments data), then we could fix the age window and *generate* virtual citizens with various incomes by sampling from this distibution.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model \n",
    "\n",
    "The central quantity of every SM model is the [Boltzmann distribution ](https://en.wikipedia.org/wiki/Boltzmann_distribution); this can be seen as the least biased probability distribution on a given probability space $\\Sigma$ and can be obtained using a maximum entropy principle on the space of distributions over $\\Sigma$. Its typical form is: \n",
    "\n",
    "$$P = \\frac{1}{Z} \\, e^{- \\beta \\, H},$$ \n",
    "\n",
    "where $Z$ is a normalization constant known as the partition function, $\\beta$ is a noise parameter with units of inverse energy and $H$ is the Hamiltonian, or energy function of the system. For this reason, this class of models is also known as *energy based* in computer science. In physics, $\\beta$ is the inverse temperature of the system in units of Boltzmann's constant, but here we will effectively rescale it inside $H$, so that this is now a pure number. $H$ describes the behaviour of two sets of stochastic vectors, typically called $v_i$ (visibles) and $h_j$ (hidden). The former constitute both the input *and* the ouput of the algo (this will be clear later), while the hidden units are the latent factors we want to learn. This structure results in the following Neural Network topology:\n",
    "\n",
    "![rbm1](https://393229b54263dsvm.file.core.windows.net/images/RBM1.png?sp=rl&st=2018-12-03T13:06:28Z&se=2020-12-04T13:06:00Z&sv=2017-11-09&sig=XP5y%2BXuU4r3Snmb%2FIgksMR%2B26XZfgrV2ZVs183Nwn3k%3D&sr=f)\n",
    "\n",
    "The input of the movielens database consists of ratings from 1 to 5; we shall thus consider a discrete configuration space of $m$ visible variables, each taking values in a finite set $\\chi_v = \\{ 1, 2, 3,4,5 \\}$. A global configuration of the system is determined by $\\mathbf{v} = (v_1, v_2, ..., v_m) \\in \\chi_v^m$ and we reserve $0$ for an unrated movie. We also need to specify the hidden units, that we take as random binary variables $\\chi_h = \\{0,1 \\}$ denoting if the particular unit is active or not and $\\mathbf{h} = (h_1, h_2, ...,h_n) \\in \\chi_h^n$. The hidden units may describe attributes such as the genre of a movie; for example, given a sci-fi/horror movie, only the hidden units describing such attributes should be active. The minimal model for such a system is defined by the following Hamiltonian: \n",
    "\n",
    "$$H = - \\sum_{i,j \\in G} v_i \\, w_{ij} \\, h_j - \\sum_{i=1}^m v_i \\, a_i - \\sum_{j=1}^n h_i \\, b_i$$\n",
    "\n",
    "The first term is an \"interaction term\", capturing the correlations between the visible and hidden units, while the other two terms are \"potential terms\", taking into account the bias of the units. The correlation matrix $w_{ij}$ and the two biases $a_i$ and $b_i$ are learning parameters to be fixed by the minimization of a properly defined cost function. Remember that this is an unsupervised problem, i.e. there is no real output and therefore we cannot directly minimize the error function between the prediction and the labeled data. As in every SM problem, the right quantity to minimize is the Free energy (remember that $\\beta =1$)\n",
    "\n",
    "$$ F =- \\log Z =- \\log \\sum_{ v_i, h_i } P(v, h) $$.\n",
    "\n",
    "In the language of probability theory, the above quantity is the cumulant generating function. One way of evaluating the free energy is to use a [Markov-chain Montecarlo sampling](https://en.wikipedia.org/wiki/Monte_Carlo_method#Computer_graphics) algorithm such as the Metropolis-Hasting; here we will use instead an approximate method called Contrastive divergence, based on [Gibbs sampling](https://en.wikipedia.org/wiki/Gibbs_sampling) (see below). The latter has the advantage of being faster than Montecarlo. Once the candidate $F$ has been found, we fix the learning parameters by extremizing $F$. Let us see how this works in practice in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Learning Algorithm \n",
    "\n",
    "Instead of sampling directly from the joint probability distribution, one can evaluate the conditional distributions   \n",
    "\n",
    "$$ P(v, h) = P(v|h) P(h) = P(h|v) P(v) $$ \n",
    "\n",
    "where the second equality follows from the fact that the model is undirected or, in physical terms, it is in equilibrium. Gibbs sampling essentially consists of two steps called **positive** and **negative** phases:\n",
    "\n",
    "### Positive \n",
    "\n",
    "**Fix the visible units on the data and evaluate $P(h_j =1| \\mathbf{v})$**, i.e. the probability that the jth hidden unit is active given the entire input vector. In practice, it is convenient to evaluate the generating function: \n",
    "\n",
    "$$ Z[v,b] = \\prod_j \\sum_{h_j = 0,1}  e^{(\\sum_i w_{ij} v_i + b_j) h_j} = \\prod_j \\left( 1+  e^{\\sum_i w_{ij} v_i + b_j} \\right).$$\n",
    "\n",
    "Taking the gradients with respect to the bias we obtain \n",
    "\n",
    "$$\\frac{\\partial}{\\partial b_j}\\log Z[v,b] =  \\frac{1}{1+ e^{-(\\sum_i w_{ij} v_i + b_j)}} = \\sigma( \\phi_j(v, b) ),$$\n",
    "\n",
    "where $\\phi_j(v,b) = \\sum_i w_{ij} v_i + b_j $ and we have identified the logistic function $\\sigma(.) \\equiv P(h_j=1|v,b)$. \n",
    "\n",
    "**Use $\\sigma$ to sample the value of $h_j$** \n",
    "\n",
    "### Negative \n",
    "\n",
    "**Use the sampled value of the hidden units to evaluate $P(v_i = q |h)$**, where $q=1,...,5$. This is given by the multinomial expression\n",
    "\n",
    "$$ P(v_i = q |h,a) =  \\prod_{v_i=1}^q e^{v_i (\\sum_j w_{ij} \\, h_j + a_i ) }/Z_q $$,\n",
    "\n",
    "where $Z_q$ is the partition function evaluated over the $q$ outcomes (note that $0$ should not be included in the sum). Finally, sample the values of $v_i$ from the above distribution. Clearly, these new $v_i$ are not necessarily those we have used as an input, at least not at the beginning of training. The above steps are repeated $k$ times, where $k$ is usually increased during training according to a given protocol. \n",
    "\n",
    "At the end of each k-step Gibbs sampling, we evaluate the difference between the initial free energy at $k=0$ (given v) and the one after k-steps \n",
    "\n",
    "$$ \\Delta F = F_0 - F_k, $$\n",
    "\n",
    "and update the learning parameters $w_{ij}$, $b_i$ and $a_i$: \n",
    "\n",
    "$$ \\frac{\\partial}{\\partial b_j} \\Delta F = \\frac{\\partial}{\\partial b_j} (\\log Z_0[v,b] - \\log Z_k[v,b]) = P_0(h_j=1|v,b) - P_k(h_j=1|v,b) $$\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_{ij} } \\Delta F = v_i \\, P_0(v_i = q|h, a) - v_i P_k(v_i| h,a) \\equiv \\langle v_i\\rangle_0 - \\langle v_i \\rangle_k. $$\n",
    "\n",
    "This process is repeated for each training epoch, eventually until $\\Delta F =0$, i.e. the learned distribution faithfully reproduces the empirical one. In this sense, $v_i$ serves both as an input and output of the model. As $w_{ij}$ contains informations on how users' votes are correlated, we can use this information to generate ratings for the unseen movies by sampling from the learned, marginal distribution:\n",
    "\n",
    "$$ \\langle v_i \\rangle = \\sum_{v_i} v_i \\, P(v) $$ \n",
    "\n",
    "The entire workflow is summarised below \n",
    "\n",
    "![gibbs](https://393229b54263dsvm.file.core.windows.net/images/Gsampling.001.png?sp=rl&st=2018-12-04T08:34:33Z&se=2020-12-05T08:34:00Z&sv=2017-11-09&sig=N0GXdj0UqLsXM2cwIZsWdMgqUTlYvu1pmGhnNmuAOWI%3D&sr=f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow implemetation and model parameters \n",
    "\n",
    "In this section we briefly describe how the algorithm is implemented in Tensorflow and which parameters can be customized by the user during training. We also discuss some best practices to be used when training the RBM model on a recommendation task. Further technical details are explained directly in the code. \n",
    "\n",
    "Tensorflow (TF) is an open source framework to develope deep learning (DL) models in a fast and efficient way. One of the shared characteristics of DL frameworks is autodifferentiation, i.e. the symbolic evaluation of gradients, that will be particulary useful here. The other advantage of TF is the geration and optimization of the symbolic operations defined on a computational graph, for fast and scalable deployment on CPU and GPU. For more informations on TF see [here](www.tensorflow.com). Unfortunately, TF is tailor made for supervised learning tasks, so its application to unsupervised model needs some more work. Note: although TF has recently started developing a [set of libraries to perform probabilistic inference](www.tensorflow_probability.com), we found their performance still not optimal and therefore we will not use them here. \n",
    "\n",
    "\n",
    "The RBM model is instantiated as a class with several methods to build the graph, perform sampling, training and inference. The skeleton of the graph is built at the moment the class is instantiated; mandatory fields are: \n",
    "\n",
    "- `hidden_units`: number of hidden units\n",
    "- `training_epoch`: number of training epochs \n",
    "- `minibatch_size`: size of the batch to be chosen at random at each training epoch \n",
    "\n",
    "The optional parameters are: \n",
    "\n",
    "- `keep_prob` : float (Default = 0.7) we use dropout regularization on the hidden units, so this parameter specifies the probability of keeping the connection to a hidden unit active. Dropout will affect specific matrix elements of $w_{ij}$, decreasing in this way the model's complexity and improving generalization. \n",
    "\n",
    "- `cd_protocol` : Array (Default = $[50, 70, 80,90,100]$) percentage of the entire training epochs when the the k-sampling step is increased in an annealing fashion. In the default case, the first 50% of the training epochs are sampled with a single k-step. As training converges, the number of k-steps is increased by $1$ at each percentage.\n",
    "\n",
    "- `save_path`: String (Default = None), if a directory is specified, the TF model is saved there. \n",
    "\n",
    "- `debug`: Boolean (Default = False) if True, prints the output of some of the intermediate steps for inspection. \n",
    "\n",
    "- `with_metrics`: Boolean (Default= False) if True it evaluates, print and finally plot the mean squared root error per training epoch on the training set. At the end, it also evaluates and print the total model accuracy both on the training and test set. We suggest to switch it off only for benchmarking execution time.  \n",
    "\n",
    "- `init_stdv`: float (Default = 0.05) standard deviation used to inititialize the correlation matrix. \n",
    "\n",
    "- `learning_rate`: float (Default = 0.04) init learning rate used in the optimization algorithm. Note that the optimizer uses a different, effective learning rate scaled to the batch size $\\alpha$ = `learning_rate/minibatch_size`. \n",
    "\n",
    "- `display_epoch `: integer (Default = 10) the number of epochs after which the rmse error is printed out during the learning phase. \n",
    "\n",
    "Although optional, it is likely that `cd_protocol` needs to be modified for different recommenders; we recommend to keep this in mind when training on a new dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data preparation and inspection \n",
    "\n",
    "The Movielens dataset comes in different sizes, denoting the number of available ratings. The number of users and rated movies also changes across the different dataset. The data are imported in a pandas dataframe including the **user ID**, the **item ID**, the **ratings** and a **timestamp** denoting when a particular user rated a particular item. Although this last feature could be explicitely included, it will not be considered here. The underlying assumption of this choice is that user's tastes are weakly time dependent, i.e. a user's taste typically chage on time scales (usually years) much longer than the typical recommendation time scale (e.g. hours/days). As a consequence, the joint probability distribution we want to learn can be safely considered as time dependent. Nevertheless, timestamps could be used as *contextual variables*, e.g. recommend a certain movie during the weekend and another during weekdays.  \n",
    "\n",
    "Below, we first load the different movielens data in pandas dataframes, explain how the user/affinity matrix is built and how the train/test set is generated. As this procedure is common to all the datasets considered here, we explain it in details only for the 1m dataset.  \n",
    "\n",
    "We start with downloading the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamp\n",
       "0     196      242       3  881250949\n",
       "1     186      302       3  891717742\n",
       "2      22      377       1  878887116\n",
       "3     244       51       2  880606923\n",
       "4     166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "mldf_100k = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['userID','movieID','rating','timestamp']\n",
    ")\n",
    "\n",
    "# Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "mldf_100k.loc[:, 'rating'] = mldf_100k['rating'].astype(np.int32) \n",
    "\n",
    "mldf_100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "\n",
    "mldf_1m = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['userID','movieID','rating','timestamp']\n",
    ")\n",
    "\n",
    "# Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "mldf_1m.loc[:, 'rating'] = mldf_1m['rating'].astype(np.int32) \n",
    "\n",
    "mldf_1m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Split the data using the stratified splitter  \n",
    "\n",
    "As a second step, we split the data into train and test set. If you are familiar with training supervised learning models, here you will notice the first difference. In the former case, we cut off a certain proportion of training examples from the dataset (e.g. images) -- here corresponding to users (or items)-- ending up with two matrices (train and test) of different row dimensions. To make the RBM work correctly, we need to mantain the same matrix size for the train and test set, although the two will contain different amounts of ratings. \n",
    "\n",
    "- First, we use the `AffinityMatrix` class to generate the $(m,n)$ user/affinity matrix $X$ defined in section **1.1**; this also returns the sparsness percentage. For example, for the 1m dataset, $95$ % of the matrix entries are zeros. This represents a challenge for the learning task: fixing $95$ % of entries with only $5$ % of data points. \n",
    "\n",
    "- Second, use the `numpy_stratified_split()` to split $X$ into train and test set. By default, we choose a $75$% to $25$% ratio. The split function selects, for every user, $25$ % of rated movies and it moves them in the new test matrix. This way of splitting the data makes sure the rating distribution remains the same across the train/test set, both locally (user-wise) and globally. If you consider the user/item matrix $X$ defined above, we would have\n",
    "\n",
    "### Train\n",
    "\n",
    "|  $X_{tr}$   |$i_1$  |$i_2$  |$i_3$  |  $...$ |$i_n$  |    \n",
    "|-----|-------|-------|-------|--------|-------|\n",
    "|$u_1$|$0$    |$0$    |$2$    |$0...$  |$0$    |\n",
    "|$u_2$|$0$    |$0$    |$3$    |$0...$  |$0$    |\n",
    "|$...$|$...$  |$...$  |$...$  |$...$   |$...$  |\n",
    "|$u_m$|$3$    |$0$    |$0$    |$0...$  |$2$    |\n",
    "\n",
    "\n",
    "### Test \n",
    "\n",
    "| $X_{tst}$    |$i_1$  |$i_2$  |$i_3$  |  ... |$i_n$  | \n",
    "|-----|-------|-------|-------|------|-------|\n",
    "|$u_1$|5      |0      |0      |0 ... |1      |\n",
    "|$u_2$|0      |0      |0      |4 ... |0      |\n",
    "|...  |...    |...    |...    |...   |...    |\n",
    "|$u_m$|0      |3      |0      |5...  |0      |\n",
    "\n",
    "The Train and Test matrices have exactly the same dimensions (i.e. same numbers of users and movies) but contain different ratings. Once the model is trained, at inference time, we use the test set user vectors to obtain the inferred values for the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"userID\",\n",
    "        \"col_item\": \"movieID\",\n",
    "        \"col_rating\": \"rating\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating the user/item affinity matrix...\n",
      "Matrix generated, sparsness percentage: 95\n"
     ]
    }
   ],
   "source": [
    "#instantiate the splitter \n",
    "am1m = AffinityMatrix(DF = mldf_1m, **header)\n",
    "\n",
    "#obtain the sparse matrix \n",
    "X1m = am1m.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the matrix above into train and test set sparse matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_1m, Xtst_1m = numpy_stratified_split(X1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to inspect the distribution of ratings in the test/train matrix to make sure that the splitter keeps it constant. We can inspect this by plotting the normalized histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Test')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (ax1m, ax2m) = plt.subplots(1, 2, sharey=True, figsize=(10,5))\n",
    "ax1m.hist(Xtr_1m[Xtr_1m !=0], 5, density= True)\n",
    "ax1m.set_title('Train')\n",
    "ax2m.hist(Xtst_1m[Xtst_1m !=0], 5, density= True)\n",
    "ax2m.set_title('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat the same operations for the other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating the user/item affinity matrix...\n",
      "Matrix generated, sparsness percentage: 93\n"
     ]
    }
   ],
   "source": [
    "#100k\n",
    "am100k = AffinityMatrix(DF = mldf_100k, **header)\n",
    "X100k= am100k.gen_affinity_matrix()\n",
    "Xtr_100k, Xtst_100k = numpy_stratified_split(X100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Train')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (ax1k, ax2k) = plt.subplots(1, 2, sharey=True, figsize=(10,5))\n",
    "ax1k.hist(Xtr_100k[Xtr_100k !=0], 5, density= True)\n",
    "ax1k.set_title('Train')\n",
    "ax2k.hist(Xtst_100k[Xtst_100k !=0], 5, density= True)\n",
    "ax2k.set_title('Train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots above we can see that the two datasets have very similar rating distributions. The main difference is in the degree of sparsness of the user/item affinity matrix; this is an important factor as it states the ratio between datapoints and unrated movies to infere. Note that the split function returns the total (or per dataset) sparsness, not the user-wise one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection of evaluation metrics for later use\n",
    "def ranking_metrics(\n",
    "    data_size,\n",
    "    data_true,\n",
    "    data_pred,\n",
    "    time_train,\n",
    "    time_test,\n",
    "    K\n",
    "):\n",
    "\n",
    "    eval_map = map_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                    col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                    relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_ndcg = ndcg_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                      col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                      relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_precision = precision_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                               col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                               relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_recall = recall_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                          col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                          relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    \n",
    "    df_result = pd.DataFrame(\n",
    "        {   \"Dataset\": data_size,\n",
    "            \"K\": K,\n",
    "            \"MAP\": eval_map,\n",
    "            \"nDCG@k\": eval_ndcg,\n",
    "            \"Precision@k\": eval_precision,\n",
    "            \"Recall@k\": eval_recall,\n",
    "            \"Train time\": time_train,\n",
    "            \"Test time\": time_test\n",
    "        }, \n",
    "        index=[0]\n",
    "    )\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model application, performance and analysis of the results  \n",
    "\n",
    "The model has been implemented as a Tensorflow (TF) class with the TF session hidden inside the `fit()` method, so that no explicit call is needed. The algorithm operates in three different steps: \n",
    "\n",
    "- Model initialization: This is where we tell TF how to build the computational graph. The main parameters to specify are the number of hidden units, the number of training epochs and the minibatch size. \n",
    "\n",
    "- Model fit: This is where we train the model on the data. The method takes two arguments: the training and test set matrices. Note that the model is trained **only** on the training set, the test set is used to display the test set accuracy of the trained model, that in turn is an estimation of the generazation capabilities of the algorithm. It is generally useful to look at these quantities to have a first idea of the optimization behaviour.  \n",
    "\n",
    "- Model prediction: This is where we generate ratings for the unseen items. Once the model has been trained and we are satisfied with its overall accuracy, we sample new ratings from the learned distribution. In particular, we extract the top_k (e.g. 10) most relevant recommendations according to some predefined scorea. The prediction is then returned in a dataframe format ready to be analysed and deployed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 1m Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "#First we initialize the model class\n",
    "model_1m = RBM(hidden_units= 1200, training_epoch = 30, minibatch_size= 350, with_metrics=True, **header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first time the fit method is called it may take longer to return the result. This is due to the fact that TF needs to initialized the GPU session. You will notice that this is not the case when training the algorithm the second or more times. As for the `minibatch_size`, you would like to choose a value that gives you a good generalization error while mantaining a reasonable running time. The lower the size, the closer you get to stochastic gradient descent, but training takes longer. A big size value (say 1/2 of batch size) will speed up training but will increase the generalization error.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the computational graph\n",
      "training epoch 0 rmse Train 0.960365\n",
      "training epoch 10 rmse Train 0.901554\n",
      "training epoch 20 rmse Train 0.865822\n",
      "training epoch 30 rmse Train 0.848922\n",
      "done training, Training time 11.8457502\n",
      "Train set accuracy 0.3520382\n",
      "Test set accuracy 0.3526532\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Model Fit\n",
    "train_time = model_1m.fit(Xtr_1m, Xtst_1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we evauate the Root mean squared error to have an idea of how learning is proceeding. Remember that in the RBM this is not the quantity being minimized, but plotting the rmse per epoch gives us a rough understanding of how learning is proceeding and how we should adjust the hyper parameters. Generally, we would like to see the rmse decrease monotonically as a function of the learning epochs. Even though you may be using an automated hyper parameter optimization method, I strongly suggest to spend some time to manually inspect the learning process; this will give you an idea of the value range to expect for the hyperparameters. Finally, note that most automated hyperparameters search methods are optimized for supervised learning, so they may not work as well for unsupervised tasks. \n",
    "\n",
    "The two final scores are the train/test mean average accuracies across the all set together with their difference. This has been defined as: \n",
    "\n",
    "$$ AC = \\frac{1}{m} \\sum_{\\mu=1}^{m} \\sum_{i=1}^{N_v} \\frac{1}{s_i} \\, I(v=vp)_{\\mu,i}, $$\n",
    "\n",
    "where $m$ = total number of users, $N_v$ = Total number of items $\\equiv$ number of visible units and $s_i$= the number of non-zero elements per row, i.e. the per user total number of ratings. \n",
    "Remember that for a model to generalize well, the difference between train and test metrics should not be too big. In order to visualize these online metrics, choose `with_metrics =True` in the `RBM()` model function. When evaluating metrics, the model takes a bit longer to run, but you need to do so only in the exploratory phase of your work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Model Evaluation\n",
    "\n",
    "To evaluate the model performance and compare it against the other algorithms in this repository, we use the `recommend_k_items()` method. Note that we pass 'maps' as a second argument in order to return the correct user/item IDs in a pandas dataframe format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done recommending items, time 1.2281962\n",
      "Extracting top 10 elements\n"
     ]
    }
   ],
   "source": [
    "#number of top score elements to be recommended  \n",
    "K = 10\n",
    "\n",
    "#Model prediction on the test set Xtst. \n",
    "top_k_1m, test_time =  model_1m.recommend_k_items(Xtst_1m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top_k returns the first K elements having the highest recommendation score. Here the recommendation score is evaluated by multiplying the predicted rating by its probability, i.e. the confidence the algorithm has about its output. So if we have two items both with predicted ratings 5, but one with probability 0.5 and the other 0.9, the latter will be considered more relevant. In order to inspect the prediction and use the evaluation metrics in this repository, we convert both top_k and Xtst to pandas dataframe format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_df_1m = am1m.map_back_sparse(top_k_1m, kind = 'prediction')\n",
    "test_df_1m = am1m.map_back_sparse(Xtst_1m, kind = 'ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>K</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mv 1m</td>\n",
       "      <td>10</td>\n",
       "      <td>0.381799</td>\n",
       "      <td>0.844634</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.398334</td>\n",
       "      <td>11.84575</td>\n",
       "      <td>1.228196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset   K       MAP    nDCG@k  Precision@k  Recall@k  Train time  \\\n",
       "0   mv 1m  10  0.381799  0.844634     0.748344  0.398334    11.84575   \n",
       "\n",
       "   Test time  \n",
       "0   1.228196  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_1m= ranking_metrics(\n",
    "    data_size = \"mv 1m\",\n",
    "    data_true =test_df_1m,\n",
    "    data_pred =top_k_df_1m,\n",
    "    time_train=train_time,\n",
    "    time_test =test_time,\n",
    "    K =10)\n",
    "\n",
    "rating_1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, one should train the model until the cost function becomes flat but often an \"early stopping\" does the job too. In the example above we decided to train the algorithm in order to have higher ranking metrics. A faster optimization will do as well, but it will decrease the raking metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 100k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "#100k\n",
    "model_100k = RBM(hidden_units= 600, training_epoch = 30, minibatch_size= 60,keep_prob= 0.9, with_metrics = True, **header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the computational graph\n",
      "training epoch 0 rmse Train 0.944547\n",
      "training epoch 10 rmse Train 0.800558\n",
      "training epoch 20 rmse Train 0.787363\n",
      "training epoch 30 rmse Train 0.778703\n",
      "done training, Training time 2.7783282\n",
      "Train set accuracy 0.3618092\n",
      "Test set accuracy 0.3637322\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_time = model_100k.fit(Xtr_100k, Xtst_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done recommending items, time 0.1529842\n",
      "Extracting top 10 elements\n"
     ]
    }
   ],
   "source": [
    "#Model prediction on the test set Xtst. \n",
    "top_k_100k, test_time =  model_100k.recommend_k_items(Xtst_100k)\n",
    "\n",
    "#to df\n",
    "top_k_df_100k = am100k.map_back_sparse(top_k_100k, kind = 'prediction')\n",
    "test_df_100k = am100k.map_back_sparse(Xtst_100k, kind = 'ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>K</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mv 100k</td>\n",
       "      <td>10</td>\n",
       "      <td>0.410181</td>\n",
       "      <td>0.822208</td>\n",
       "      <td>0.703287</td>\n",
       "      <td>0.437869</td>\n",
       "      <td>2.778328</td>\n",
       "      <td>0.152984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset   K       MAP    nDCG@k  Precision@k  Recall@k  Train time  \\\n",
       "0  mv 100k  10  0.410181  0.822208     0.703287  0.437869    2.778328   \n",
       "\n",
       "   Test time  \n",
       "0   0.152984  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_100k= ranking_metrics(\n",
    "    data_size = \"mv 100k\",\n",
    "    data_true =test_df_100k,\n",
    "    data_pred =top_k_df_100k,\n",
    "    time_train=train_time,\n",
    "    time_test =test_time,\n",
    "    K=10) \n",
    "\n",
    "eval_100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python (reco_full)",
   "language": "python",
   "name": "reco_full"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
