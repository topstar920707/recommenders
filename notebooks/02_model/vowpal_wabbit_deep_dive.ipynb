{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Using Vowpal Wabbit for Recommendations</h1>\n",
    "\n",
    "<img src=\"https://github.com/VowpalWabbit/vowpal_wabbit/blob/master/logo_assets/vowpal-wabbits-github-logo.png?raw=true\" height=\"30%\" width=\"30%\" alt=\"Vowpal Wabbit\">\n",
    "</center>\n",
    "\n",
    "[Vowpal Wabbit](https://github.com/VowpalWabbit/vowpal_wabbit) is a fast online machine learning library that implements several algorithms relevant to the recommendation use case.\n",
    "\n",
    "The main advantage of Vowpal Wabbit (VW) is that training is done in an online fashion typically using Stochastic Gradient Descent or similar variants, which allows it to scale well to very large datasets. Additionally, it is optimized to run very quickly and can support distributed training scenarios for extremely large datasets.\n",
    "\n",
    "In this notebook we demonstrate how to use the VW library to generate recommendations on the [Movielens](https://grouplens.org/datasets/movielens/) dataset.\n",
    "\n",
    "Several things are worth noting in how VW is being used in this notebook. By leveraging an Azure Data Science Virtual Machine ([DSVM](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/)), VW comes pre-installed and can be used directly from the command line. There are also python bindings to be able to use VW within a python environment and even a wrapper conforming to the SciKit-Learn Estimator API. However, the python bindings must be installed as an additional python package with Boost dependencies, so for simplicity's sake execution of VW is done via a subprocess call mimicking what would happen from the command line execution of the model.\n",
    "\n",
    "VW expects a specific [input format](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format), and to_vw() below is a convenience function to convert the standard movielens dataset into that format. Datafiles then are written to disk and passed to VW for training.\n",
    "\n",
    "The examples shown are to demonstrate functional capabilities not to indicate performance advantages of different approaches. There are several hyper-parameters that can greatly impact performance of VW models (see [command line options](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Command-Line-Arguments)). To properly compare approaches it is helpful to learn about and tune these parameters for production workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Environment Setup</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import run\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from reco_utils.dataset.movielens import load_pandas_df\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.evaluation.python_evaluation import rmse, mae, exp_var, rsquared, get_top_k_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vw(df, output, logistic=False):\n",
    "    \"\"\"Convert Pandas DataFrame to vw input format\n",
    "    Args:\n",
    "        df (pd.DataFrame): input DataFrame\n",
    "        output (str): path to output file\n",
    "    \"\"\"\n",
    "    with open(output, 'w') as f:\n",
    "        tmp = df.reset_index()\n",
    "\n",
    "        # we need to reset the rating type to an integer to simplify the vw formatting\n",
    "        tmp['rating'] = tmp['rating'].astype('int64')\n",
    "        \n",
    "        # convert rating to binary value\n",
    "        if logistic:\n",
    "            tmp['rating'] = tmp['rating'].apply(lambda x: 1 if x >= 3 else -1)\n",
    "        \n",
    "        for _, row in tmp.iterrows():\n",
    "            f.write('{rating} {index}|u {userID} |i {itemID}\\n'.format_map(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vw(train_params, test_params, test_data, prediction_path):\n",
    "    \"\"\"Convenience function to train, test, and show metrics of interest\n",
    "    Args:\n",
    "        train_params (str): vw training parameters\n",
    "        test_params (str): vw testing parameters\n",
    "        test_data (pd.dataFrame): test data\n",
    "        prediction_path (str): path to vw prediction output   \n",
    "    \"\"\"\n",
    "\n",
    "    # train model\n",
    "    run(train_params.split(' '), check=True)\n",
    "    \n",
    "    # test model\n",
    "    run(test_params.split(' '), check=True)\n",
    "    \n",
    "    # read in predictions\n",
    "    pred_data = pd.read_csv(prediction_path, delim_whitespace=True, names=['prediction'], index_col=1).join(test_data)\n",
    "    \n",
    "    # ensure results are integers in correct range\n",
    "    pred_data['prediction'] = pred_data['prediction'].apply(lambda x: int(max(1, min(5, round(x)))))\n",
    "\n",
    "    for f in [rmse, mae, rsquared, exp_var]:\n",
    "        print('{name}: {metric}'.format(name=f.__name__.upper(), metric=f(test_data, pred_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp directory to maintain data files\n",
    "tmpdir = TemporaryDirectory()\n",
    "\n",
    "model_path = os.path.join(tmpdir.name, 'vw.model')\n",
    "train_path = os.path.join(tmpdir.name, 'train.dat')\n",
    "test_path = os.path.join(tmpdir.name, 'test.dat')\n",
    "train_logistic_path = os.path.join(tmpdir.name, 'train_logistic.dat')\n",
    "test_logistic_path = os.path.join(tmpdir.name, 'test_logistic.dat')\n",
    "prediction_path = os.path.join(tmpdir.name, 'prediction.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load & Transform Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movielens data (use the 1M dataset)\n",
    "df = load_pandas_df('1m')\n",
    "\n",
    "# split data to train and test sets, default values take 75% of each users ratings as train, and 25% as test\n",
    "train, test = python_stratified_split(df)\n",
    "\n",
    "# save train and test data in vw format\n",
    "to_vw(df=train, output=train_path)\n",
    "to_vw(df=test, output=test_path)\n",
    "\n",
    "# save data for logistic regression (requires adjusting the label)\n",
    "to_vw(df=train, output=train_logistic_path, logistic=True)\n",
    "to_vw(df=test, output=test_logistic_path, logistic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression Based Recommendations</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering different approaches for solving a problem with machine learning it is helpful to generate a baseline approach to understand how more complex solutions perform across dimensions of performance, time, and resource (memory or cpu) usage.\n",
    "\n",
    "One of the most basic approaches for a recommendation engine is to simply learn a linear regression model that is trained on examples of ratings as the target variable and corresponding user ids and movie ids as independent features.\n",
    "\n",
    "By passing each user-item rating in as an example the model will begin to learn weights based on average ratings for each user as well as average ratings per item.\n",
    "\n",
    "VW uses linear regression by default, so no extra command line options are needed beyond specifying where to locate the model and the data.\n",
    "\n",
    "This however generates predicted ratings which are no longer integers, so some additional adjustments can be made at prediction time to convert them back to the integer scale of 1 through 5 if necessary. Here this is done in the evaluate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9606618288218944\n",
      "MAE: 0.6868742202744634\n",
      "RSQUARED: 0.2619950895104812\n",
      "EXP_VAR: 0.2620255308898497\n",
      "CPU times: user 1.67 s, sys: 47.3 ms, total: 1.72 s\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_params = 'vw -f {model} -d {data}'.format(model=model_path, data=train_path)\n",
    "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n",
    "\n",
    "run_vw(train_params=train_params, \n",
    "       test_params=test_params, \n",
    "       test_data=test, \n",
    "       prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar alternative is to leverage multinomial classification, which treats each rating value as a distinct class. \n",
    "\n",
    "This avoids any non integer results, but also reduces the training data for each class which could lead to poorer performance if the counts of different rating levels are skewed.\n",
    "\n",
    "Basic multiclass logistic regression can be accomplished using the One Against All approach specified by the '--oaa N' option, where N is the number of classes and proving the logistic option for the loss function to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0615890476546246\n",
      "MAE: 0.7146124564153418\n",
      "RSQUARED: 0.09877954418265689\n",
      "EXP_VAR: 0.12455611599414951\n",
      "CPU times: user 2.11 s, sys: 31.7 ms, total: 2.14 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_params = 'vw --loss_function logistic --oaa 5 -f {model} -d {data}'.format(model=model_path, data=train_path)\n",
    "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n",
    "\n",
    "run_vw(train_params=train_params,\n",
    "       test_params=test_params,\n",
    "       test_data=test,\n",
    "       prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, one might simply be interested in whether the user likes or dislikes an item and we can adjust the input data to represent a binary outcome, where ratings in (1,3] are dislikes (negative results) and (3,5] are likes (positive results).\n",
    "\n",
    "This framing allows for a simple logistic regression model to be applied. To perform logistic regression the loss_function parameter is changed to 'logistic' and the target label is switched to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.764643840355633\n",
      "MAE: 1.4427961357602124\n",
      "RSQUARED: -1.490189004814928\n",
      "EXP_VAR: -0.07611382892527008\n",
      "CPU times: user 2.05 s, sys: 43.4 ms, total: 2.09 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_params = 'vw --loss_function logistic -f {model} -d {data}'.format(model=model_path, data=train_logistic_path)\n",
    "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_logistic_path, pred=prediction_path)\n",
    "\n",
    "run_vw(train_params=train_params,\n",
    "       test_params=test_params,\n",
    "       test_data=test,\n",
    "       prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have treated the user features and item features independently, but taking into account interactions between features can provide a mechanism to learn more fine grained preferences of the users.\n",
    "\n",
    "To generate interaction features use the quadratic command line argument and specify the namespaces that should be combined: '-q ui' combines the user and item namespaces based on the first letter of each.\n",
    "\n",
    "When generating interaction terms one thing to consider is the [hash space](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction) used for the features. It can be beneficial to increase the size of the space to reduce unwanted collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9639071277012671\n",
      "MAE: 0.6913606410543489\n",
      "RSQUARED: 0.2570004245847899\n",
      "EXP_VAR: 0.25724987674764754\n",
      "CPU times: user 1.92 s, sys: 39.5 ms, total: 1.96 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_params = 'vw -b 24 -q ui -f {model} -d {data}'.format(model=model_path, data=train_path)\n",
    "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n",
    "\n",
    "run_vw(train_params=train_params,\n",
    "       test_params=test_params,\n",
    "       test_data=test,\n",
    "       prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Matrix Factorization Based Recommendations</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above approaches train a regression model, but VW also supports matrix factorization with two different approaches.\n",
    "\n",
    "The first approach is called using the '--rank' command line argument and performs matrix factorization based on Singular Value Decomposition (SVD).\n",
    "\n",
    "See the [Matrix Factorization Example](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Matrix-factorization-example) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0159629286560183\n",
      "MAE: 0.7659943699817664\n",
      "RSQUARED: 0.17458205809330873\n",
      "EXP_VAR: 0.22847638017481597\n",
      "CPU times: user 2.45 s, sys: 35.4 ms, total: 2.48 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_params = 'vw --rank 5 -qui -f {model} -d {data}'.format(model=model_path, data=train_path)\n",
    "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n",
    "\n",
    "run_vw(train_params=train_params,\n",
    "       test_params=test_params,\n",
    "       test_data=test,\n",
    "       prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach based on [Rendel's factorization machines](https://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/Rendle2010FM.pdf) is called using '--lrq' (low rank quadratic). More LRQ details in this [demo](https://github.com/VowpalWabbit/vowpal_wabbit/tree/master/demo/movielens).\n",
    "\n",
    "This learns two lower rank matrices which are multiplied to generate an approximation of the user-item rating matrix. Compressing the matrix in this way leads to learning generalizable factors which avoids some of the limitations of using regression models with extremely sparse interaction features. This can lead to better convergence and smaller on-disk models.\n",
    "\n",
    "An additional term to improve performance is --lrqdropout which will dropout columns during training. This however tends to increase the optimal rank size. Other parameters such as L2 regularization can help avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9825091378096849\n",
      "MAE: 0.7003134896516426\n",
      "RSQUARED: 0.2280460770162016\n",
      "EXP_VAR: 0.22805835662769547\n",
      "CPU times: user 2 s, sys: 43.5 ms, total: 2.04 s\n",
      "Wall time: 3.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_params = 'vw --lrq ui7 --lrqdropout -f {model} -d {data}'.format(model=model_path, data=train_path)\n",
    "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n",
    "\n",
    "run_vw(train_params=train_params,\n",
    "       test_params=test_params,\n",
    "       test_data=test,\n",
    "       prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scoring</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training a model with any of the above approaches, the model can be used to score potential user-pairs in offline batch mode, or in a real-time scoring mode. The example below shows how to leverage the utilities in the reco_utils directory to  generate Top-K recommendations from offline scored output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9673615767747724\n",
      "MAE: 0.6877662568523178\n",
      "RSQUARED: 0.25011863284471003\n",
      "EXP_VAR: 0.2501312700738213\n"
     ]
    }
   ],
   "source": [
    "# store all data\n",
    "data_path = os.path.join(tmpdir.name, 'all.dat')\n",
    "to_vw(df=df, output=data_path)\n",
    "\n",
    "# predict on the full set of users\n",
    "train_params = 'vw --lrq ui7 --lrqdropout -f {model} -d {data}'.format(model=model_path, data=train_path)\n",
    "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=data_path, pred=prediction_path)\n",
    "\n",
    "run_vw(train_params=train_params,\n",
    "       test_params=test_params,\n",
    "       test_data=df,\n",
    "       prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>prediction</th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3.0</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1357</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978298709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3068</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1537</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978299620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2194</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978299297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1103</td>\n",
       "      <td>3.0</td>\n",
       "      <td>978298905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2997</td>\n",
       "      <td>3.0</td>\n",
       "      <td>978298147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1291</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>196</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978298296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978297512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>202</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2858</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978297039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0  level_1  prediction  userID  itemID  rating  timestamp\n",
       "0         0        0         5.0       1    1193     5.0  978300760\n",
       "1         0        2         5.0       1     914     3.0  978301968\n",
       "2         0        3         5.0       1    3408     4.0  978300275\n",
       "3         0        4         5.0       1    2355     5.0  978824291\n",
       "4         0        5         5.0       1    1197     3.0  978302268\n",
       "5         1       53         5.0       2    1357     5.0  978298709\n",
       "6         1       54         5.0       2    3068     4.0  978299000\n",
       "7         1       55         5.0       2    1537     4.0  978299620\n",
       "8         1       57         5.0       2    2194     4.0  978299297\n",
       "9         1       61         5.0       2    1103     3.0  978298905\n",
       "10        2      193         5.0       3    2997     3.0  978298147\n",
       "11        2      195         5.0       3    1291     4.0  978297600\n",
       "12        2      196         5.0       3    1259     5.0  978298296\n",
       "13        2      201         5.0       3     260     5.0  978297512\n",
       "14        2      202         5.0       3    2858     4.0  978297039"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load predictions and filter to test set\n",
    "test_users = [1, 2, 3]\n",
    "pred_data = pd.read_csv(prediction_path, delim_whitespace=True, names=['prediction'], index_col=1).join(df)\n",
    "test_user_data = pred_data[pred_data['userID'].isin(test_users)]\n",
    "\n",
    "get_top_k_items(test_user_data, col_rating='prediction', k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cleanup</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco)",
   "language": "python",
   "name": "reco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
