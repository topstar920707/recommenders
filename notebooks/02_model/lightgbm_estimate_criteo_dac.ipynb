{"cells":[{"cell_type":"code","source":["## parameters:\n## run describe on the input table\ndescribe = False\n## save the result of the preprocessing pipeline as a table.\nsave_as_table = True\n\n## for testing - pipeline will include categorical variables 0:n_sparse_features in the features table to estimate the model.\n## third string variable was the first with missing values...\nn_sparse_features = 26\n## for testing - pipeline will include numeric variables 0:n_num_features in the features table to estimate the model.\nn_num_features = 13\nclassifier_lightgbm_iterations = 3  \nn_folds = 4                         \nnum_leaves_grid = [32,64]\n\nreplace_small_levels = True\nsmall_level_freq_thresh = 10 ## same threshold used by winners: https://www.csie.ntu.edu.tw/~r01922136/kaggle-2014-criteo.pdf\n## constructed variables:\ntable_to_save = 'criteo_dac_proc_{}sparse_{}num_freqthresh{}'.format(n_sparse_features,n_num_features, small_level_freq_thresh)\n\nprint(table_to_save)\n\noutput_dir = 'dbfs:/FileStore'"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["## load data loader"],"metadata":{}},{"cell_type":"code","source":["# from reco_utils.dataset.criteo_dac import load_spark_df"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["## read in the data - this takes some time...8-10 minutes\n# df = load_spark_df(spark=spark, dbutils=dbutils)\n## print('writing to parquet...')\n## df.write.parquet('dbfs:/FileStore/dac_train.parquet')\ndf = sqlContext.read.parquet(\"/FileStore/dac_train.parquet\")\n# Could ADLS be causing issues?\n# df = sqlContext.read.parquet(\"/mnt/adlsgen2/dac_train.parquet\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["if describe:\n  ## This can take quite a bit of time...\n  cur_descr = df.describe()\n  display(cur_descr)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["## boundary check n_sparse_features\nif n_sparse_features < 0 or n_sparse_features > 26:\n  raise ValueError('n_sparse_features must be between 0 and 26...')\nelse:\n  print('Running with {} sparse (i.e. categorical) features.'.format(n_sparse_features))\n  \nif n_num_features < 0 or n_num_features > 13:\n  raise ValueError('n_num_features must be between 0 and 13...')\nelse:\n  print('Running with {} numeric features.'.format(n_num_features))\n  \nif n_num_features+n_sparse_features < 1:\n  raise ValueError('total number of features is less than 1.')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Imports"],"metadata":{}},{"cell_type":"code","source":["import os\n\n## for feature engineering:\nfrom pyspark.ml.feature import (Imputer,StringIndexer,VectorAssembler)\nfrom pyspark.ml.pipeline import Pipeline\n\n## for modeling:\nfrom mmlspark import LightGBMClassifier\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nfrom pyspark.sql.functions import col, when\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Define what features to process\n\n- `features` maps to numeric features that need to have missing values replaced\n- `sparse_features` maps to the first `n_sparse_features` categorical / string variables"],"metadata":{}},{"cell_type":"code","source":["\n## features are int features (does median imputation)\nfeatures = [x for x in df.columns if x[0:3] == 'int'][0:n_num_features]\n## sparse_features are str features \nsparse_features = [x for x in df.columns if x[0:3] == 'cat'][0:n_sparse_features]\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Fill Missing Values in String Vars"],"metadata":{}},{"cell_type":"code","source":["## fill  missing values in string variables\ndf = df.na.fill('M', subset = sparse_features)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Replace infrequent levels with a special value"],"metadata":{}},{"cell_type":"code","source":["level_counts_dict = {i: df.groupby(i).count().\n select(i, when(col('count') > small_level_freq_thresh, col(i)).otherwise(\"RARE\").alias(i+'_fcut')) for i in sparse_features}"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["## now join them back...\nfor i in sparse_features:\n  df = df.join(level_counts_dict[i], i, how = 'left')"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## Recast `int` variables to `float`\n\n`Imputer()` only works with `float` or `double` type. We could import the data as floats, or run directly on ints using the `df.na.fill()` method.\n\nCurrently using this approach to keep the work in the pipeline."],"metadata":{}},{"cell_type":"code","source":["## cast ints to floats, because Imputer only works with floats\n## and only pull out the strings with the frequency cutoff\nsql_lst = ['cast({} as float) {}'.format(x, x) for x in features] + [f + '_fcut' for f in sparse_features] + ['label']\nrecast_df = df.selectExpr(*[sql_lst])"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["## save for now...\n## about 25 minutes on l16s x 4\noutfile = os.path.join('dbfs:/FileStore/',table_to_save+'.parquet')\ndbutils.fs.rm(outfile, recurse = True)\nrecast_df.write.parquet(outfile)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["recast_df = sqlContext.read.parquet(os.path.join('dbfs:/FileStore/',table_to_save+'.parquet'))"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["pipeline = Pipeline(stages=[\n  Imputer(strategy='median',\n          inputCols=features,\n          outputCols=[f + '_imp' for f in features]),\n  # LightGBM can handle categoricals directly if StringIndexer is used through meta-data\n  *[StringIndexer(inputCol=f + '_fcut' , outputCol=f+'_vec') for f in sparse_features],\n  VectorAssembler(inputCols= [f + '_imp' for f in features] +\n                  [f + '_vec' for f in sparse_features],\n                  outputCol='features')\n])"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# fit is needed if you use imputer..\n## 2.5 minutes\ntrain_proc_df = pipeline.fit(recast_df).transform(recast_df)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["\ntry:\n  if save_as_table:\n    outFile = os.path.join(output_dir, table_to_save+'_postpipe.parquet')\n    train_proc_df.write.parquet(outFile)\nexcept:\n  pass"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["## describe label to see balance\ndisplay(train_proc_df.select(['label']).describe())"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# train_proc_df.printSchema()\n# train_proc_df.select('features').printSchema()\n# display(train_proc_df.select('features').limit(2))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["## Set up the Classifier:"],"metadata":{}},{"cell_type":"code","source":["help(LightGBMClassifier)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["model = LightGBMClassifier(featuresCol='features',\n                           labelCol='label',\n                           numIterations=classifier_lightgbm_iterations,\n                           numLeaves=31,\n                           maxDepth=10,\n                           isUnbalance=True)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["## Fit the model.\n\nto see if simple use-case works"],"metadata":{}},{"cell_type":"code","source":["## try just fitting the model, not with CV\n## model fit works, sometimes.\n## took 5 minutes with 3 cat features...\nmodel_fit = model.fit(train_proc_df)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["grid = (ParamGridBuilder()\n        .addGrid(model.numLeaves, num_leaves_grid) \n        .build())\n\nevaluator = BinaryClassificationEvaluator(labelCol='label')\n\ncv = CrossValidator(estimator=model, estimatorParamMaps=grid, evaluator=evaluator, numFolds=n_folds)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["## estimate the model:\n## throws an error:\ncv_fit = cv.fit(train_proc_df)\n"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":32}],"metadata":{"name":"lightgbm_estimate_criteo_dac","notebookId":1706216560221809},"nbformat":4,"nbformat_minor":0}
