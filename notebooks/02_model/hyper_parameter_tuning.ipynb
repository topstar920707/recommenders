{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.2\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.hyperdrive import *\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to a workspace from `.\\aml_config\\config.json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\jumin\\git\\Recommenders\\notebooks\\02_model\\aml_config\\config.json\n",
      "Workspace name:  junmin-aml-workspace\n"
     ]
    }
   ],
   "source": [
    "# Connect to a workspace\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_workspaceblobstore"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.get_default_datastore().as_mount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a remote compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "Succeeded.....................\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2018-12-20T14:47:28.945000+00:00', 'creationTime': '2018-12-20T14:45:00.343249+00:00', 'currentNodeCount': 1, 'errors': None, 'modifiedTime': '2018-12-20T14:45:28.941889+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 1, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 1, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n",
      "gpu-cluster AmlCompute Succeeded\n"
     ]
    }
   ],
   "source": [
    "CLUSTER_NAME = 'gpu-cluster'\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', # STANDARD_NC24s_v3\n",
    "                                                           min_nodes=1,\n",
    "                                                           max_nodes=4)\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(compute_target.status.serialize())\n",
    "\n",
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'movielens_100k'\n",
    "\n",
    "# TODO Download dataset and upload to datastore\n",
    "# ds = ws.get_default_datastore()\n",
    "# ds.upload(src_dir='./'+DATA_PATH, target_path=DATA_PATH, overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEP_MODEL_TRAIN_SCRIPT = 'deep_model_train.py'\n",
    "SCRIPT_FOLDER = './model_train'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set (or search) hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETER_TUNING = True\n",
    "\n",
    "if HYPERPARAMETER_TUNING:\n",
    "    # vs. Estimator\n",
    "    est = TensorFlow(source_directory=SCRIPT_FOLDER,\n",
    "                     script_params={'--data-folder': ws.get_default_datastore().as_mount()},\n",
    "                     compute_target=compute_target,\n",
    "                     entry_script=DEEP_MODEL_TRAIN_SCRIPT, \n",
    "                     use_gpu=True)\n",
    "    \n",
    "    # vs. GridParameterSampling\n",
    "    ps = RandomParameterSampling(\n",
    "        {\n",
    "    #         '--batch-size': choice(25, 50, 100),\n",
    "            '--first-layer-neurons': choice(10, 50, 200, 300, 500),\n",
    "            '--second-layer-neurons': choice(10, 50, 200, 500),\n",
    "            '--learning-rate': loguniform(-6, -1)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Early termnination policy\n",
    "    policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "    hdrc = HyperDriveRunConfig(estimator=est, \n",
    "                               hyperparameter_sampling=ps, \n",
    "                               policy=policy, \n",
    "                               primary_metric_name='validation_acc', \n",
    "                               primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                               max_total_runs=8,\n",
    "                               max_concurrent_runs=4)\n",
    "    run = exp.submit(config=htc)\n",
    "else:\n",
    "    est = TensorFlow(source_directory=SCRIPT_FOLDER,\n",
    "                     script_params={\n",
    "                         '--data-folder': ws.get_default_datastore().as_mount(),\n",
    "                         '--batch-size': 50,\n",
    "                         '--first-layer-neurons': 300,\n",
    "                         '--second-layer-neurons': 100,\n",
    "                         '--learning-rate': 0.01\n",
    "                     },\n",
    "                     compute_target=compute_target,\n",
    "                     entry_script=DEEP_MODEL_TRAIN_SCRIPT, \n",
    "                     use_gpu=True)\n",
    "    run = exp.submit(est)\n",
    "    \n",
    "    \n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_file_names())\n",
    "model = best_run.register_model(model_name='tf-dnn', model_path='outputs/model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Checks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create AmlCompute cluster\n",
    "\n",
    "\n",
    "# Create an experiment to track the runs in the workspace\n",
    "deep_model_exp = Experiment(workspace=ws, name='deep-model')\n",
    "\n",
    "# Start a run\n",
    "deep_model_run = exp.start_logging()\n",
    "\n",
    "# Log a number\n",
    "deep_model_run.log(\"my_number\", 42)\n",
    "deep_model_run.log_list(\"my_list\", [1, 2, 3])\n",
    "deep_model_run.complete()\n",
    "\n",
    "print(deep_model_run.get_portal_url())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "import math\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "         'learning_rate': loguniform(math.log(1e-4), math.log(1e-6)),\n",
    "})\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(\n",
    "     estimator=estimator,\n",
    "     hyperparameter_sampling=param_sampling,\n",
    "     primary_metric_name='f1',\n",
    "     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "     max_total_runs=16,\n",
    "     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up resources\n",
    "ws.delete(delete_dependent_resources=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [Fine-tune natural language processing models using Azure Machine Learning service](https://azure.microsoft.com/en-us/blog/fine-tune-natural-language-processing-models-using-azure-machine-learning-service/)\n",
    "* [Training, hyperparameter tune, and deploy with TensorFlow](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-tensorflow/train-hyperparameter-tune-deploy-with-tensorflow.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
