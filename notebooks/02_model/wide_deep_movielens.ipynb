{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Model for Movie Recommendation\n",
    "\n",
    "### Prerequisite\n",
    "* `tensorflow`\n",
    "\n",
    "In this example, we utilize TensorFlow's higher level Estimator API to build wide-and-deep model for movie recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    rmse, mae, rsquared, exp_var,\n",
    "    map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:CPU:0', '/device:XLA_CPU:0', '/device:XLA_GPU:0', '/device:GPU:0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "devices = device_lib.list_local_devices()\n",
    "[x.name for x in devices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId  Rating  Timestamp\n",
       "0     196      242     3.0  881250949\n",
       "1     186      302     3.0  891717742\n",
       "2      22      377     1.0  878887116\n",
       "3     244       51     2.0  880606923\n",
       "4     166      346     1.0  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['UserId','MovieId','Rating','Timestamp'],\n",
    "    # TODO For now, not using genres YET\n",
    "    load_genres=False\n",
    ")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 943 users to 5-dim vector\n",
      "Embedding 1682 items to 6-dim vector\n"
     ]
    }
   ],
   "source": [
    "# Distinct users and items\n",
    "user_list = data['UserId'].unique()\n",
    "item_list = data['MovieId'].unique()\n",
    "\n",
    "# Rule of thumb for embedding_dimensions =  number_of_categories ** 0.25\n",
    "USER_EMBEDDING_DIM = int(len(user_list) ** 0.25) # or 16\n",
    "ITEM_EMBEDDING_DIM = int(len(item_list) ** 0.25) # or 64\n",
    "print(\"Embedding {} users to {}-dim vector\".format(len(user_list), USER_EMBEDDING_DIM))\n",
    "print(\"Embedding {} items to {}-dim vector\".format(len(item_list), ITEM_EMBEDDING_DIM))\n",
    "\n",
    "# Convert a categorical feature, e.g. UserId or MovieId, into a lower-dimensional vector (embedding)\n",
    "user_id = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'UserId', user_list)\n",
    "user_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=user_id,\n",
    "    dimension=USER_EMBEDDING_DIM,\n",
    "    max_norm=USER_EMBEDDING_DIM**.5)\n",
    "\n",
    "item_id = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'MovieId', item_list)\n",
    "item_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=item_id,\n",
    "    dimension=ITEM_EMBEDDING_DIM,\n",
    "    max_norm=ITEM_EMBEDDING_DIM**.5)\n",
    "\n",
    "timestamp = tf.feature_column.numeric_column('Timestamp')\n",
    "\n",
    "# TODO numeric_column (w/ shape)\n",
    "# genres = tf.feature_column.numeric_column(\n",
    "#     'Genre', shape=(NUM_GENRES,), dtype=tf.uint8)\n",
    "\n",
    "deep_columns = [user_embedding, item_embedding, timestamp]  # TODO , genres]\n",
    "wide_columns = []  # TODO cross product transformation of user and item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tran and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       UserId  MovieId  Timestamp\n",
      "31450     496      136  876066424\n",
      "42809      64      101  889740225\n",
      "52419     158      471  880132513\n",
      "45663     198      652  884209569\n",
      "50696     749      121  878847645\n",
      "\n",
      "Labels:\n",
      "31450    1.0\n",
      "42809    2.0\n",
      "52419    4.0\n",
      "45663    3.0\n",
      "50696    3.0\n",
      "Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train, test = python_random_split(data, ratio=0.75, seed=123)\n",
    "\n",
    "train_x = train.copy()\n",
    "train_y = train_x.pop('Rating')\n",
    "test_x = test.copy()\n",
    "test_y = test_x.pop('Rating')\n",
    "\n",
    "print(train_x.head())\n",
    "print(\"\\nLabels:\")\n",
    "print(train_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection\n",
    "* `wide` - Linear model\n",
    "* `deep` - DNN model\n",
    "* `wide_deep` - Linear combination of the linear and DNN models\n",
    "\n",
    "(TODO)Model type: `regressor` or `classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wide', 'deep', or 'wide_deep' \n",
    "MODEL_TYPE = 'deep'\n",
    "HIDDEN_UNITS = [256, 256, 256, 128]\n",
    "# Model checkpoints folder\n",
    "MODEL_DIR = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fae1c17f940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# TODO set run config if needed\n",
    "if MODEL_TYPE == 'wide':\n",
    "    if len(wide_columns) == 0:\n",
    "        raise ValueError(\"No features have defined for the 'wide' model\")\n",
    "    model = tf.estimator.LinearRegressor(  # LinearClassifier(\n",
    "        model_dir=MODEL_DIR,\n",
    "        feature_columns=wide_columns,\n",
    "    )\n",
    "elif MODEL_TYPE == 'deep':\n",
    "    if len(deep_columns) == 0:\n",
    "        raise ValueError(\"No features have defined for the 'deep' model\")\n",
    "    model = tf.estimator.DNNRegressor(  # DNNClassifier(\n",
    "        model_dir=MODEL_DIR,\n",
    "        feature_columns=deep_columns,\n",
    "        hidden_units=HIDDEN_UNITS,\n",
    "        optimizer=tf.train.AdamOptimizer(),\n",
    "#         activation_fn=tf.nn.sigmoid,\n",
    "#         dropout=0.3,\n",
    "#         loss_reduction=tf.losses.Reduction.MEAN,\n",
    "#         batch_norm=False\n",
    "    )\n",
    "elif MODEL_TYPE == 'wide_deep':\n",
    "    if len(wide_columns) == 0 and len(deep_columns) == 0:\n",
    "        raise ValueError(\"No features have defined for the 'wide_deep' model\")\n",
    "    model = tf.estimator.DNNLinearCombinedRegressor(  # DNNLinearCombinedClassifier(\n",
    "        model_dir=MODEL_DIR,\n",
    "        # wide settings\n",
    "        linear_feature_columns=wide_columns,\n",
    "        # deep settings\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=HIDDEN_UNITS,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Model type should be either 'wide', 'deep', or 'wide_deep'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/jumin/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./models/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.975615e+17, step = 0\n",
      "INFO:tensorflow:global_step/sec: 115.375\n",
      "INFO:tensorflow:loss = 1075005600000.0, step = 100 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.477\n",
      "INFO:tensorflow:loss = 16948674.0, step = 200 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.13\n",
      "INFO:tensorflow:loss = 8898.426, step = 300 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.722\n",
      "INFO:tensorflow:loss = 8810.109, step = 400 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.951\n",
      "INFO:tensorflow:loss = 8353.259, step = 500 (0.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.72\n",
      "INFO:tensorflow:loss = 8778.246, step = 600 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.688\n",
      "INFO:tensorflow:loss = 8109.78, step = 700 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.835\n",
      "INFO:tensorflow:loss = 9728.315, step = 800 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.22\n",
      "INFO:tensorflow:loss = 9088.412, step = 900 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.571\n",
      "INFO:tensorflow:loss = 8519.102, step = 1000 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.312\n",
      "INFO:tensorflow:loss = 8699.685, step = 1100 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.91\n",
      "INFO:tensorflow:loss = 8919.544, step = 1200 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.581\n",
      "INFO:tensorflow:loss = 8438.738, step = 1300 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.919\n",
      "INFO:tensorflow:loss = 8994.007, step = 1400 (0.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.715\n",
      "INFO:tensorflow:loss = 10053.408, step = 1500 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.195\n",
      "INFO:tensorflow:loss = 8244.707, step = 1600 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.538\n",
      "INFO:tensorflow:loss = 10313.573, step = 1700 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.184\n",
      "INFO:tensorflow:loss = 10152.421, step = 1800 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.611\n",
      "INFO:tensorflow:loss = 9657.124, step = 1900 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.858\n",
      "INFO:tensorflow:loss = 10211.369, step = 2000 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.003\n",
      "INFO:tensorflow:loss = 7916.2036, step = 2100 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.57\n",
      "INFO:tensorflow:loss = 8587.68, step = 2200 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.797\n",
      "INFO:tensorflow:loss = 8201.74, step = 2300 (0.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.962\n",
      "INFO:tensorflow:loss = 601244100000000.0, step = 2400 (0.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.707\n",
      "INFO:tensorflow:loss = 56305370000.0, step = 2500 (0.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.139\n",
      "INFO:tensorflow:loss = 1089207.2, step = 2600 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.297\n",
      "INFO:tensorflow:loss = 3843.6733, step = 2700 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.642\n",
      "INFO:tensorflow:loss = 4141.46, step = 2800 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.386\n",
      "INFO:tensorflow:loss = 4101.54, step = 2900 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.037\n",
      "INFO:tensorflow:loss = 4164.6167, step = 3000 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.036\n",
      "INFO:tensorflow:loss = 4398.045, step = 3100 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.438\n",
      "INFO:tensorflow:loss = 3844.138, step = 3200 (0.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.405\n",
      "INFO:tensorflow:loss = 3837.512, step = 3300 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.735\n",
      "INFO:tensorflow:loss = 3942.5386, step = 3400 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.678\n",
      "INFO:tensorflow:loss = 4377.2007, step = 3500 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.573\n",
      "INFO:tensorflow:loss = 3795.1562, step = 3600 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.12\n",
      "INFO:tensorflow:loss = 4283.8457, step = 3700 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.052\n",
      "INFO:tensorflow:loss = 3657.5103, step = 3800 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.009\n",
      "INFO:tensorflow:loss = 3907.4858, step = 3900 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.818\n",
      "INFO:tensorflow:loss = 4068.6782, step = 4000 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.357\n",
      "INFO:tensorflow:loss = 4240.132, step = 4100 (0.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.618\n",
      "INFO:tensorflow:loss = 3732.849, step = 4200 (0.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.14\n",
      "INFO:tensorflow:loss = 4255.534, step = 4300 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.612\n",
      "INFO:tensorflow:loss = 3769.346, step = 4400 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.691\n",
      "INFO:tensorflow:loss = 3575.7117, step = 4500 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.353\n",
      "INFO:tensorflow:loss = 4074.812, step = 4600 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.297\n",
      "INFO:tensorflow:loss = 4545.4634, step = 4700 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.299\n",
      "INFO:tensorflow:loss = 3919.0989, step = 4800 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.074\n",
      "INFO:tensorflow:loss = 3975.0361, step = 4900 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.215\n",
      "INFO:tensorflow:loss = 4446.778, step = 5000 (0.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.298\n",
      "INFO:tensorflow:loss = 258645770000000.0, step = 5100 (0.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.893\n",
      "INFO:tensorflow:loss = 10794174000.0, step = 5200 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.523\n",
      "INFO:tensorflow:loss = 190110.73, step = 5300 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.038\n",
      "INFO:tensorflow:loss = 481.10455, step = 5400 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.648\n",
      "INFO:tensorflow:loss = 430.95602, step = 5500 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.689\n",
      "INFO:tensorflow:loss = 458.82217, step = 5600 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.555\n",
      "INFO:tensorflow:loss = 410.01736, step = 5700 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.653\n",
      "INFO:tensorflow:loss = 482.0265, step = 5800 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.088\n",
      "INFO:tensorflow:loss = 413.59393, step = 5900 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.384\n",
      "INFO:tensorflow:loss = 445.01498, step = 6000 (0.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.594\n",
      "INFO:tensorflow:loss = 414.79303, step = 6100 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.651\n",
      "INFO:tensorflow:loss = 431.19614, step = 6200 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.153\n",
      "INFO:tensorflow:loss = 434.35422, step = 6300 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.213\n",
      "INFO:tensorflow:loss = 416.94617, step = 6400 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.105\n",
      "INFO:tensorflow:loss = 489.4911, step = 6500 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.731\n",
      "INFO:tensorflow:loss = 484.6767, step = 6600 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.401\n",
      "INFO:tensorflow:loss = 435.53793, step = 6700 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.75\n",
      "INFO:tensorflow:loss = 404.5531, step = 6800 (0.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.546\n",
      "INFO:tensorflow:loss = 407.53494, step = 6900 (0.948 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 134.764\n",
      "INFO:tensorflow:loss = 420.58386, step = 7000 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.285\n",
      "INFO:tensorflow:loss = 381.7384, step = 7100 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.577\n",
      "INFO:tensorflow:loss = 508.60516, step = 7200 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.977\n",
      "INFO:tensorflow:loss = 440.88892, step = 7300 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.189\n",
      "INFO:tensorflow:loss = 458.9027, step = 7400 (0.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.093\n",
      "INFO:tensorflow:loss = 433.6165, step = 7500 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.411\n",
      "INFO:tensorflow:loss = 415.26874, step = 7600 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.508\n",
      "INFO:tensorflow:loss = 432.86987, step = 7700 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.175\n",
      "INFO:tensorflow:loss = 472.8913, step = 7800 (0.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.073\n",
      "INFO:tensorflow:loss = 455.38312, step = 7900 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.442\n",
      "INFO:tensorflow:loss = 448.27756, step = 8000 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.67\n",
      "INFO:tensorflow:loss = 945.5565, step = 8100 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.366\n",
      "INFO:tensorflow:loss = 483.44095, step = 8200 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.406\n",
      "INFO:tensorflow:loss = 450.901, step = 8300 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.007\n",
      "INFO:tensorflow:loss = 681.9743, step = 8400 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.194\n",
      "INFO:tensorflow:loss = 554.03723, step = 8500 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.003\n",
      "INFO:tensorflow:loss = 633.6369, step = 8600 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.538\n",
      "INFO:tensorflow:loss = 488.43073, step = 8700 (0.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.749\n",
      "INFO:tensorflow:loss = 599.6916, step = 8800 (0.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.748\n",
      "INFO:tensorflow:loss = 693.0198, step = 8900 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.192\n",
      "INFO:tensorflow:loss = 47350055000.0, step = 9000 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.492\n",
      "INFO:tensorflow:loss = 1030616.56, step = 9100 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.151\n",
      "INFO:tensorflow:loss = 476.1427, step = 9200 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.446\n",
      "INFO:tensorflow:loss = 449.82416, step = 9300 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.855\n",
      "INFO:tensorflow:loss = 431.3385, step = 9400 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.326\n",
      "INFO:tensorflow:loss = 381.9815, step = 9500 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.315\n",
      "INFO:tensorflow:loss = 380.01962, step = 9600 (0.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.373\n",
      "INFO:tensorflow:loss = 404.9217, step = 9700 (0.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.163\n",
      "INFO:tensorflow:loss = 433.40356, step = 9800 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.118\n",
      "INFO:tensorflow:loss = 393.07758, step = 9900 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.983\n",
      "INFO:tensorflow:loss = 399.87292, step = 10000 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.533\n",
      "INFO:tensorflow:loss = 476.72736, step = 10100 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.299\n",
      "INFO:tensorflow:loss = 444.0957, step = 10200 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.243\n",
      "INFO:tensorflow:loss = 395.58344, step = 10300 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.376\n",
      "INFO:tensorflow:loss = 449.4601, step = 10400 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.637\n",
      "INFO:tensorflow:loss = 402.64108, step = 10500 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.577\n",
      "INFO:tensorflow:loss = 431.1583, step = 10600 (0.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.348\n",
      "INFO:tensorflow:loss = 443.699, step = 10700 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.692\n",
      "INFO:tensorflow:loss = 1747.0171, step = 10800 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.985\n",
      "INFO:tensorflow:loss = 1116847900000.0, step = 10900 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.884\n",
      "INFO:tensorflow:loss = 2522276.5, step = 11000 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.946\n",
      "INFO:tensorflow:loss = 25563.223, step = 11100 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.103\n",
      "INFO:tensorflow:loss = 23963.904, step = 11200 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.125\n",
      "INFO:tensorflow:loss = 8956.4375, step = 11300 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.566\n",
      "INFO:tensorflow:loss = 8268.014, step = 11400 (0.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.847\n",
      "INFO:tensorflow:loss = 6854.709, step = 11500 (0.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.227\n",
      "INFO:tensorflow:loss = 5307.0586, step = 11600 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.102\n",
      "INFO:tensorflow:loss = 3065.3948, step = 11700 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.675\n",
      "INFO:tensorflow:loss = 1009.6876, step = 11800 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.224\n",
      "INFO:tensorflow:loss = 374.0113, step = 11900 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.882\n",
      "INFO:tensorflow:loss = 330.0929, step = 12000 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.882\n",
      "INFO:tensorflow:loss = 394.19522, step = 12100 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.849\n",
      "INFO:tensorflow:loss = 330.0951, step = 12200 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.598\n",
      "INFO:tensorflow:loss = 385.45312, step = 12300 (0.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.629\n",
      "INFO:tensorflow:loss = 357.51486, step = 12400 (0.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.143\n",
      "INFO:tensorflow:loss = 1251.6062, step = 12500 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.342\n",
      "INFO:tensorflow:loss = 490.2712, step = 12600 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.161\n",
      "INFO:tensorflow:loss = 47676234000000.0, step = 12700 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.843\n",
      "INFO:tensorflow:loss = 391679300.0, step = 12800 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.348\n",
      "INFO:tensorflow:loss = 3951.2322, step = 12900 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.905\n",
      "INFO:tensorflow:loss = 292.2615, step = 13000 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.723\n",
      "INFO:tensorflow:loss = 355.1814, step = 13100 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.719\n",
      "INFO:tensorflow:loss = 336.35516, step = 13200 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.746\n",
      "INFO:tensorflow:loss = 316.46912, step = 13300 (0.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.568\n",
      "INFO:tensorflow:loss = 399.92816, step = 13400 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.274\n",
      "INFO:tensorflow:loss = 352.75668, step = 13500 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.655\n",
      "INFO:tensorflow:loss = 322.4586, step = 13600 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.552\n",
      "INFO:tensorflow:loss = 304.61572, step = 13700 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.709\n",
      "INFO:tensorflow:loss = 382.14105, step = 13800 (0.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.285\n",
      "INFO:tensorflow:loss = 314.83264, step = 13900 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.907\n",
      "INFO:tensorflow:loss = 307.75845, step = 14000 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.34\n",
      "INFO:tensorflow:loss = 338.2774, step = 14100 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.922\n",
      "INFO:tensorflow:loss = 380.43616, step = 14200 (0.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.856\n",
      "INFO:tensorflow:loss = 315.1646, step = 14300 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.463\n",
      "INFO:tensorflow:loss = 341.49802, step = 14400 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.64\n",
      "INFO:tensorflow:loss = 330.25375, step = 14500 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.587\n",
      "INFO:tensorflow:loss = 327.02457, step = 14600 (0.660 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14649 into ./models/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 151.76266.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7fae1c17f6a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maybe should set tf.estimator.RunConfig to run on GPU?\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    shuffle=True,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "model.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-13-23:23:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./models/model.ckpt-14649\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-13-23:23:46\n",
      "INFO:tensorflow:Saving dict for global step 14649: average_loss = 1.5211167, global_step = 14649, label/mean = 3.5334, loss = 194.01999, prediction/mean = 3.9837782\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14649: ./models/model.ckpt-14649\n",
      "{'average_loss': 1.5211167, 'label/mean': 3.5334, 'loss': 194.01999, 'prediction/mean': 3.9837782, 'global_step': 14649}\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=test_x,\n",
    "    y=test_y,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "result = model.evaluate(input_fn=test_input_fn, steps=None)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Item rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./models/model.ckpt-14649\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42083</th>\n",
       "      <td>600</td>\n",
       "      <td>651</td>\n",
       "      <td>888451492</td>\n",
       "      <td>4.022713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71825</th>\n",
       "      <td>607</td>\n",
       "      <td>494</td>\n",
       "      <td>883879556</td>\n",
       "      <td>4.007088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99535</th>\n",
       "      <td>875</td>\n",
       "      <td>1103</td>\n",
       "      <td>876465144</td>\n",
       "      <td>3.975838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47879</th>\n",
       "      <td>648</td>\n",
       "      <td>238</td>\n",
       "      <td>882213535</td>\n",
       "      <td>3.960213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734</th>\n",
       "      <td>113</td>\n",
       "      <td>273</td>\n",
       "      <td>875935609</td>\n",
       "      <td>3.866463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserId  MovieId  Timestamp  prediction\n",
       "42083     600      651  888451492    4.022713\n",
       "71825     607      494  883879556    4.007088\n",
       "99535     875     1103  876465144    3.975838\n",
       "47879     648      238  882213535    3.960213\n",
       "36734     113      273  875935609    3.866463"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=test_input_fn))\n",
    "pred_list = [p['predictions'][0] for p in predictions]\n",
    "test_x['prediction']  = pd.Series(pred_list).values\n",
    "test_x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t1.233336\n",
      "MAE:\t\t0.943717\n",
      "rsquared:\t-0.181869\n",
      "exp var:\t-0.024264\n"
     ]
    }
   ],
   "source": [
    "cols = {\n",
    "    'col_user': 'UserId',\n",
    "    'col_item': 'MovieId',\n",
    "    'col_rating': 'Rating',\n",
    "    'col_prediction': 'prediction',\n",
    "}\n",
    "\n",
    "eval_rmse = rmse(test, test_x, **cols)\n",
    "eval_mae = mae(test, test_x, **cols)\n",
    "eval_rsquared = rsquared(test, test_x, **cols)\n",
    "eval_exp_var = exp_var(test, test_x, **cols)\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recommend k items\n",
    "\n",
    "1) Remove seen items and 2) add timestamp info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before excude seen items: 1586126\n",
      "After excude seen items: 1511126\n",
      "   UserId  MovieId    Timestamp\n",
      "0     600      651  888451492.0\n",
      "1     607      494  883879556.0\n",
      "2     875     1103  876465144.0\n",
      "3     648      238  882213535.0\n",
      "4     113      273  875935609.0\n"
     ]
    }
   ],
   "source": [
    "# Get the cross join of all user-item pairs and score them.\n",
    "user_item_col = ['UserId', 'MovieId']\n",
    "user_item_list = list(itertools.product(user_list, item_list))\n",
    "users_items = pd.DataFrame(user_item_list, columns=user_item_col)\n",
    "print(\"Before excude seen items:\", len(users_items))\n",
    "\n",
    "# Remove seen items (items in the train set)\n",
    "users_items_exclude_train = users_items.loc[\n",
    "    ~users_items.set_index(user_item_col).index.isin(train.set_index(user_item_col).index)\n",
    "]\n",
    "print(\"After excude seen items:\", len(users_items_exclude_train))\n",
    "\n",
    "# Add timestamp info\n",
    "users_items_exclude_train = pd.merge(test, users_items_exclude_train,\n",
    "                                     on=user_item_col, how='outer')\n",
    "users_items_exclude_train.drop('Rating', axis=1, inplace=True)\n",
    "users_items_exclude_train.fillna(test['Timestamp'].max(), inplace=True) \n",
    "print(users_items_exclude_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./models/model.ckpt-14649\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>651</td>\n",
       "      <td>888451492.0</td>\n",
       "      <td>4.022713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607</td>\n",
       "      <td>494</td>\n",
       "      <td>883879556.0</td>\n",
       "      <td>4.007088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>875</td>\n",
       "      <td>1103</td>\n",
       "      <td>876465144.0</td>\n",
       "      <td>3.975838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>648</td>\n",
       "      <td>238</td>\n",
       "      <td>882213535.0</td>\n",
       "      <td>3.960213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113</td>\n",
       "      <td>273</td>\n",
       "      <td>875935609.0</td>\n",
       "      <td>3.866463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId    Timestamp  prediction\n",
       "0     600      651  888451492.0    4.022713\n",
       "1     607      494  883879556.0    4.007088\n",
       "2     875     1103  876465144.0    3.975838\n",
       "3     648      238  882213535.0    3.960213\n",
       "4     113      273  875935609.0    3.866463"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=users_items_exclude_train,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "reco = list(model.predict(input_fn=reco_input_fn))\n",
    "reco_list = [p['predictions'][0] for p in reco]\n",
    "users_items_exclude_train['prediction']  = pd.Series(reco_list).values\n",
    "users_items_exclude_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.020709\n",
      "NDCG:\t0.089744\n",
      "Precision@K:\t0.051538\n",
      "Recall@K:\t0.020709\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "eval_map = map_at_k(test, users_items_exclude_train, k=k, **cols)\n",
    "eval_ndcg = ndcg_at_k(test, users_items_exclude_train, k=k, **cols)\n",
    "eval_precision = precision_at_k(test, users_items_exclude_train, k=k, **cols)\n",
    "eval_recall = recall_at_k(test, users_items_exclude_train, k=k, **cols)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "python3-tf-gpu",
   "language": "python",
   "name": "python3-tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
