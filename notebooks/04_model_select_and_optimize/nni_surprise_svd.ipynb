{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "Surprise version: 1.0.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import json\n",
    "import os\n",
    "import surprise\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.evaluation.python_evaluation import rmse, precision_at_k, ndcg_at_k\n",
    "from reco_utils.recommender.surprise.surprise_utils import compute_rating_predictions, compute_ranking_predictions\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Surprise version: {}\".format(surprise.__version__))\n",
    "\n",
    "tmp_dir = TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Dataset\n",
    "1. Download data and split into training, validation and test sets\n",
    "2. Store the data sets to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0     196     242     3.0\n",
       "1     186     302     3.0\n",
       "2      22     377     1.0\n",
       "3     244      51     2.0\n",
       "4     166     346     1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[\"userID\", \"itemID\", \"rating\"]\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = python_random_split(data, [0.7, 0.15, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(tmp_dir.name, 'aml_data') \n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_train.pkl\"\n",
    "train.to_pickle(os.path.join(DATA_DIR, TRAIN_FILE_NAME))\n",
    "\n",
    "VAL_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_val.pkl\"\n",
    "validation.to_pickle(os.path.join(DATA_DIR, VAL_FILE_NAME))\n",
    "\n",
    "TEST_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_test.pkl\"\n",
    "test.to_pickle(os.path.join(DATA_DIR, TEST_FILE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare a training script [svd_training_nni.py](../../reco_utils/nni/svd_training.py) for the hyperparameter tuning, which will log our target metrics such as precision, NDCG, RMSE.\n",
    "We define the arguments of the script and the search space for the hyperparameters. All the parameter values will be passed to our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_svd_model\"\n",
    "PRIMARY_METRIC = 'precision_at_k'\n",
    "RATING_METRICS = ['rmse']\n",
    "RANKING_METRICS = ['precision_at_k', 'ndcg_at_k']  \n",
    "USERCOL = 'userID'\n",
    "ITEMCOL = 'itemID'\n",
    "RECOMMEND_SEEN = False\n",
    "K = 10\n",
    "RANDOM_STATE = 0\n",
    "VERBOSE = True\n",
    "NUM_EPOCHS = 30\n",
    "BIASED = True\n",
    "\n",
    "script_params = \" \".join([\n",
    "    '--datastore', DATA_DIR,\n",
    "    '--train-datapath', TRAIN_FILE_NAME,\n",
    "    '--validation-datapath', VAL_FILE_NAME,\n",
    "    '--surprise-reader', 'ml-100k',\n",
    "    '--rating-metrics', \" \".join(RATING_METRICS),\n",
    "    '--ranking-metrics', \" \".join(RANKING_METRICS),\n",
    "    '--usercol', USERCOL,\n",
    "    '--itemcol', ITEMCOL,\n",
    "    '--k', str(K),\n",
    "    '--random-state', str(RANDOM_STATE),\n",
    "    '--epochs', str(NUM_EPOCHS),\n",
    "    '--primary-metric', PRIMARY_METRIC\n",
    "])\n",
    "\n",
    "if BIASED:\n",
    "    script_params += ' --biased'\n",
    "if VERBOSE:\n",
    "    script_params += ' --verbose'\n",
    "if RECOMMEND_SEEN:\n",
    "    script_params += ' --recommend-seen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters search space\n",
    "# We do not set 'lr_all' and 'reg_all' because they will be overriden by the other lr_ and reg_ parameters\n",
    "\n",
    "hyper_params = {\n",
    "    'n_factors': {\"_type\": \"choice\", \"_value\": [10, 50, 100, 150, 200]},\n",
    "    'init_mean': {\"_type\": \"uniform\", \"_value\": [-0.5, 0.5]},\n",
    "    'init_std_dev': {\"_type\": \"uniform\", \"_value\": [0.01, 0.2]},\n",
    "    'lr_bu': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'lr_bi': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'lr_pu': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'lr_qi': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'reg_bu': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]},\n",
    "    'reg_bi': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]}, \n",
    "    'reg_pu': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]}, \n",
    "    'reg_qi': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../reco_utils/nni/search_space_svd.json', 'w') as fp:\n",
    "    json.dump(hyper_params, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a yaml file for the configuration of the trials and the tuning algorithm to be used (in this experiment we use TPE). The tuning trials will be executed locally on a [Standard_D16_v3 virtual machine](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general#dv3-series-1) (16 vcpus, 64 GB memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'authorName': 'default',\n",
    "    'experimentName': 'surprise_svd',\n",
    "    'trialConcurrency': 8,\n",
    "    'maxExecDuration': '1h',\n",
    "    'maxTrialNum': 100,\n",
    "    'trainingServicePlatform': 'local',\n",
    "    # The path to Search Space\n",
    "    'searchSpacePath': 'search_space_svd.json',\n",
    "    'useAnnotation': False,\n",
    "    'tuner': {\n",
    "        'builtinTunerName': 'TPE',\n",
    "        'classArgs': {\n",
    "            #choice: maximize, minimize\n",
    "            'optimize_mode': 'maximize'\n",
    "        }\n",
    "    },\n",
    "    # The path and the running command of trial\n",
    "    'trial':  {\n",
    "      'command': 'python3 svd_training.py' + \" \" + script_params,\n",
    "      'codeDir': '.',\n",
    "      'gpuNum': 0\n",
    "    }\n",
    "}\n",
    " \n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Execute NNI Trials\n",
    "\n",
    "The conda environment comes with NNI installed, which includes the command line tool `nnictl` for controlling and getting information about NNI experiments. <br>\n",
    "To start the NNI trials for tuning, execute the following command: <br>\n",
    "`nnictl create --config ../../reco_utils/nni/config_svd.yml` <br>\n",
    "You can see the progress of the experiment by using the URL links output by the above command.\n",
    "\n",
    "![](https://recodatasets.blob.core.windows.net/images/nn1.png)\n",
    "\n",
    "![](https://recodatasets.blob.core.windows.net/images/nn2.png)\n",
    "\n",
    "![](https://recodatasets.blob.core.windows.net/images/nn3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Show Results\n",
    "\n",
    "The trial with the best metric and the corresponding metrics and hyperparameters can be read from the Web UI,\n",
    "\n",
    "![](https://recodatasets.blob.core.windows.net/images/nni4.png)\n",
    "\n",
    "or from the JSON file created by the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_directory = '/home/anargyri/nni/experiments/BTXE9wQP/trials/OaQaz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(exp_directory, \"metrics.json\"), \"r\") as fp:\n",
    "    best_run_metrics = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.0041081918007453,\n",
       " 'ndcg_at_k': 0.09499804974666749,\n",
       " 'precision_at_k': 0.0841320553780618}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(exp_directory, \"parameter.cfg\"), \"r\") as fp:\n",
    "    parameter_values = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 150,\n",
       " 'init_mean': -0.19913719902493227,\n",
       " 'init_std_dev': 0.11618790065015394,\n",
       " 'lr_bu': 0.016463102616016915,\n",
       " 'lr_bi': 0.00018770097489760547,\n",
       " 'lr_pu': 0.04836549541451997,\n",
       " 'lr_qi': 0.04062529506784888,\n",
       " 'reg_bu': 0.23422042744189878,\n",
       " 'reg_bi': 0.8826509703299851,\n",
       " 'reg_pu': 0.4579176210355413,\n",
       " 'reg_qi': 0.8740101469424384}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_values[\"parameters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the metrics on the test data. To do this, we get the SVD model that was saved as `model.dump` in the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load(os.path.join(exp_directory, \"model.dump\"))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_results(svd):\n",
    "    test_results = {}\n",
    "    predictions = compute_rating_predictions(svd, test, usercol=\"userID\", itemcol=\"itemID\")\n",
    "    for metric in RATING_METRICS:\n",
    "        test_results[metric] = eval(metric)(test, predictions)\n",
    "\n",
    "    all_predictions = compute_ranking_predictions(svd, train, usercol=\"userID\", itemcol=\"itemID\", recommend_seen=RECOMMEND_SEEN)\n",
    "    for metric in RANKING_METRICS:\n",
    "        test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=K)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 1.0013418475790854, 'precision_at_k': 0.08496801705756932, 'ndcg_at_k': 0.0959363440067854}\n"
     ]
    }
   ],
   "source": [
    "test_results_tpe = compute_test_results(svd)\n",
    "print(test_results_tpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. More Tuning Algorithms\n",
    "We now apply other tuning algorithms supported by NNI to the same problem. The only change needed is in the relevant entry of the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tuner']['builtinTunerName'] = 'Random'\n",
    " \n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nnictl stop`<br>\n",
    "`nnictl create --config ../../reco_utils/nni/config_svd.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load(\"/home/anargyri/nni/experiments/uOwanZo5/trials/aaju7/model.dump\")[1]\n",
    "test_results_random = compute_test_results(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tuner']['builtinTunerName'] = 'Anneal'\n",
    " \n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nnictl stop`<br>\n",
    "`nnictl create --config ../../reco_utils/nni/config_svd.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load(\"/home/anargyri/nni/experiments/l7q7bAak/trials/Fox0b/model.dump\")[1]\n",
    "test_results_anneal = compute_test_results(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tuner']['builtinTunerName'] = 'Evolution'\n",
    " \n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nnictl stop`<br>\n",
    "`nnictl create --config ../../reco_utils/nni/config_svd.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load(\"/home/anargyri/nni/experiments/jqSfATn9/trials/g1MQG/model.dump\")[1]\n",
    "test_results_evolution = compute_test_results(svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMAC tuner requires to be installed with the following command <br>\n",
    "`nnictl package install --name=SMAC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tuner']['builtinTunerName'] = 'SMAC'\n",
    " \n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nnictl stop`<br>\n",
    "`nnictl create --config ../../reco_utils/nni/config_svd.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load(\"/home/anargyri/nni/experiments/VsOmUkYA/trials/LO7aG/model.dump\")[1]\n",
    "test_results_smac = compute_test_results(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tuner']['builtinTunerName'] = 'MetisTuner'\n",
    " \n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nnictl stop`<br>\n",
    "`nnictl create --config ../../reco_utils/nni/config_svd.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load(\"/home/anargyri/nni/experiments/v709Lcpk/trials/BckEP/model.dump\")[1]\n",
    "test_results_metis = compute_test_results(svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperband follows a different style of configuration from other tuners. See [the NNI documentation](https://nni.readthedocs.io/en/latest/hyperbandAdvisor.html). Note that the [training script](../../reco_utils/nni/svd_training.py) needs to be adjusted as well, since each Hyperband trial receives an additional parameter `STEPS`, which corresponds to the resource allocation _r<sub>i</sub>_ in the [Hyperband algorithm](https://arxiv.org/pdf/1603.06560.pdf). In this example, we used `STEPS` in combination with `R` to determine the number of epochs that SVD will run for in every trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['advisor'] = {\n",
    "  'builtinAdvisorName': 'Hyperband',\n",
    "  'classArgs': {\n",
    "    'R': NUM_EPOCHS,\n",
    "    'eta': 3,\n",
    "    'optimize_mode': 'maximize'\n",
    "  }\n",
    "}\n",
    "\n",
    "config.pop('tuner')\n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nnictl stop`<br>\n",
    "`nnictl create --config ../../reco_utils/nni/config_svd.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load(\"/home/anargyri/nni/experiments/Dj90D2uB/trials/kOIu9/model.dump\")[1]\n",
    "test_results_hyperband = compute_test_results(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metis</th>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Search</th>\n",
       "      <td>0.089339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPE</th>\n",
       "      <td>0.084968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annealing</th>\n",
       "      <td>0.069510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperband</th>\n",
       "      <td>0.068443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAC</th>\n",
       "      <td>0.064179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evolution</th>\n",
       "      <td>0.058849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precision@10\n",
       "Metis              0.102345\n",
       "Random Search      0.089339\n",
       "TPE                0.084968\n",
       "Annealing          0.069510\n",
       "Hyperband          0.068443\n",
       "SMAC               0.064179\n",
       "Evolution          0.058849"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=['TPE', 'Random Search', 'Annealing', 'Evolution', 'SMAC', 'Metis', 'Hyperband'],\n",
    "             data=[res['precision_at_k'] for res in [test_results_tpe, test_results_random, test_results_anneal, \n",
    "                                                     test_results_evolution, test_results_smac, test_results_metis, \n",
    "                                                     test_results_hyperband]], \n",
    "             columns=['precision@{}'.format(K)]\n",
    "            ).sort_values(by='precision@{}'.format(K), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Concluding Remarks\n",
    "\n",
    "We showed how to tune **all** the hyperparameters accepted by Surprise SVD simultaneously, by utilizing the NNI toolkit. \n",
    "For example, training and evaluation of a single SVD model takes about 50 seconds on the 100k MovieLens data on a Standard D2_V2 VM. Searching through 100 different combinations of hyperparameters sequentially would take about 80 minutes whereas each of the above experiments took about 10. With NNI, one can take advantage of concurrency and multiple processors on a virtual machine and can use a variety of methods to navigate efficiently through a large space of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [Matrix factorization algorithms in Surprise](https://surprise.readthedocs.io/en/stable/matrix_factorization.html) \n",
    "* [Surprise SVD deep-dive notebook](../02_model/surprise_svd_deep_dive.ipynb)\n",
    "* [Neural Network Intelligence toolkit](https://github.com/Microsoft/nni)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_base)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
