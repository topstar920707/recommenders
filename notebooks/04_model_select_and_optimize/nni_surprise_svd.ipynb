{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "Surprise version: 1.0.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import json\n",
    "import os\n",
    "import surprise\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import time\n",
    "import yaml\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.evaluation.python_evaluation import rmse, precision_at_k, ndcg_at_k\n",
    "from reco_utils.recommender.surprise.surprise_utils import compute_rating_predictions, compute_ranking_predictions\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Surprise version: {}\".format(surprise.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Dataset\n",
    "1. Download data and split into training and testing sets\n",
    "2. Upload the training set to the default **blob storage** of the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0     196     242     3.0\n",
       "1     186     302     3.0\n",
       "2      22     377     1.0\n",
       "3     244      51     2.0\n",
       "4     166     346     1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[\"userID\", \"itemID\", \"rating\"]\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = python_random_split(data, [0.7, 0.15, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'aml_data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_train.pkl\"\n",
    "train.to_pickle(os.path.join(DATA_DIR, TRAIN_FILE_NAME))\n",
    "\n",
    "VAL_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_val.pkl\"\n",
    "validation.to_pickle(os.path.join(DATA_DIR, VAL_FILE_NAME))\n",
    "\n",
    "TEST_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_test.pkl\"\n",
    "test.to_pickle(os.path.join(DATA_DIR, TEST_FILE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also prepare a training script [svd_training_nni.py](../../reco_utils/nni/svd_training.py) for the hyperparameter tuning, which will log our target metrics such as precision, NDCG, RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the arguments of the script and the search space for the hyperparameters. All the parameter values will be passed to our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_svd_model\"\n",
    "PRIMARY_METRIC = 'precision_at_k'\n",
    "RATING_METRICS = ['rmse']\n",
    "RANKING_METRICS = ['precision_at_k', 'ndcg_at_k']  \n",
    "USERCOL = 'userID'\n",
    "ITEMCOL = 'itemID'\n",
    "RECOMMEND_SEEN = False\n",
    "K = 10\n",
    "RANDOM_STATE = 0\n",
    "VERBOSE = True\n",
    "NUM_EPOCHS = 30\n",
    "BIASED = True\n",
    "\n",
    "script_params = {\n",
    "    'datastore': os.path.join(os.getcwd(), 'aml_data'),\n",
    "    'train_datapath': TRAIN_FILE_NAME,\n",
    "    'validation_datapath': VAL_FILE_NAME,\n",
    "    'output_dir': './outputs',\n",
    "    'surprise_reader': 'ml-100k',\n",
    "    'rating_metrics': RATING_METRICS,\n",
    "    'ranking_metrics': RANKING_METRICS,\n",
    "    'usercol': USERCOL,\n",
    "    'itemcol': ITEMCOL,\n",
    "    'k': K,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'primary_metric': PRIMARY_METRIC\n",
    "}\n",
    "\n",
    "if BIASED:\n",
    "    script_params['biased'] = ''\n",
    "if VERBOSE:\n",
    "    script_params['verbose'] = ''\n",
    "if RECOMMEND_SEEN:\n",
    "    script_params['recommend_seen'] = ''\n",
    "\n",
    "script_params = {k: {\"_type\": \"choice\", \"_value\": [script_params[k]]} for k in script_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters search space\n",
    "# We do not set 'lr_all' and 'reg_all' because they will be overriden by the other lr_ and reg_ parameters\n",
    "\n",
    "hyper_params = {\n",
    "    'n_factors': {\"_type\": \"choice\", \"_value\": [10, 50, 100, 150, 200]},\n",
    "    'init_mean': {\"_type\": \"uniform\", \"_value\": [-0.5, 0.5]},\n",
    "    'init_std_dev': {\"_type\": \"uniform\", \"_value\": [0.01, 0.2]},\n",
    "    'lr_bu': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'lr_bi': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'lr_pu': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'lr_qi': {\"_type\": \"uniform\", \"_value\": [1e-6, 0.1]}, \n",
    "    'reg_bu': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]},\n",
    "    'reg_bi': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]}, \n",
    "    'reg_pu': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]}, \n",
    "    'reg_qi': {\"_type\": \"uniform\", \"_value\": [1e-6, 1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params.update(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../reco_utils/nni/search_space_svd.json', 'w') as fp:\n",
    "    json.dump(script_params, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a yml file for the configuration of the trials and the tuning algorithm to be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'authorName': 'default',\n",
    "    'experimentName': 'surprise_svd',\n",
    "    'trialConcurrency': 10,\n",
    "    'maxExecDuration': '1h',\n",
    "    'maxTrialNum': 10,\n",
    "    'trainingServicePlatform': 'local',\n",
    "    # The path to Search Space\n",
    "    'searchSpacePath': 'search_space_svd.json',\n",
    "    'useAnnotation': False,\n",
    "    'tuner': {\n",
    "        'builtinTunerName': 'TPE',\n",
    "        'classArgs': {\n",
    "            #choice: maximize, minimize\n",
    "            'optimize_mode': 'maximize'\n",
    "        }\n",
    "    },\n",
    "    # The path and the running command of trial\n",
    "    'trial':  {\n",
    "      'command': 'python3 svd_training.py',\n",
    "      'codeDir': '.',\n",
    "      'gpuNum': 0\n",
    "    }\n",
    "}\n",
    " \n",
    "with open('../../reco_utils/nni/config_svd.yml', 'w') as fp:\n",
    "    fp.write(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Execute NNI Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cd3c66d91f433888ffffc6e45b46fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: movielens_100k_svd_model_1551957798853\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: movielens_100k_svd_model_1551957798853\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'movielens_100k_svd_model_1551957798853',\n",
       " 'target': 'cpuclustersvd',\n",
       " 'status': 'Completed',\n",
       " 'endTimeUtc': '2019-03-07T11:57:23.000Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"precision_at_k\", \"goal\": \"maximize\"}',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive'},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://anargyri6699545766.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens_100k_svd_model_1551957798853/azureml-logs/hyperdrive.txt?sv=2018-03-28&sr=b&sig=5vpEl9OQZvTgU4v%2BiIAKATIHBJg8UyBw8e3jD0xtAz4%3D&st=2019-03-07T11%3A47%3A26Z&se=2019-03-07T19%3A57%3A26Z&sp=r'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313732b33930494d8245cf305ffd99f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an experiment to track the runs in the workspace\n",
    "exp = aml.core.Experiment(workspace=ws, name=EXP_NAME)\n",
    "run = exp.submit(config=hd_config)\n",
    "\n",
    "azureml.widgets.RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the experiment progress from this notebook by using `azureml.widgets.RunDetails(hd_run).show()` or check from the Azure portal with the url link you can get by running `hd_run.get_portal_url()`.\n",
    "To load an existing Hyperdrive run, use `hd_run = hd.HyperDriveRun(exp, <user-run-id>, hyperdrive_run_config=hd_run_config)`. You also can cancel a run with `hd_run.cancel()`.\n",
    "![](https://recodatasets.blob.core.windows.net/images/svd_hyperdrive1.PNG)\n",
    "![](https://recodatasets.blob.core.windows.net/images/svd_hyperdrive2.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best run and printout metrics\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of epochs': 30,\n",
       " 'rmse': 1.0343498081373697,\n",
       " 'precision_at_k': 0.10000000000000002,\n",
       " 'ndcg_at_k': 0.11498322243961594}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--datastore $AZUREML_DATAREFERENCE_workspaceblobstore --train-datapath data/movielens_100k_train.pkl --validation-datapath data/movielens_100k_val.pkl --output_dir ./outputs --surprise-reader ml-100k --rating-metrics rmse --ranking-metrics precision_at_k ndcg_at_k --usercol userID --itemcol itemID --k 10 --random-state 0 --epochs 30 --biased --verbose --n_factors 150 --init_mean -0.4163305768968 --init_std_dev 0.159711436379793 --lr_bu 0.0386753983834255 --lr_bi 4.48660045721016E-05 --lr_pu 0.0119378772073106 --lr_qi 0.0936873305814469 --reg_bu 0.385400397115581 --reg_bi 0.975251474623207 --reg_pu 0.906537637834819 --reg_qi 0.801240951271603\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(parameter_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the metrics on the test data. To do this, get the SVD model that was saved as model.dump in the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('aml_model', exist_ok=True)\n",
    "best_run.download_file('outputs/model.dump', output_file_path='aml_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load('aml_model/model.dump')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 1.0331492610799313, 'precision_at_k': 0.09968017057569298, 'ndcg_at_k': 0.1160964958978592}\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "predictions = compute_rating_predictions(svd, test, usercol=\"userID\", itemcol=\"itemID\")\n",
    "for metric in RATING_METRICS:\n",
    "    test_results[metric] = eval(metric)(test, predictions)\n",
    "\n",
    "all_predictions = compute_ranking_predictions(svd, train, usercol=\"userID\", itemcol=\"itemID\", recommend_seen=RECOMMEND_SEEN)\n",
    "for metric in RANKING_METRICS:\n",
    "    test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=K)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(SCRIPT_DIR)\n",
    "    shutil.rmtree(DATA_DIR)\n",
    "except (PermissionError, FileNotFoundError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Concluding Remarks\n",
    "\n",
    "We showed how to tune **all** the hyperparameters accepted by Surprise SVD simultaneously, by utilizing the Azure Machine Learning service. \n",
    "For example, training and evaluation of a single SVD model takes about 50 seconds on the 100k MovieLens data on a Standard D2_V2 VM. Searching through 100 different combinations of hyperparameters sequentially would take about 80 minutes whereas this notebook took less than half that. With AzureML, one can easily specify the size of the cluster according to the problem at hand and use Bayesian sampling to navigate efficiently through a large space of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [Matrix factorization algorithms in Surprise](https://surprise.readthedocs.io/en/stable/matrix_factorization.html) \n",
    "* [Surprise SVD deep-dive notebook](../02_model/surprise_svd_deep_dive.ipynb)\n",
    "* [Fine-tune natural language processing models using Azure Machine Learning service](https://azure.microsoft.com/en-us/blog/fine-tune-natural-language-processing-models-using-azure-machine-learning-service/)\n",
    "* [Training, hyperparameter tune, and deploy with TensorFlow](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-tensorflow/train-hyperparameter-tune-deploy-with-tensorflow.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_base)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
