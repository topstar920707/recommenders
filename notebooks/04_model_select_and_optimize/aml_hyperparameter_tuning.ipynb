{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.<br>\n",
    "Licensed under the MIT License.</i>\n",
    "<br><br>\n",
    "# Recommender Hyperparameter Tuning w/ AzureML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to auto-tune hyperparameters of a recommender model by utilizing **Azure Machine Learning service**<sup>[a](#azureml-search), [b](#azure-subscription)</sup> ([AzureML](https://azure.microsoft.com/en-us/services/machine-learning-service/)).\n",
    "\n",
    "We present an overall process of utilizing AzureML, specifically [**Hyperdrive**](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive?view=azure-ml-py) component, for the hyperparameter tuning by demonstrating key steps:\n",
    "1. Configure AzureML Workspace\n",
    "2. Create Remote Compute Target (GPU cluster)\n",
    "3. Prepare Data\n",
    "4. Prepare Training Scripts\n",
    "5. Setup and Run Hyperdrive Experiment\n",
    "6. Model Import, Re-train and Test\n",
    "\n",
    "In this notebook, we use [**wide-and-deep model**](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html) from **TensorFlow high-level Estimator API (v1.12)** on the movie recommendation scenario. Wide-and-deep learning jointly trains wide linear model and deep neural networks (DNN) to combine the benefits of memorization and generalization for recommender systems.\n",
    "\n",
    "For more details about the **wide-and-deep** model:\n",
    "* [Wide-Deep Quickstart notebook](../00_quick_start/wide_deep_model_movielens.ipynb)\n",
    "* [Original paper](https://arxiv.org/abs/1606.07792)\n",
    "* [TensorFlow API doc](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedRegressor)\n",
    "  \n",
    "Regarding **AuzreML**, please refer:\n",
    "* [Quickstart notebook](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python)\n",
    "* [Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters)\n",
    "* [Tensorflow model tuning with Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-tensorflow)\n",
    "\n",
    "> <span id=\"azureml-search\">a. </span>To use AzureML, you will need an Azure subscription.  \n",
    "<span id=\"azure-subscription\">b. </span>When you web-search \"Azure Machine Learning\", you will most likely to see mixed results of Azure Machine Learning (AzureML) and Azure Machine Learning **Studio**. Please note they are different services where AzureML's focuses are on ML model management, tracking and hyperparameter tuning, while the [ML Studio](https://studio.azureml.net/)'s is to provide a high-level tool for 'easy-to-use' experience of ML designing and experimentation based on GUI.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# AzureML workspace info. Note, will look up \"aml_config\\config.json\" first, then fall back to use this\n",
    "SUBSCRIPTION_ID = '<subscription-id>'\n",
    "RESOURCE_GROUP  = '<resource-group>'\n",
    "WORKSPACE_NAME  = '<workspace-name>'\n",
    "\n",
    "# Remote compute (cluster) configuration. If you want to save the cost more, set these to small.\n",
    "VM_SIZE = 'STANDARD_NC6'\n",
    "VM_PRIORITY = 'lowpriority'\n",
    "# Cluster nodes\n",
    "MIN_NODES = 4\n",
    "MAX_NODES = 8\n",
    "# Hyperdrive experimentation configuration\n",
    "MAX_TOTAL_RUNS = 200  # Number of runs (training-and-evaluation) to search the best hyperparameters. \n",
    "MAX_CONCURRENT_RUNS = 8\n",
    "\n",
    "# Recommend top k items\n",
    "TOP_K = 10\n",
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "# Number of samples to train. Epochs = NUM_SAMPLES_TO_TRAIN / len(train)\n",
    "NUM_SAMPLES_TO_TRAIN = 20000000\n",
    "# Metrics to track. Put your primary metric (to search) at the first place\n",
    "METRICS = ['rmse', 'ndcg']  \n",
    "# Data column names\n",
    "USER_COL = 'UserId'\n",
    "ITEM_COL = 'MovieId'\n",
    "RATING_COL = 'Rating'\n",
    "ITEM_FEAT_COL = 'Genres'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configure AzureML Workspace\n",
    "**AzureML workspace** is a foundational block in the cloud that you use to experiment, train, and deploy machine learning models via AzureML service. In this notebook, we 1) create a workspace from [**Azure portal**](https://portal.azure.com) and 2) configure from this notebook.\n",
    "\n",
    "You can find more details about the setup and configure processes from the following links:\n",
    "* [Quickstart with Azure portal](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started)\n",
    "* [Quickstart with Python SDK](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python)\n",
    "  \n",
    "<br>\n",
    "  \n",
    "#### 1.1 Create a workspace\n",
    "1. Sign in to the [Azure portal](https://portal.azure.com) by using the credentials for the Azure subscription you use.\n",
    "2. Select **Create a resource** menu, search for **Machine Learning service workspace** select **Create** button.\n",
    "3. In the **ML service workspace** pane, configure your workspace with entering the *workspace name* and *resource group* (or **create new** resource group if you don't have one already), and select **Create**. It can take a few moments to create the workspace.\n",
    "  \n",
    "<br>\n",
    "  \n",
    "#### 1.2 Configure\n",
    "To configure this notebook to communicate with the workspace, type in your Azure subscription id, the resource group name and workspace name to `<subscription-id>`, `<resource-group>`, `<workspace-name>` in the above notebook cell. Alternatively, you can create a *.\\aml_config\\config.json* file with the following contents:\n",
    "```\n",
    "{\n",
    "    \"subscription_id\": \"<subscription-id>\",\n",
    "    \"resource_group\": \"<resource-group>\",\n",
    "    \"workspace_name\": \"<workspace-name>\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if everything is ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "import papermill as pm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import azureml as aml\n",
    "import azureml.widgets as widgets\n",
    "import azureml.train.hyperdrive as hd\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.common import tf_utils\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    rmse, mae, rsquared, exp_var,\n",
    "    map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    ")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"Azure ML SDK Version:\", aml.core.VERSION)\n",
    "print(\"Tensorflow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a workspace\n",
    "try:\n",
    "    ws = aml.core.Workspace.from_config()\n",
    "except aml.exceptions.UserErrorException:\n",
    "    try:\n",
    "        ws = aml.core.Workspace(\n",
    "            subscription_id=SUBSCRIPTION_ID,\n",
    "            resource_group=RESOURCE_GROUP,\n",
    "            workspace_name=WORKSPACE_NAME\n",
    "        )\n",
    "    except aml.exceptions.AuthenticationException:\n",
    "        ws = None\n",
    "\n",
    "if ws is None:\n",
    "    raise ValueError(\n",
    "        \"\"\"Cannot access the AzureML workspace w/ the config info provided.\n",
    "        Please check if you entered the correct id, group name and workspace name\"\"\"\n",
    "    )\n",
    "else:\n",
    "    print(\"AzureML workspace name: \", ws.name)\n",
    "    clear_output()  # Comment out this if you want to see your workspace info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Remote Compute Target\n",
    "\n",
    "We create a gpu cluster as our **remote compute target**. If a cluster with the same name is already exist in your workspace, the script will load it instead. You can see [this document](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets) to learn more about setting up a compute target on different locations.\n",
    "\n",
    "This notebook selects **STANDARD_NC6** virtual machine and sets it's priority as *lowpriority* to save the cost.\n",
    "\n",
    "Size | vCPU | Memory (GiB) | Temp storage (SSD, GiB) | GPU | GPU memory (GiB) | Max data disks | Max NICs\n",
    "---|---|---|---|---|---|---|---\n",
    "Standard_NC6 | <center>6</center> | <center>56</center> | <center>340</center> | <center>1</center> | <center>8</center> | <center>24</center> | <center>1</center>\n",
    "\n",
    "For more information about Azure virtual machine sizes, see [here](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-gpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NAME = 'gpu-cluster-nc6'\n",
    "\n",
    "try:\n",
    "    compute_target = aml.core.compute.ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n",
    "    print(\"Found existing compute target\")\n",
    "except aml.core.compute_target.ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = aml.core.compute.AmlCompute.provisioning_configuration(\n",
    "        vm_size=VM_SIZE,\n",
    "        vm_priority=VM_PRIORITY,\n",
    "        min_nodes=MIN_NODES,\n",
    "        max_nodes=MAX_NODES\n",
    "    )\n",
    "    # create the cluster\n",
    "    compute_target = aml.core.compute.ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Data\n",
    "For demonstration purpose, we use 1M MovieLens dataset. First, download the data and convert the format (multi-hot encode *genres*) to make it work for our model. More details about this step is described in our [Wide-Deep Quickstart notebook](../00_quick_start/wide_deep_model_movielens.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[USER_COL, ITEM_COL, RATING_COL],\n",
    "    genres_col='Genres_string'\n",
    ")\n",
    "\n",
    "# Encode 'genres' into int array (multi-hot representation) to use as item features\n",
    "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n",
    "data[ITEM_FEAT_COL] = genres_encoder.fit_transform(\n",
    "    data['Genres_string'].apply(lambda s: s.split(\"|\"))\n",
    ").tolist()\n",
    "data.drop('Genres_string', axis=1, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into train, validation, and test sets. The train and validation sets will be used for hyperparameter tuning, and the test set will be used for the final evaluation of the model after we import the best model from AzureML workspace.\n",
    "\n",
    "Here, we don't use multiple-split directly by passing `ratio=[0.56, 0.19, 0.25]`. Instead, we first split the data into train and test sets with the same `seed` we've been using in other notebooks to make the train set identical across them. Then, we further split the train set into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same seed to make the train and test sets identical across other notebooks in the repo.\n",
    "train, test = python_random_split(data, ratio=0.75, seed=123)\n",
    "# Further split the train set into train and validation set.\n",
    "train, valid = python_random_split(train)\n",
    "\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, upload the train and validation sets to the AzureML workspace. Our Hyperdrivce experiment will use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'aml_data'\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_train.pkl\"\n",
    "train.to_pickle(os.path.join(DATA_DIR, TRAIN_FILE_NAME))\n",
    "VALID_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_valid.pkl\"\n",
    "valid.to_pickle(os.path.join(DATA_DIR, VALID_FILE_NAME))\n",
    "\n",
    "# Note, all the files under DATA_DIR will be uploaded to the data store\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(\n",
    "    src_dir=DATA_DIR,\n",
    "    target_path='data',\n",
    "    overwrite=True,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare Training Scripts\n",
    "Next step is to prepare scripts that AzureML Hyperdrive will use to train and evaluate models with selected hyperparameters. We re-use our [Wide-Deep Quickstart notebook](../00_quick_start/wide_deep_model_movielens.ipynb) for that. To run the model notebook from the Hyperdrive Run, all we need is to prepare an [entry script](../../reco_utils/aml/wide_deep.py) which parses the hyperparameter arguments, passes them to the notebook, and records the results of the notebook to AzureML Run logs by using `papermill`. Hyperdrive uses the logs to track the performance of each hyperparameter-set and finds the best performed one.  \n",
    "\n",
    "Here is a code snippet from the [entry script](../../reco_utils/aml/wide_deep.py):\n",
    "```\n",
    "import argparse\n",
    "import papermill as pm\n",
    "from azureml.core import Run\n",
    "run = Run.get_context()\n",
    "...\n",
    "parser = argparse.ArgumentParser()\n",
    "...\n",
    "parser.add_argument('--dnn-optimizer', type=str, dest='dnn_optimizer', ...\n",
    "parser.add_argument('--dnn-optimizer-lr', type=float, dest='dnn_optimizer_lr', ...\n",
    "...\n",
    "pm.execute_notebook(\n",
    "    \"../../notebooks/00_quick_start/wide_deep_model_movielens.ipynb\",\n",
    "    OUTPUT_NOTEBOOK,\n",
    "    parameters=params,\n",
    "    kernel_name='python3',\n",
    ")\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all the necessary scripts which will be loaded to our Hyperdrive Experiment Run\n",
    "SCRIPT_DIR = 'aml_script'\n",
    "\n",
    "# Clean-up scripts if already exists\n",
    "shutil.rmtree(SCRIPT_DIR, ignore_errors=True)\n",
    "\n",
    "# Copy scripts to SCRIPT_DIR temporarly\n",
    "shutil.copytree(os.path.join('..', '..', 'reco_utils'), os.path.join(SCRIPT_DIR, 'reco_utils'))\n",
    "\n",
    "# We re-use our model notebook for training and testing models.\n",
    "model_notebook_dir = os.path.join('notebooks', '00_quick_start')\n",
    "dest_model_notebook_dir = os.path.join(SCRIPT_DIR, model_notebook_dir)\n",
    "os.makedirs(dest_model_notebook_dir , exist_ok=True)\n",
    "shutil.copy(\n",
    "    os.path.join('..', '..', model_notebook_dir, 'wide_deep_model_movielens.ipynb'),\n",
    "    dest_model_notebook_dir\n",
    ")\n",
    "\n",
    "# This is our entry script for Hyperdrive Run\n",
    "ENTRY_SCRIPT_NAME = 'reco_utils/aml/wide_deep.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Setup and Run Hyperdrive Experiment\n",
    "[Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) create a machine learning Experiment [Run](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run?view=azure-ml-py) on the workspace and utilizes child-runs to search the best set of hyperparameters.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 5.1 Create Experiment \n",
    "[Experiment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment(class)?view=azure-ml-py) is the main entry point into experimenting with AzureML. To create new Experiment or get the existing one, we pass our experimentation name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment to track the runs in the workspace\n",
    "EXP_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_wide_deep_model\"\n",
    "exp = aml.core.Experiment(workspace=ws, name=EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Define Search Space \n",
    "Now we define the search space of hyperparameters. For example, if you want to test different batch sizes of {64, 128, 256}, you can use `azureml.train.hyperdrive.choice(64, 128, 256)`. To search from a continuous space, use `uniform(start, end)`. For more options, see [Hyperdrive parameter expressions](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.parameter_expressions?view=azure-ml-py).\n",
    "In this notebook, we fix model type as `wide_deep` and the number of samples to train as 20M. Note, 'the number of samples to train' is not the data size, but just a count of sample feeding.\n",
    "\n",
    "FYI, epochs will be:\n",
    "```\n",
    "epochs = NUM_SAMPLES_TO_TRAIN / len(train)\n",
    "```\n",
    "and train steps will be:\n",
    "```\n",
    "train_steps = NUM_SAMPLES_TO_TRAIN / BATCH_SIZE\n",
    "```\n",
    "\n",
    "In the search space, we set different linear and DNN optimizers, structures, learning rates and regularization rates. Details about the hyperparameters can be found from our [Wide-Deep Quickstart notebook](../00_quick_start/wide_deep_model_movielens.ipynb).\n",
    "\n",
    "> Hyperdrive provides three different parameter sampling methods: `RandomParameterSampling`, `GridParameterSampling`, and `BayesianParameterSampling`. Details about each method can be found from [Azure doc](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters). Here, we use the Bayesian sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed parameters\n",
    "script_params = {\n",
    "    '--datastore': ds.as_mount(),\n",
    "    '--train-datapath': \"data/\" + TRAIN_FILE_NAME,\n",
    "    '--test-datapath': \"data/\" + VALID_FILE_NAME,\n",
    "    '--top-k': TOP_K,\n",
    "    '--user-col': USER_COL,\n",
    "    '--item-col': ITEM_COL,\n",
    "    '--item-feat-col': ITEM_FEAT_COL,\n",
    "    '--rating-col': RATING_COL,\n",
    "    '--metrics': METRICS,\n",
    "    '--num-samples-to-train': NUM_SAMPLES_TO_TRAIN,  # epochs = num-samples-to-train / num-train\n",
    "    '--model-type': 'wide_deep'\n",
    "}\n",
    "\n",
    "# Hyperparameter search space\n",
    "params = {\n",
    "    '--batch-size': hd.choice(64, 128, 256),\n",
    "    # Linear model hyperparameters\n",
    "    '--linear-optimizer': hd.choice('Ftrl'),  # 'SGD' easily got exploded loss in regression problems.\n",
    "    '--linear-optimizer-lr': hd.uniform(0.0001, 0.1),\n",
    "    '--linear-l1-reg': hd.uniform(0.0, 0.1),\n",
    "    # Deep model hyperparameters\n",
    "    '--dnn-optimizer': hd.choice('Adagrad', 'Adam'),\n",
    "    '--dnn-optimizer-lr': hd.uniform(0.0001, 0.1),\n",
    "    '--dnn-user-embedding-dim': hd.choice(4, 8, 16, 32, 64, 128),\n",
    "    '--dnn-item-embedding-dim': hd.choice(4, 8, 16, 32, 64, 128),\n",
    "    '--dnn-hidden-layer-1': hd.choice(0, 32, 64, 128, 256, 512, 1024),  # 0: not using this layer\n",
    "    '--dnn-hidden-layer-2': hd.choice(0, 32, 64, 128, 256, 512, 1024),\n",
    "    '--dnn-hidden-layer-3': hd.choice(0, 32, 64, 128, 256, 512, 1024),\n",
    "    '--dnn-hidden-layer-4': hd.choice(32, 64, 128, 256, 512, 1024),\n",
    "    '--dnn-batch-norm': hd.choice(0, 1),\n",
    "    '--dnn-dropout': hd.uniform(0.0, 0.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AzureML Estimator** is the building block for training. An Estimator encapsulates the training code and parameters, the compute resources and runtime environment for a particular training scenario (Note, this is not TensorFlow's Estimator)\n",
    "\n",
    "We create one for our experimentation with the dependencies our model requires as follows:\n",
    "```\n",
    "conda_packages=['pandas', 'scikit-learn', 'tensorflow-gpu=1.12'],\n",
    "pip_packages=['ipykernel', 'papermill']\n",
    "```\n",
    "\n",
    "To the Hyperdrive Run Config, we set our primary metric name and the goal (our hyperparameter search criteria), hyperparameter sampling method, and number of total child-runs. The bigger the search space, the more number of runs we will need for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = aml.train.estimator.Estimator(\n",
    "    source_directory=SCRIPT_DIR,\n",
    "    entry_script=ENTRY_SCRIPT_NAME,\n",
    "    script_params=script_params,\n",
    "    compute_target=compute_target,\n",
    "    use_gpu=True,\n",
    "    conda_packages=['pandas', 'scikit-learn', 'tensorflow-gpu=1.12'],\n",
    "    pip_packages=['ipykernel', 'papermill']\n",
    ")\n",
    "\n",
    "hd_run_config = hd.HyperDriveRunConfig(\n",
    "    estimator=est, \n",
    "    hyperparameter_sampling=hd.BayesianParameterSampling(params),\n",
    "    primary_metric_name=METRICS[0],\n",
    "    primary_metric_goal=hd.PrimaryMetricGoal.MINIMIZE, \n",
    "    max_total_runs=MAX_TOTAL_RUNS,\n",
    "    max_concurrent_runs=MAX_CONCURRENT_RUNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Run Experiment\n",
    "\n",
    "Now we submit the Run to our experiment. You can see the experiment progress from this notebook by using `azureml.widgets.RunDetails(hd_run).show()` or check from the Azure portal with the url link you can get by running `hd_run.get_portal_url()`.\n",
    "\n",
    "![hyperdrive](hyperdrive.jpg)\n",
    "\n",
    "<br>\n",
    "\n",
    "To load an existing Hyperdrive Run, use `hd_run = hd.HyperDriveRun(exp, <user-run-id>, hyperdrive_run_config=hd_run_config)`. You also can cancel the Run with `hd_run.cancel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_run = exp.submit(config=hd_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.RunDetails(hd_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Once all the child-runs are finished, we can get the best run and the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best run and printout metrics\n",
    "best_run = hd_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(best_run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"* Best Run Id:\", best_run.id)\n",
    "print(\"\\n* Best hyperparameters:\")\n",
    "print(\"Model type =\", best_run_metrics['model_type'])\n",
    "print(\"Batch size =\", best_run_metrics['batch_size'])\n",
    "print(\"Linear optimizer =\", best_run_metrics['linear_optimizer'])\n",
    "print(\"\\tLearning rate = {0:.4f}\".format(best_run_metrics['linear_optimizer_lr']))\n",
    "print(\"\\tL1 regularization = {0:.4f}\".format(best_run_metrics['linear_l1_reg']))\n",
    "print(\"DNN optimizer =\", best_run_metrics['dnn_optimizer'])\n",
    "print(\"\\tUser embedding dimension =\", best_run_metrics['dnn_user_dim'])\n",
    "print(\"\\tItem embedding dimension =\", best_run_metrics['dnn_item_dim'])\n",
    "print(\"\\tHidden units =\", best_run_metrics['dnn_hidden_units'])\n",
    "print(\"\\tLearning rate = {0:.4f}\".format(best_run_metrics['dnn_optimizer_lr']))\n",
    "print(\"\\tDropout rate = {0:.4f}\".format(best_run_metrics['dnn_dropout']))\n",
    "print(\"\\tBatch normalization =\", best_run_metrics['dnn_batch_norm'])\n",
    "print(\"\\n* Performance metrics:\")\n",
    "print(\"Mean squared error = {0:.4f}\".format(best_run_metrics['average_loss']))\n",
    "for m in METRICS:\n",
    "    print(\"\\t{0} = {1:.4f}\".format(m, best_run_metrics[m]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Import, Re-train, and Test\n",
    "\n",
    "[Wide-Deep Quickstart notebook](../00_quick_start/wide_deep_model_movielens.ipynb), which we've used in our Hyperdrive Experiment, exports the trained model to the output folder (the output path is recorded at `best_run_metrics['saved_model_dir']`). We can download a model from the best run and test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'aml_model'\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "model_file_dir = os.path.normpath(best_run_metrics['saved_model_dir']) + '/'\n",
    "for f in best_run.get_file_names():\n",
    "    if f.startswith(model_file_dir):\n",
    "        output_file_path = os.path.join(MODEL_DIR, f[len(model_file_dir):])\n",
    "        print(\"Downloading {}..\".format(f))\n",
    "        best_run.download_file(name=f, output_file_path=output_file_path)\n",
    "\n",
    "saved_model = tf.contrib.estimator.SavedModelEstimator(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation dataset we split in the beginning has been used to evaluate the model during the hyperparameter tuning. Since we finished the tuning, now we use them to final train the model on top of what it already learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test with and without this step.\n",
    "train_fn = tf_utils.pandas_input_fn(\n",
    "    df=valid,  # The set we have been used for hyperparameter tuning.\n",
    "    y_col=RATING_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,  # None == run forever. We use steps=TRAIN_STEPS instead.\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "model.train(\n",
    "    input_fn=train_fn,\n",
    "    steps=1000  # We re-train a little bit more\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test the model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'col_user': USER_COL,\n",
    "    'col_item': ITEM_COL,\n",
    "    'col_rating': RATING_COL,\n",
    "    'col_prediction': 'prediction'\n",
    "}\n",
    "\n",
    "RANKING_METRICS = {\n",
    "    'map': map_at_k,\n",
    "    'ndcg': ndcg_at_k,\n",
    "    'precision': precision_at_k,\n",
    "    'recall': recall_at_k\n",
    "}\n",
    "RATING_METRICS = {\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'rsquared': rsquared,\n",
    "    'exp_var': exp_var\n",
    "}\n",
    "\n",
    "# Prediction input function for TensorFlow SavedModel\n",
    "def predict_input_fn(df):\n",
    "    def input_fn():\n",
    "        examples = [None] * len(df)\n",
    "        for index, test_sample in df.iterrows():\n",
    "            example = tf.train.Example()\n",
    "\n",
    "            example.features.feature[USER_COL].int64_list.value.extend([test_sample[USER_COL]])\n",
    "            example.features.feature[ITEM_COL].int64_list.value.extend([test_sample[ITEM_COL]])\n",
    "            example.features.feature[ITEM_FEAT_COL].float_list.value.extend(test_sample[ITEM_FEAT_COL])\n",
    "\n",
    "            examples[index] = example.SerializeToString()\n",
    "        return {'inputs': tf.constant(examples)}\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating prediction set\n",
    "X_test = test.drop(RATING_COL, axis=1).reset_index(drop=True)\n",
    "\n",
    "# Rating prediction\n",
    "predictions = list(itertools.islice(\n",
    "    saved_model.predict(predict_input_fn(X_test)),\n",
    "    len(X_test)\n",
    "))\n",
    "prediction_df = X_test.copy()\n",
    "prediction_df['prediction'] = [p['predictions'][0] for p in predictions]\n",
    "print(prediction_df['prediction'].describe(), \"\\n\")\n",
    "for m, fn in RATING_METRICS.items():\n",
    "    result = fn(test, prediction_df, **cols)\n",
    "    print(m, \"=\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique items\n",
    "if ITEM_FEAT_COL is None:\n",
    "    items = data.drop_duplicates(ITEM_COL)[[ITEM_COL]].reset_index(drop=True)\n",
    "else:\n",
    "    items = data.drop_duplicates(ITEM_COL)[[ITEM_COL, ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "# Unique users\n",
    "users = data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "\n",
    "# Ranking prediction set\n",
    "ranking_pool = user_item_pairs(\n",
    "    user_df=users,\n",
    "    item_df=items,\n",
    "    user_col=USER_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    user_item_filter_df=train,  # remove seen items\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Rating prediction\n",
    "predictions = list(itertools.islice(\n",
    "    saved_model.predict(predict_input_fn(ranking_pool)),\n",
    "    len(ranking_pool)\n",
    "))\n",
    "ranking_pool['prediction'] = [p['predictions'][0] for p in predictions]\n",
    "\n",
    "for m, fn in RANKING_METRICS.items():\n",
    "    result = fn(test, ranking_pool, **{**cols, 'k': TOP_K})\n",
    "    name = \"{}@{}\".format(m, TOP_K)\n",
    "    print(name, \"=\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if Hyperdrive found a good hyperparameters, we simply test the model with the hyperparameters used in [TensorFlow's wide-deep learning example](https://github.com/tensorflow/models/tree/master/official/wide_deep) as our baseline. The baseline example \n",
    "uses DNN (without the wide model) for [MovieLens example](https://github.com/tensorflow/models/blob/master/official/wide_deep/movielens_main.py).\n",
    "\n",
    "> Note, this is not 'apples to apples' comparison. For example, TensorFlow's movielens example uses *rating-timestamp* as a numeric feature, but we did not use that here because we think the timestamps are not relevant to the movies' ratings. This comparison is more like to show how Hyperdrive can help to find better hyperparameters without requiring exhaustive efforts in searching through a huge space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_NOTEBOOK = \"google_output.ipynb\"\n",
    "OUTPUT_MODEL_DIR = \"google_wide_deep_checkpoints\"\n",
    "\n",
    "params = {\n",
    "    'MOVIELENS_DATA_SIZE': MOVIELENS_DATA_SIZE,\n",
    "    'MODEL_TYPE': 'deep',\n",
    "    'NUM_SAMPLES_TO_TRAIN': 20000000,\n",
    "    'BATCH_SIZE': 256,\n",
    "    'DNN_OPTIMIZER': 'Adam',\n",
    "    'DNN_OPTIMIZER_LR': 0.001,\n",
    "    'DNN_HIDDEN_LAYER_1': 256,\n",
    "    'DNN_HIDDEN_LAYER_2': 256,\n",
    "    'DNN_HIDDEN_LAYER_3': 256,\n",
    "    'DNN_HIDDEN_LAYER_4': 128,\n",
    "    'DNN_USER_DIM': 16,\n",
    "    'DNN_ITEM_DIM': 64,\n",
    "    'DNN_DROPOUT': 0.3,\n",
    "    'DNN_BATCH_NORM': 0,\n",
    "    'MODEL_DIR': 'google_wide_deep_checkpoints',\n",
    "    'METRICS': ['rmse', 'mae', 'rsquared', 'exp_var', 'map', 'ndcg', 'precision', 'recall']\n",
    "}\n",
    "\n",
    "pm.execute_notebook(\n",
    "    \"../00_quick_start/wide_deep_model_movielens.ipynb\",\n",
    "    OUTPUT_NOTEBOOK,\n",
    "    parameters=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb = pm.read_notebook(OUTPUT_NOTEBOOK)\n",
    "display(nb.dataframe)\n",
    "display(nb.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(SCRIPT_DIR, ignore_errors=True)\n",
    "shutil.rmtree(DATA_DIR, ignore_errors=True)\n",
    "shutil.rmtree(MODEL_DIR, ignore_errors=True)\n",
    "\n",
    "os.remove(OUTPUT_NOTEBOOK)\n",
    "shutil.rmtree(OUTPUT_MODEL_DIR, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
