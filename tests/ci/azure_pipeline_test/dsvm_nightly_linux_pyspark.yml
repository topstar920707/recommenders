# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
#
# A Github Service Connection must also be created with the name "AI-GitHub"
# https://docs.microsoft.com/en-us/azure/devops/pipelines/process/demands?view=azure-devops&tabs=yaml

resources:
  repositories:
    - repository: aitemplates
      type: github
      name: microsoft/AI
      endpoint: AI-GitHub

schedules:
- cron: "0 0 * * *"
  displayName: Daily midnight build
  branches:
    include:
    - master
    - staging

trigger: none

pr: none

variables:
- group: LinuxAgentPool

jobs:
- job: nightly
  displayName: 'Nightly tests Linux Spark'
  timeoutInMinutes: 180 # how long to run the job before automatically cancelling
  pool:
    name: $(Agent_Pool)

  steps:
  - template: .ci/steps/reco_config_conda_linux.yml@aitemplates
    parameters:
      conda_env: nightly_reco_pyspark

  - script: |
      . /anaconda/etc/profile.d/conda.sh && \
      conda activate nightly_reco_pyspark && \
      echo "Smoke tests" && \
      pytest tests/smoke --durations 0 -m "smoke and spark and not gpu" --junitxml=reports/test-smoke.xml && \
      echo "Integration tests" && \
      pytest tests/integration --durations 0 -m "integration and spark and not gpu" --junitxml=reports/test-integration.xml && \
      conda deactivate    
    displayName: 'Run Tests'

  - task: PublishTestResults@2
    displayName: 'Publish Test Results '
    inputs:
      testResultsFiles: '**/test-*.xml'
      failTaskOnFailedTests: true
    condition: succeededOrFailed()

  - script: |
      conda env remove -n nightly_reco_pyspark -y   
    workingDirectory: tests
    displayName: 'Conda remove'
    continueOnError: true
    condition: always() # this step will always run, even if the pipeline is canceled
