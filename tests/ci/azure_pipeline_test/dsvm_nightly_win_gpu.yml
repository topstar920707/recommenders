# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
#
# A Github Service Connection must also be created with the name "AI-GitHub"
# https://docs.microsoft.com/en-us/azure/devops/pipelines/process/demands?view=azure-devops&tabs=yaml

schedules:
- cron: "0 0 * * *"
  displayName: Daily master gpu test pipeline
  branches:
    include:
    - master

trigger: none

pr: none

variables:
- group: WindowsAgentPool

jobs:
- job: nightly
  displayName: 'Nightly tests Windows GPU'
  timeoutInMinutes: 180 # how long to run the job before automatically cancelling
  pool:
    name: $(Agent_Pool)

  steps:
    - template: .ci/steps/reco_config_conda_win.yml@aitemplates
      parameters:
        conda_env: nightly_reco_base

    - script: |
      call conda env remove -n nightly_reco_gpu -y
      if exist C:\Anaconda\envs\nightly_reco_gpu rmdir /s /q C:\Anaconda\envs\nightly_reco_gpu
    displayName: 'Remove Conda Env if it exists'

  - script: |
      python ./scripts/generate_conda_file.py --gpu --name nightly_reco_gpu
      conda env create --quiet -f nightly_reco_gpu.yaml --verbose
    displayName: 'Setup Conda Env'

  - script: |
      call conda activate nightly_reco_gpu
      echo "Smoke tests"
      pytest tests/smoke --durations 0 -m "smoke and not spark and gpu" --junitxml=reports/test-smoke.xml
      echo "Integration tests"
      pytest tests/integration --durations 0 -m "integration and not spark and gpu" --junitxml=reports/test-integration.xml
    displayName: 'Run python smoke and integration tests'

  - task: PublishTestResults@2
    displayName: 'Publish Test Results **/test-*.xml'
    inputs:
      testResultsFiles: '**/test-*.xml'
      failTaskOnFailedTests: true
    condition: succeededOrFailed()

  - script: |
      call conda env remove -n nightly_reco_gpu -y
      if exist C:\Anaconda\envs\nightly_reco_gpu rmdir /s /q C:\Anaconda\envs\nightly_reco_gpu
    workingDirectory: tests
    displayName: 'Conda remove'
    continueOnError: true
    condition: always() # this step will always run, even if the pipeline is canceled
