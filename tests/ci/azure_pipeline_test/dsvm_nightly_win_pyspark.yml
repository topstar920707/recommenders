# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

schedules:
- cron: "0 06 * * *"
  displayName: Daily master spark testing pipeline
  branches:
    include:
    - master
    - staging

# no PR builds
pr: none

# no CI trigger
trigger: none

jobs:
- job: nightly
  displayName : "Nightly tests windows pyspark"
  timeoutInMinutes: 180

  pool:
    name: RecommendersAgentPoolWin

  steps:
  - script: |
      call conda env remove -n nightly_reco_pyspark
      SET F="C:\Anaconda\envs\nightly_reco_pyspark"
      IF EXIST %F% RMDIR /S /Q %F%
    displayName: 'Remove Conda Env if it exists'

  - script: |
      python ./scripts/generate_conda_file.py --pyspark --name nightly_reco_pyspark
      conda env create --quiet -f nightly_reco_pyspark.yaml --verbose
    displayName: 'Setup Conda Env'

  - script: |
      call conda activate nightly_reco_pyspark
      echo "Show libraries"
      pip list
      set SPARK_HOME=
      echo "Smoke tests"
      pytest tests/smoke --durations 0 -m "smoke and spark and not gpu" --junitxml=reports/test-smoke.xml
      echo "Integration tests"
      pytest tests/integration --durations 0 -m "integration and spark and not gpu" --junitxml=reports/test-integration.xml
      call conda deactivate
    displayName: 'Run pyspark smoke and integration tests'
    env:
      PYSPARK_PYTHON: c:\anaconda\envs\reco_pyspark\python.exe
      PYSPARK_DRIVER_PYTHON: c:\anaconda\envs\reco_pyspark\python.exe

  - task: PublishTestResults@2
    displayName: 'Publish Test Results '
    inputs:
      testResultsFiles: '**/test-*.xml'
      failTaskOnFailedTests: true
    condition: succeededOrFailed()

  - script: |
      call conda env remove -n nightly_reco_pyspark -y
      SET F="C:\Anaconda\envs\nightly_reco_pyspark"
      IF EXIST %F% RMDIR /S /Q %F%
    workingDirectory: tests
    displayName: 'Conda remove'
    continueOnError: true
    condition: succeededOrFailed()
